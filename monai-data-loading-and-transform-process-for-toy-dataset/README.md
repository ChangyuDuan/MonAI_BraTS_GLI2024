# BraTSè„‘è‚¿ç˜¤åˆ†å‰²é¡¹ç›®

è¿™æ˜¯ä¸€ä¸ªåŸºäºMONAIæ¡†æ¶çš„BraTSè„‘è‚¿ç˜¤åˆ†å‰²é¡¹ç›®ï¼Œæ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹å’Œé«˜çº§æ¶æ„æ–¹æ³•ã€‚é¡¹ç›®æä¾›äº†å®Œæ•´çš„æ•°æ®å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œå¯è§†åŒ–åŠŸèƒ½ï¼Œå†…ç½®äº†ä¸°å¯Œçš„è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬Diceç³»æ•°ã€Hausdorffè·ç¦»ã€è¡¨é¢è·ç¦»ã€æ··æ·†çŸ©é˜µã€å¹³å‡IoUå’Œå¹¿ä¹‰Diceåˆ†æ•°ç­‰ã€‚

## ğŸ”§ æœ€æ–°æ›´æ–° (v3.2.1)

### âœ… è¯­æ³•é”™è¯¯ä¿®å¤å®Œæˆ
- **ä¿®å¤äº†æ‰€æœ‰Pythonæ–‡ä»¶çš„è¯­æ³•é”™è¯¯**ï¼Œç¡®ä¿é¡¹ç›®å¯ä»¥æ­£å¸¸è¿è¡Œ
- **main.py**: ä¿®å¤é‡å¤çš„ `else` è¯­å¥å¯¼è‡´çš„ `SyntaxError`
- **train.py**: ä¿®å¤å¤šä¸ª `IndentationError` å’Œ `SyntaxError`ï¼ŒåŒ…æ‹¬æ¡ä»¶è¯­å¥ç¼©è¿›å¯¹é½ã€å­¦ä¹ ç‡è°ƒåº¦å™¨ä»£ç å—ç¼©è¿›ç­‰
- **model.py**: ä¿®å¤èåˆç½‘ç»œå‚æ•°ç±»å‹é”™è¯¯ï¼Œ`fusion_channels` ä»æ•´æ•°æ”¹ä¸ºåˆ—è¡¨ç±»å‹
- **æ‰€æœ‰æ¨¡å—**: é€šè¿‡è¯­æ³•æ£€æŸ¥éªŒè¯ï¼Œç¡®ä¿ä»£ç è´¨é‡

### ğŸš€ åŠŸèƒ½éªŒè¯å®Œæˆ
- **è‡ªé€‚åº”æŸå¤±å‡½æ•°**: ç¡®è®¤åœ¨æ‰€æœ‰æ¨¡å‹è®­ç»ƒä¸­æ­£å¸¸ä½¿ç”¨ï¼ŒåŠ¨æ€è°ƒæ•´æƒé‡
- **å®Œæ•´è¯„ä¼°æŒ‡æ ‡**: ç¡®è®¤åœ¨è®­ç»ƒç›‘æ§å’Œæ¨¡å‹è¯„ä¼°ä¸­å…¨é¢åº”ç”¨
- **ä¼˜åŒ–å™¨é…ç½®**: ç¡®è®¤æ ¹æ®ä¸åŒæ¨¡å‹ç±»å‹é‡‡ç”¨ç›¸åº”çš„ä¼˜åŒ–ç­–ç•¥
- **æ¨ç†åŠŸèƒ½**: ç¡®è®¤æ”¯æŒæ‰€æœ‰æ¨¡å‹ç±»å‹çš„æ¨ç†ï¼ŒåŒ…æ‹¬é«˜çº§æ¨¡å‹
- **èåˆç½‘ç»œ**: ä¿®å¤å‚æ•°ç±»å‹é”™è¯¯ï¼Œç°åœ¨å¯ä»¥æ­£å¸¸åˆ›å»ºå’Œè¿è¡Œèåˆæ¨¡å‹

### ğŸ” æœ€æ–°ä¿®å¤ (v3.2.1)
- **èåˆç½‘ç»œå‚æ•°é”™è¯¯**: ä¿®å¤äº† `FusionNetworkArchitecture` ä¸­ `fusion_channels` å‚æ•°ç±»å‹ä¸åŒ¹é…çš„é—®é¢˜
  - **é—®é¢˜**: `fusion_channels` è¢«ä¼ å…¥æ•´æ•°å€¼ `256`ï¼Œä½†æœŸæœ›åˆ—è¡¨ç±»å‹
  - **è§£å†³**: å°†é»˜è®¤å€¼æ”¹ä¸º `[64, 128, 256, 512]`ï¼Œç¬¦åˆå¤šçº§ç‰¹å¾èåˆçš„è®¾è®¡
  - **éªŒè¯**: æ‰€æœ‰æ¨¡å‹åŠŸèƒ½éªŒè¯é€šè¿‡ï¼ŒåŒ…æ‹¬åŸºç¡€æ¨¡å‹å’Œé«˜çº§èåˆæ¨¡å‹

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### ç»Ÿä¸€ç­–ç•¥æ¶æ„
é¡¹ç›®é‡‡ç”¨ç»Ÿä¸€çš„ç­–ç•¥æ¶æ„ï¼Œç¡®ä¿åœ¨è®­ç»ƒã€è¯„ä¼°å’Œéƒ¨ç½²çš„æ‰€æœ‰é˜¶æ®µéƒ½ä½¿ç”¨ä¸€è‡´çš„é…ç½®ï¼š

- **è‡ªé€‚åº”æŸå¤±å‡½æ•°ç­–ç•¥** - æ‰€æœ‰æ¨¡å‹é»˜è®¤ä½¿ç”¨adaptive_combinedç­–ç•¥ï¼ŒåŠ¨æ€ç»“åˆå¤šç§æŸå¤±å‡½æ•°
- **å®Œæ•´è¯„ä¼°æŒ‡æ ‡** - ç»Ÿä¸€ä½¿ç”¨å…¨éƒ¨6ç§è¯„ä¼°æŒ‡æ ‡è¿›è¡Œå…¨é¢æ€§èƒ½è¯„ä¼°
- **ä¸€è‡´æ€§ä¿è¯** - è®­ç»ƒ-è¯„ä¼°-éƒ¨ç½²å…¨æµç¨‹é…ç½®ç»Ÿä¸€ï¼Œé¿å…æ€§èƒ½å·®å¼‚

### ğŸ¯ è‡ªé€‚åº”æŸå¤±å‡½æ•°ç³»ç»Ÿ
é¡¹ç›®å®ç°äº†æ™ºèƒ½çš„è‡ªé€‚åº”æŸå¤±å‡½æ•°ç­–ç•¥ï¼Œåœ¨æ‰€æœ‰æ¨¡å‹è®­ç»ƒä¸­è‡ªåŠ¨åº”ç”¨ï¼Œæ ¹æ®è®­ç»ƒè¿›åº¦åŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡ï¼š

#### æŸå¤±å‡½æ•°ç»„åˆ (5ç§)
- **DiceCE Loss** - ç»“åˆDiceæŸå¤±å’Œäº¤å‰ç†µæŸå¤±ï¼Œé€‚åˆåˆ†å‰²ä»»åŠ¡
- **Focal Loss** - å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œå…³æ³¨å›°éš¾æ ·æœ¬
- **Tversky Loss** - å¯è°ƒèŠ‚å‡é˜³æ€§å’Œå‡é˜´æ€§æƒé‡ï¼Œå¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡
- **Generalized Dice Loss** - å¤„ç†å¤šç±»åˆ«åˆ†å‰²çš„ç±»åˆ«ä¸å¹³è¡¡
- **Dice Focal Loss** - ç»“åˆDiceå’ŒFocalçš„ä¼˜åŠ¿

#### åŠ¨æ€æƒé‡è°ƒæ•´ç­–ç•¥
- **å‰20%è®­ç»ƒ**: ä¸»è¦ä½¿ç”¨DiceCE (0.7) + Focal (0.2) + Tversky (0.1)
- **20%-40%è®­ç»ƒ**: å¢åŠ Focalæƒé‡ï¼ŒDiceCE (0.5) + Focal (0.3) + Tversky (0.1) + GeneralizedDice (0.1)
- **40%-60%è®­ç»ƒ**: å¹³è¡¡å„æŸå¤±ï¼ŒDiceCE (0.3) + Focal (0.3) + Tversky (0.2) + GeneralizedDice (0.1) + DiceFocal (0.1)
- **60%-80%è®­ç»ƒ**: å¢åŠ Tverskyæƒé‡ï¼ŒDiceCE (0.2) + Focal (0.2) + Tversky (0.4) + GeneralizedDice (0.1) + DiceFocal (0.1)
- **æœ€å20%è®­ç»ƒ**: ç»„åˆæ‰€æœ‰æŸå¤±ï¼Œæ¯ç§æƒé‡0.2ï¼Œå……åˆ†åˆ©ç”¨æ‰€æœ‰æŸå¤±å‡½æ•°çš„ä¼˜åŠ¿

#### è‡ªåŠ¨åº”ç”¨æœºåˆ¶
- **è®­ç»ƒè¿‡ç¨‹**: æ¯ä¸ªepochè‡ªåŠ¨è°ƒç”¨ `update_loss_epoch()` æ›´æ–°æƒé‡
- **æ‰€æœ‰æ¨¡å‹**: å•æ¨¡å‹ã€èåˆç½‘ç»œã€çŸ¥è¯†è’¸é¦ã€NASå‡è‡ªåŠ¨ä½¿ç”¨
- **æ— éœ€é…ç½®**: é»˜è®¤å¯ç”¨ï¼Œç”¨æˆ·æ— éœ€æ‰‹åŠ¨è®¾ç½®

## é¡¹ç›®ç»“æ„

```
â”œâ”€â”€ main.py                      # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ model.py                     # æ¨¡å‹å®šä¹‰å’Œåˆ›å»º
â”œâ”€â”€ DatasetLoader_transforms.py  # æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
â”œâ”€â”€ train.py                     # è®­ç»ƒæ¨¡å—
â”œâ”€â”€ evaluate.py                  # è¯„ä¼°æ¨¡å—
â”œâ”€â”€ inference.py                 # æ¨ç†æ¨¡å—
â””â”€â”€ utils.py                     # å·¥å…·å‡½æ•°
```

## ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 1.12+
- MONAI 1.0+
- CUDA 11.0+ (å¯é€‰ï¼Œç”¨äºGPUåŠ é€Ÿ)

### ä¾èµ–åŒ…å®‰è£…

```bash
pip install torch torchvision torchaudio
pip install monai[all]
pip install matplotlib pandas tqdm tensorboard
pip install nibabel scikit-image
```

## å¿«é€Ÿå¼€å§‹

### 1. æ¨¡å‹ä¿å­˜ä½ç½®è¯´æ˜

#### ğŸ“ åŸºç¡€æ¨¡å‹ä¿å­˜ä½ç½®
è®­ç»ƒå®Œæˆçš„åŸºç¡€æ¨¡å‹ä¿å­˜åœ¨ï¼š
```
./outputs/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ best_model.pth          # æœ€ä½³æ¨¡å‹æƒé‡
â”‚   â””â”€â”€ model_20240101_120000.pth # å¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ tensorboard_logs/       # TensorBoardæ—¥å¿—
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ training_history.json   # è®­ç»ƒå†å²è®°å½•
â”‚   â””â”€â”€ training_curves.png     # è®­ç»ƒæ›²çº¿å›¾
â””â”€â”€ visualizations/
    â””â”€â”€ sample_predictions.png  # æ ·æœ¬é¢„æµ‹å¯è§†åŒ–
```

#### ğŸ“ æ•™å¸ˆæ¨¡å‹é¢„è®­ç»ƒä¿å­˜ä½ç½®
é¢„è®­ç»ƒçš„æ•™å¸ˆæ¨¡å‹ä¿å­˜åœ¨ï¼š
```
./pretrained_teachers/
â”œâ”€â”€ UNet/
â”‚   â”œâ”€â”€ best_model.pth          # UNetæ•™å¸ˆæ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ training_log.json       # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ config.json             # æ¨¡å‹é…ç½®
â”œâ”€â”€ SegResNet/
â”‚   â”œâ”€â”€ best_model.pth          # SegResNetæ•™å¸ˆæ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ training_log.json       # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ config.json             # æ¨¡å‹é…ç½®
â”œâ”€â”€ UNETR/
â”‚   â”œâ”€â”€ best_model.pth          # UNETRæ•™å¸ˆæ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ training_log.json       # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ config.json             # æ¨¡å‹é…ç½®
â”œâ”€â”€ SwinUNETR/
â”‚   â”œâ”€â”€ best_model.pth          # SwinUNETRæ•™å¸ˆæ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ training_log.json       # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ config.json             # æ¨¡å‹é…ç½®
â”œâ”€â”€ AttentionUNet/
â”‚   â”œâ”€â”€ best_model.pth          # AttentionUNetæ•™å¸ˆæ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ training_log.json       # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ config.json             # æ¨¡å‹é…ç½®
â”œâ”€â”€ VNet/
â”‚   â”œâ”€â”€ best_model.pth          # VNetæ•™å¸ˆæ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ training_log.json       # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ config.json             # æ¨¡å‹é…ç½®
â””â”€â”€ HighResNet/
    â”œâ”€â”€ best_model.pth          # HighResNetæ•™å¸ˆæ¨¡å‹æƒé‡
    â”œâ”€â”€ training_log.json       # è®­ç»ƒæ—¥å¿—
    â””â”€â”€ config.json             # æ¨¡å‹é…ç½®
```

#### ğŸš€ é«˜çº§æ¨¡å‹ä¿å­˜ä½ç½®
é«˜çº§æ¨¡å‹ï¼ˆèåˆç½‘ç»œã€çŸ¥è¯†è’¸é¦ã€ç¥ç»æ¶æ„æœç´¢ï¼‰ä¿å­˜åœ¨ï¼š
```
./outputs/models/
â”œâ”€â”€ fusion_model/
â”‚   â””â”€â”€ checkpoints/
â”‚       â””â”€â”€ best_model.pth      # èåˆæ¨¡å‹æƒé‡
â”œâ”€â”€ distillation_student/
â”‚   â””â”€â”€ checkpoints/
â”‚       â””â”€â”€ best_model.pth      # å­¦ç”Ÿæ¨¡å‹æƒé‡
â”œâ”€â”€ nas_model/
â”‚   â””â”€â”€ checkpoints/
â”‚       â””â”€â”€ best_model.pth      # NASæ¨¡å‹æƒé‡
â””â”€â”€ {model_name}/               # å…¶ä»–é«˜çº§æ¨¡å‹
    â””â”€â”€ checkpoints/
        â””â”€â”€ best_model.pth      # å¯¹åº”æ¨¡å‹æƒé‡
```

#### ğŸ’¾ æ¨¡å‹æ–‡ä»¶å†…å®¹è¯´æ˜
æ¯ä¸ªä¿å­˜çš„æ¨¡å‹æ–‡ä»¶åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
- `model_state_dict`ï¼šæ¨¡å‹çŠ¶æ€å­—å…¸
- `optimizer_state_dict`ï¼šä¼˜åŒ–å™¨çŠ¶æ€
- `scheduler_state_dict`ï¼šè°ƒåº¦å™¨çŠ¶æ€  
- `best_metric`ï¼šæœ€ä½³éªŒè¯æŒ‡æ ‡ï¼ˆDiceåˆ†æ•°ï¼‰
- `config`ï¼šå®Œæ•´çš„è®­ç»ƒé…ç½®ä¿¡æ¯
- `is_advanced`ï¼šæ ‡è¯†æ¨¡å‹ç±»å‹ï¼ˆåŸºç¡€/é«˜çº§ï¼‰
- `model_name`ï¼šæ¨¡å‹åç§°
- `save_time`ï¼šä¿å­˜æ—¶é—´æˆ³
- `epoch`ï¼šä¿å­˜æ—¶çš„è®­ç»ƒè½®æ•°

#### ğŸ”§ è‡ªå®šä¹‰ä¿å­˜è·¯å¾„
```bash
# è‡ªå®šä¹‰åŸºç¡€æ¨¡å‹è¾“å‡ºç›®å½•
python main.py --mode train --output_dir ./my_custom_output
# æ¨¡å‹å°†ä¿å­˜åœ¨ï¼š./my_custom_output/checkpoints/best_model.pth

# è‡ªå®šä¹‰æ•™å¸ˆæ¨¡å‹é¢„è®­ç»ƒç›®å½•
python main.py --mode train --pretrained_dir ./my_teachers
# æ•™å¸ˆæ¨¡å‹å°†ä¿å­˜åœ¨ï¼š./my_teachers/{model_name}/best_model.pth
```

### 2. è®­ç»ƒæ¨¡å‹

é¡¹ç›®æ”¯æŒä¸¤å¤§ç±»æ¨¡å‹è®­ç»ƒï¼š**åŸºç¡€æ¨¡å‹**å’Œ**é«˜çº§æ¨¡å‹**ã€‚æ¯ç§ç±»å‹éƒ½æœ‰è¯¦ç»†çš„è®­ç»ƒè„šæœ¬ç¤ºä¾‹ã€‚

#### ğŸ”¥ åŸºç¡€æ¨¡å‹è®­ç»ƒ

åŸºç¡€æ¨¡å‹æ˜¯å•ä¸ªæ·±åº¦å­¦ä¹ æ¶æ„çš„è®­ç»ƒï¼Œé€‚åˆå¿«é€ŸéªŒè¯å’ŒåŸºå‡†æµ‹è¯•ã€‚è®­ç»ƒå®Œæˆåæ¨¡å‹å°†ä¿å­˜åœ¨ `./outputs/models/{model_name}/checkpoints/best_model.pth`ã€‚

```bash
# 1. æœ€ç®€åŒ–å‘½ä»¤ï¼ˆä½¿ç”¨æ‰€æœ‰é»˜è®¤è®¾ç½®ï¼‰
# é»˜è®¤ï¼šUNetæ¨¡å‹ã€200è½®è®­ç»ƒã€è‡ªåŠ¨è®¾å¤‡æ£€æµ‹
python main.py --mode train --data_dir /path/to/BraTS_data

# 2. æŒ‡å®šæ¨¡å‹è®­ç»ƒï¼ˆæ¨èï¼‰
python main.py --mode train --data_dir /path/to/BraTS_data --model_names SegResNet --epochs 150 --batch_size 2 --output_dir ./outputs

# 3. å®Œæ•´é…ç½®è®­ç»ƒ
python main.py --mode train --data_dir /path/to/BraTS_data --model_names UNETR --epochs 200 --batch_size 1 --learning_rate 1e-4 --device cuda --output_dir ./outputs
```

**å‚æ•°è¯¦ç»†è¯´æ˜ï¼š**

**åŸºç¡€å‚æ•°ï¼š**
- `--mode train`ï¼šè¿è¡Œæ¨¡å¼ï¼Œè®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
- `--data_dir`ï¼šBraTSæ•°æ®é›†ç›®å½•è·¯å¾„

**æ¨¡å‹é…ç½®ï¼š**
- `--model_names`ï¼šæŒ‡å®šè®­ç»ƒçš„æ¨¡å‹æ¶æ„ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `UNet`
  - **å¯é€‰å€¼**ï¼šUNetã€SegResNetã€UNETRã€SwinUNETRã€AttentionUNetã€VNetã€HighResNet
- `--epochs`ï¼šè®­ç»ƒè½®æ•°ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `200`
  - **æ¨è**ï¼š100-300è½®
- `--batch_size`ï¼šæ‰¹æ¬¡å¤§å°ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `2`
  - **æ¨è**ï¼š1-4ï¼ˆæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼‰

**ç³»ç»Ÿé…ç½®ï¼š**
- `--learning_rate`ï¼šå­¦ä¹ ç‡ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `1e-4`
- `--device`ï¼šè®¡ç®—è®¾å¤‡ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `auto`ï¼ˆè‡ªåŠ¨æ£€æµ‹cuda/cpuï¼‰
- `--output_dir`ï¼šæ¨¡å‹è¾“å‡ºç›®å½•ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `./outputs`
  - **ä¿å­˜è·¯å¾„**ï¼š`{output_dir}/models/{model_name}/checkpoints/best_model.pth`

**æ”¯æŒçš„7ä¸ªåŸºç¡€æ¨¡å‹ï¼š** UNetã€SegResNetã€UNETRã€SwinUNETRã€AttentionUNetã€VNetã€HighResNet

#### ğŸš€ é«˜çº§æ¨¡å‹è®­ç»ƒ

é«˜çº§æ¨¡å‹åŒ…æ‹¬èåˆç½‘ç»œã€çŸ¥è¯†è’¸é¦å’Œç¥ç»æ¶æ„æœç´¢ï¼Œæä¾›æ›´å¼ºå¤§çš„æ€§èƒ½ã€‚æ‰€æœ‰é«˜çº§æ¨¡å‹éƒ½è‡ªåŠ¨ä½¿ç”¨è‡ªé€‚åº”æŸå¤±å‡½æ•°å’Œå®Œæ•´è¯„ä¼°æŒ‡æ ‡ä½“ç³»ã€‚

##### ğŸ”§ é«˜çº§æ¨¡å‹ä¼˜åŒ–å™¨é…ç½®

ä¸åŒç±»å‹çš„é«˜çº§æ¨¡å‹é‡‡ç”¨ä¸“é—¨ä¼˜åŒ–çš„è®­ç»ƒç­–ç•¥ï¼š

```python
# çŸ¥è¯†è’¸é¦æ¨¡å‹ - ä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡ç¡®ä¿ç¨³å®šè®­ç»ƒ
optimizer = create_optimizer(
    model, 
    optimizer_name='adamw',
    learning_rate=5e-5,  # è¾ƒå°å­¦ä¹ ç‡
    weight_decay=1e-5
)

# èåˆç½‘ç»œæ¨¡å‹ - ä½¿ç”¨æ ‡å‡†å­¦ä¹ ç‡
optimizer = create_optimizer(
    model,
    optimizer_name='adamw', 
    learning_rate=1e-4,  # æ ‡å‡†å­¦ä¹ ç‡
    weight_decay=1e-5
)

# NASæ¨¡å‹ - åˆ†åˆ«ä¼˜åŒ–æ¶æ„å‚æ•°å’Œæ¨¡å‹å‚æ•°
arch_optimizer = torch.optim.Adam(model.get_arch_parameters(), lr=3e-4)
model_optimizer = create_optimizer(model, learning_rate=1e-3)
```

##### ğŸ“ˆ å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥

```python
# æ”¯æŒå¤šç§å­¦ä¹ ç‡è°ƒåº¦å™¨
scheduler = create_scheduler(
    optimizer,
    scheduler_name='cosineannealinglr',  # é»˜è®¤ä½™å¼¦é€€ç«
    T_max=max_epochs
)
# å…¶ä»–é€‰é¡¹: 'steplr', 'reducelronplateau'
```

##### èåˆç½‘ç»œè®­ç»ƒ

èåˆç½‘ç»œåœ¨ç‰¹å¾çº§åˆ«ç»“åˆå¤šä¸ªä¸åŒæ¶æ„ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶æé«˜æ€§èƒ½ã€‚è®­ç»ƒå®Œæˆåæ¨¡å‹å°†ä¿å­˜åœ¨ `./outputs/models/fusion_model/checkpoints/best_model.pth`ã€‚

```bash
# 1. åŸºç¡€å‘½ä»¤ï¼ˆä½¿ç”¨æ‰€æœ‰é»˜è®¤è®¾ç½®ï¼Œå¯é€‰å‚æ•°éƒ½ä¸æŒ‡å®šï¼‰
python main.py --mode train --data_dir /path/to/BraTS_data --model_category advanced --model_type fusion --epochs 200

# 2. å®Œæ•´é…ç½®å‘½ä»¤ï¼ˆä½¿ç”¨æ‰€æœ‰7ä¸ªæ¨¡å‹ï¼Œæ‰€æœ‰å‚æ•°éƒ½æŒ‡å®šï¼‰
python main.py --mode train --data_dir /path/to/BraTS_data --model_category advanced --model_type fusion --fusion_type attention --fusion_channels 64 128 256 512 --epochs 300 --batch_size 1 --learning_rate 5e-5 --device cuda --output_dir ./outputs

# 3. è‡ªå®šä¹‰ä¸‰æ¨¡å‹é…ç½®ï¼ˆUNetã€SegResNetã€UNETRï¼Œæ‰€æœ‰å‚æ•°éƒ½æŒ‡å®šï¼‰
python main.py --mode train --data_dir /path/to/BraTS_data --model_category advanced --model_type fusion --fusion_models UNet SegResNet UNETR --fusion_type cross_attention --fusion_channels 32 64 128 256 --epochs 250 --batch_size 2 --learning_rate 1e-4 --device auto --output_dir ./custom_fusion_outputs
```

**å‚æ•°è¯¦ç»†è¯´æ˜ï¼š**

**åŸºç¡€å‚æ•°ï¼š**
- `--mode train`ï¼šè¿è¡Œæ¨¡å¼ï¼Œè®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
- `--data_dir`ï¼šBraTSæ•°æ®é›†ç›®å½•è·¯å¾„
- `--model_category advanced`ï¼šæ¨¡å‹ç±»åˆ«ï¼Œé€‰æ‹©é«˜çº§æ¨¡å‹
- `--model_type fusion`ï¼šé«˜çº§æ¨¡å‹ç±»å‹ï¼Œé€‰æ‹©èåˆç½‘ç»œ

**èåˆæ¨¡å‹é…ç½®ï¼š**
- `--fusion_models`ï¼šæŒ‡å®šå‚ä¸èåˆçš„æ¨¡å‹åˆ—è¡¨ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨å…¨éƒ¨7ä¸ªæ¨¡å‹è¿›è¡Œèåˆ
  - **å¯é€‰å€¼**ï¼šUNetã€SegResNetã€UNETRã€SwinUNETRã€AttentionUNetã€VNetã€HighResNet
  - **ç¤ºä¾‹**ï¼š`--fusion_models UNet SegResNet UNETR` åªä½¿ç”¨è¿™3ä¸ªæ¨¡å‹
- `--fusion_type`ï¼šèåˆç­–ç•¥ç±»å‹ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `attention`
  - `attention`ï¼šåŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç‰¹å¾èåˆï¼ˆé»˜è®¤ï¼‰
  - `cross_attention`ï¼šäº¤å‰æ³¨æ„åŠ›èåˆï¼Œæ¨¡å‹é—´ç›¸äº’å…³æ³¨
  - `weighted`ï¼šåŠ æƒå¹³å‡èåˆ
  - `concat`ï¼šç‰¹å¾æ‹¼æ¥èåˆ
- `--fusion_channels`ï¼šå„å±‚èåˆé€šé“æ•°é…ç½®ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `64 128 256 512`ï¼ˆå¯¹åº”ç¼–ç å™¨å„å±‚ï¼‰
  - **ç¤ºä¾‹**ï¼š`--fusion_channels 32 64 128 256` ä½¿ç”¨æ›´å°çš„é€šé“æ•°

**è®­ç»ƒå‚æ•°ï¼š**
- `--epochs`ï¼šè®­ç»ƒè½®æ•°
  - **æ¨è**ï¼š200-300è½®ï¼ˆèåˆç½‘ç»œéœ€è¦æ›´å¤šè®­ç»ƒæ—¶é—´ï¼‰
- `--batch_size`ï¼šæ‰¹æ¬¡å¤§å°ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **æ¨è**ï¼š1-2ï¼ˆèåˆç½‘ç»œæ˜¾å­˜å ç”¨è¾ƒå¤§ï¼‰
- `--learning_rate`ï¼šå­¦ä¹ ç‡ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `1e-4`
  - **æ¨è**ï¼š5e-5ï¼ˆèåˆç½‘ç»œå»ºè®®ä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡ï¼‰

**ç³»ç»Ÿé…ç½®ï¼š**
- `--device`ï¼šè®¡ç®—è®¾å¤‡ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `auto`ï¼ˆè‡ªåŠ¨æ£€æµ‹cuda/cpuï¼‰
- `--output_dir`ï¼šæ¨¡å‹è¾“å‡ºç›®å½•ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `./outputs`
  - **ä¿å­˜è·¯å¾„**ï¼š`{output_dir}/models/fusion_model/checkpoints/best_model.pth`
- **è®­ç»ƒæ—¥å¿—**ï¼šç°åœ¨ä¼šæ­£ç¡®æ˜¾ç¤º"è¾“å‡ºç›®å½•: outputs/models/fusion_model"è€Œä¸æ˜¯UNetç›®å½•

**æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š**
- ä½¿ç”¨è¾ƒå°çš„batch_sizeï¼ˆ1-2ï¼‰é¿å…æ˜¾å­˜ä¸è¶³
- å¢åŠ è®­ç»ƒè½®æ•°ï¼ˆ200-300ï¼‰ç¡®ä¿å……åˆ†èåˆ
- ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼ˆ5e-5ï¼‰æé«˜è®­ç»ƒç¨³å®šæ€§
- æ ¹æ®æ˜¾å­˜æƒ…å†µè°ƒæ•´fusion_channelså¤§å°

**é»˜è®¤çš„7ä¸ªèåˆæ¨¡å‹ï¼š** UNetã€SegResNetã€UNETRã€SwinUNETRã€AttentionUNetã€VNetã€HighResNet

**èåˆç½‘ç»œå·¥ä½œåŸç†ï¼š**
- **å¤šæ¨¡å‹ç‰¹å¾æå–**ï¼š7ä¸ªåŸºç¡€æ¨¡å‹åŒæ—¶å¤„ç†è¾“å…¥æ•°æ®ï¼Œæå–å„è‡ªç‰¹å¾
- **å‚æ•°å†»ç»“ç­–ç•¥**ï¼šåŸºç¡€æ¨¡å‹å‚æ•°è¢«å†»ç»“ï¼Œä¸å‚ä¸è®­ç»ƒï¼Œç¡®ä¿é¢„è®­ç»ƒçŸ¥è¯†ä¿ç•™
- **èåˆå±‚è®­ç»ƒ**ï¼šåªè®­ç»ƒæ–°å¢çš„èåˆç»„ä»¶ï¼ˆæ³¨æ„åŠ›æ¨¡å—ã€ç‰¹å¾é€‚é…å±‚ã€è§£ç å™¨ç­‰ï¼‰
- **æ™ºèƒ½ç‰¹å¾ç»„åˆ**ï¼šé€šè¿‡äº¤å‰æ³¨æ„åŠ›ã€é€šé“æ³¨æ„åŠ›ç­‰æœºåˆ¶æ™ºèƒ½ç»„åˆä¸åŒæ¨¡å‹ç‰¹å¾
- **ç«¯åˆ°ç«¯ä¼˜åŒ–**ï¼šèåˆç­–ç•¥é€šè¿‡åå‘ä¼ æ’­è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜ç»„åˆæ–¹å¼

##### çŸ¥è¯†è’¸é¦è®­ç»ƒ

çŸ¥è¯†è’¸é¦ä½¿ç”¨å¤šä¸ªæ•™å¸ˆæ¨¡å‹è®­ç»ƒè½»é‡çº§å­¦ç”Ÿæ¨¡å‹ï¼Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å‡å°‘æ¨¡å‹å¤æ‚åº¦ã€‚æ•™å¸ˆæ¨¡å‹ä¿å­˜åœ¨ `./pretrained_teachers/`ï¼Œå­¦ç”Ÿæ¨¡å‹ä¿å­˜åœ¨ `./outputs/models/distillation_model/checkpoints/best_model.pth`ã€‚

```bash
# 1. æŒ‡å®šæ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†è’¸é¦ï¼ˆæ¨èï¼‰
python main.py --mode train  --data_dir /path/to/BraTS_data  --model_category advanced  --model_type distillation  --teacher_models UNet SegResNet UNETR SwinUNETR AttentionUNet  --student_model UNet  --distillation_type multi_teacher  --distillation_temperature 5.0  --distillation_alpha 0.8  --epochs 250  --teacher_epochs 100  --device cuda  --pretrain_teachers  --output_dir ./outputs  --pretrained_dir ./pretrained_teachers

# 2. é»˜è®¤æ¨¡å¼ï¼ˆä½¿ç”¨å…¨éƒ¨7ä¸ªæ•™å¸ˆæ¨¡å‹ï¼‰
python main.py --mode train  --data_dir /path/to/BraTS_data  --model_category advanced  --model_type distillation  --student_model UNet  --pretrain_teachers  --teacher_epochs 100  --epochs 250  --device cuda  --output_dir ./outputs  --pretrained_dir ./pretrained_teachers

# 3. æœ€ç®€åŒ–å‘½ä»¤ï¼ˆä½¿ç”¨æ‰€æœ‰é»˜è®¤è®¾ç½®ï¼‰
# é»˜è®¤ï¼š7ä¸ªæ•™å¸ˆæ¨¡å‹ã€UNetå­¦ç”Ÿæ¨¡å‹ã€é»˜è®¤ä¿å­˜è·¯å¾„
python main.py --mode train --data_dir /path/to/BraTS_data --model_category advanced --model_type distillation --pretrain_teachers --teacher_epochs 100  --epochs 250  --device cpu
```

**å‚æ•°è¯¦ç»†è¯´æ˜ï¼š**

**åŸºç¡€å‚æ•°ï¼š**
- `--mode train`ï¼šè¿è¡Œæ¨¡å¼ï¼Œè®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
- `--data_dir`ï¼šBraTSæ•°æ®é›†ç›®å½•è·¯å¾„
- `--model_category advanced`ï¼šæ¨¡å‹ç±»åˆ«ï¼Œé€‰æ‹©é«˜çº§æ¨¡å‹
- `--model_type distillation`ï¼šé«˜çº§æ¨¡å‹ç±»å‹ï¼Œé€‰æ‹©çŸ¥è¯†è’¸é¦

**æ•™å¸ˆæ¨¡å‹é…ç½®ï¼š**
- `--teacher_models`ï¼šæŒ‡å®šæ•™å¸ˆæ¨¡å‹åˆ—è¡¨ï¼ˆå¯é€‰ï¼šUNetã€SegResNetã€UNETRã€SwinUNETRã€AttentionUNetã€VNetã€HighResNetï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨å…¨éƒ¨7ä¸ªæ¨¡å‹ä½œä¸ºæ•™å¸ˆ
- `--pretrain_teachers`ï¼šå¯ç”¨æ•™å¸ˆæ¨¡å‹é¢„è®­ç»ƒï¼ˆæ¨èï¼‰
- `--teacher_epochs 100`ï¼šæ•™å¸ˆæ¨¡å‹é¢„è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤100ï¼‰
- `--force_retrain_teachers`ï¼šå¼ºåˆ¶é‡æ–°è®­ç»ƒå·²å­˜åœ¨çš„æ•™å¸ˆæ¨¡å‹ï¼ˆå¯é€‰ï¼‰

**å­¦ç”Ÿæ¨¡å‹é…ç½®ï¼š**
- `--student_model`ï¼šå­¦ç”Ÿæ¨¡å‹æ¶æ„
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨UNetä½œä¸ºå­¦ç”Ÿæ¨¡å‹
- `--epochs 250`ï¼šå­¦ç”Ÿæ¨¡å‹è’¸é¦è®­ç»ƒè½®æ•°

**è’¸é¦å‚æ•°ï¼š**
- `--distillation_type multi_teacher`ï¼šè’¸é¦ç±»å‹
  - `multi_teacher`ï¼šå¤šæ•™å¸ˆå¹¶è¡Œè’¸é¦ï¼ŒåŒæ—¶ä½¿ç”¨æ‰€æœ‰æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†ï¼ˆæ¨èï¼‰
  - `progressive`ï¼šæ¸è¿›å¼è’¸é¦ï¼ŒæŒ‰å¤æ‚åº¦ä»ç®€å•åˆ°å¤æ‚é€æ­¥å­¦ä¹ æ•™å¸ˆæ¨¡å‹
- `--distillation_temperature 5.0`ï¼šè’¸é¦æ¸©åº¦ï¼Œæ§åˆ¶è½¯æ ‡ç­¾å¹³æ»‘ç¨‹åº¦ï¼ˆé»˜è®¤4.0ï¼‰
- `--distillation_alpha 0.8`ï¼šè½¯æ ‡ç­¾æƒé‡ï¼Œå¹³è¡¡æ•™å¸ˆå’ŒçœŸå®æ ‡ç­¾ï¼ˆé»˜è®¤0.7ï¼‰

**ç³»ç»Ÿé…ç½®ï¼š**
- `--device`ï¼šè®¡ç®—è®¾å¤‡ï¼ˆcpu/cuda/autoï¼Œé»˜è®¤autoï¼‰
- `--output_dir`ï¼šæ¨¡å‹è¾“å‡ºç›®å½•
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `./outputs`
- `--pretrained_dir`ï¼šæ•™å¸ˆæ¨¡å‹é¢„è®­ç»ƒç›®å½•
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `./pretrained_teachers`

**é»˜è®¤çš„7ä¸ªæ•™å¸ˆæ¨¡å‹ï¼š** UNetã€SegResNetã€UNETRã€SwinUNETRã€AttentionUNetã€VNetã€HighResNet

##### ç¥ç»æ¶æ„æœç´¢è®­ç»ƒ

ç¥ç»æ¶æ„æœç´¢è‡ªåŠ¨å‘ç°æœ€ä¼˜ç½‘ç»œæ¶æ„ï¼Œå‡å°‘äººå·¥è®¾è®¡éœ€æ±‚ã€‚è®­ç»ƒå®Œæˆåæ¨¡å‹å°†ä¿å­˜åœ¨ `./outputs/models/nas_model/checkpoints/best_model.pth`ã€‚

```bash
#1. è¶…ç½‘ç»œè®­ç»ƒï¼ˆé»˜è®¤æ¨èï¼‰ - å®Œæ•´å‚æ•°
python main.py --mode train --data_dir /path/to/BraTS_data --model_category advanced --model_type nas --nas_epochs 100 --epochs 400 --base_channels 32 --num_layers 4 --batch_size 2 --learning_rate 1e-4 --device cuda --output_dir ./outputs

#2. DARTSæ¶æ„æœç´¢ï¼ˆé«˜çº§ç”¨æˆ·ï¼‰ - å®Œæ•´å‚æ•°
python main.py --mode train --data_dir /path/to/BraTS_data --model_category advanced --model_type nas --nas_type searcher --nas_epochs 100 --epochs 400 --arch_lr 5e-4 --model_lr 2e-3 --batch_size 2 --learning_rate 1e-4 --device cuda --output_dir ./outputs

#3. æ¸è¿›å¼NASï¼ˆé€æ­¥å¢åŠ ç½‘ç»œå¤æ‚åº¦ï¼‰ - å®Œæ•´å‚æ•°
python main.py --mode train --data_dir /path/to/BraTS_data --model_category advanced --model_type nas --nas_type progressive --nas_epochs 100 --epochs 400 --max_layers 8 --start_layers 2 --batch_size 2 --learning_rate 1e-4 --device cuda --output_dir ./outputs

#5. æœ€ç®€åŒ–å‘½ä»¤ï¼ˆä½¿ç”¨æ‰€æœ‰é»˜è®¤è®¾ç½®ï¼‰
python main.py --mode train --data_dir /path/to/BraTS_data --model_category advanced --model_type nas

```

**å‚æ•°è¯¦ç»†è¯´æ˜ï¼š**

**åŸºç¡€å‚æ•°ï¼š**
- `--mode train`ï¼šè¿è¡Œæ¨¡å¼ï¼Œè®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
- `--data_dir`ï¼šBraTSæ•°æ®é›†ç›®å½•è·¯å¾„
- `--model_category advanced`ï¼šæ¨¡å‹ç±»åˆ«ï¼Œé€‰æ‹©é«˜çº§æ¨¡å‹
- `--model_type nas`ï¼šé«˜çº§æ¨¡å‹ç±»å‹ï¼Œé€‰æ‹©ç¥ç»æ¶æ„æœç´¢

**NASæœç´¢é…ç½®ï¼š**
- `--nas_type`ï¼šNASæœç´¢ç­–ç•¥ç±»å‹ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨è¶…ç½‘ç»œè®­ç»ƒ
  - `searcher`ï¼šDARTSå¯å¾®åˆ†æ¶æ„æœç´¢ï¼ŒåŒæ—¶ä¼˜åŒ–æ¶æ„å’Œæƒé‡
  - `progressive`ï¼šæ¸è¿›å¼æœç´¢ï¼Œä»ç®€å•æ¶æ„é€æ­¥å¢åŠ å¤æ‚åº¦
  - `supernet`ï¼šè¶…ç½‘ç»œè®­ç»ƒï¼Œä¸€æ¬¡è®­ç»ƒåŒ…å«å¤šç§å­æ¶æ„çš„å¤§ç½‘ç»œï¼ˆé»˜è®¤ï¼‰
- `--nas_epochs`ï¼šæ¶æ„æœç´¢é˜¶æ®µçš„è®­ç»ƒè½®æ•°ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `50`
  - **æ¨è**ï¼š50-100è½®ï¼ˆæœç´¢é˜¶æ®µéœ€è¦å……åˆ†æ¢ç´¢ï¼‰
- `--epochs`ï¼šæœ€ç»ˆæ¨¡å‹è®­ç»ƒè½®æ•°ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `200`
  - **æ¨è**ï¼š200-400è½®ï¼ˆæ‰¾åˆ°æœ€ä¼˜æ¶æ„åçš„å……åˆ†è®­ç»ƒï¼‰

**DARTSæœç´¢å‚æ•°ï¼ˆnas_type=searcheræ—¶ä½¿ç”¨ï¼‰ï¼š**
- `--arch_lr`ï¼šæ¶æ„å‚æ•°å­¦ä¹ ç‡ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `3e-4`
  - **æ¨è**ï¼š1e-4åˆ°5e-4ä¹‹é—´
- `--model_lr`ï¼šæ¨¡å‹æƒé‡å­¦ä¹ ç‡ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `1e-3`
  - **æ¨è**ï¼š5e-4åˆ°2e-3ä¹‹é—´

**æ¸è¿›å¼NASå‚æ•°ï¼ˆnas_type=progressiveæ—¶ä½¿ç”¨ï¼‰ï¼š**
- `--max_layers`ï¼šæœ€å¤§ç½‘ç»œå±‚æ•°ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `8`
  - **æ¨è**ï¼š4-10å±‚ä¹‹é—´
- `--start_layers`ï¼šèµ·å§‹ç½‘ç»œå±‚æ•°ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `2`
  - **æ¨è**ï¼š2-4å±‚å¼€å§‹

**è¶…ç½‘ç»œå‚æ•°ï¼ˆnas_type=supernetæ—¶ä½¿ç”¨ï¼‰ï¼š**
- `--base_channels`ï¼šåŸºç¡€é€šé“æ•°ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `32`
  - **æ¨è**ï¼š16-64ä¹‹é—´ï¼Œå½±å“æ¨¡å‹å¤§å°
- `--num_layers`ï¼šç½‘ç»œå±‚æ•°ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `4`
  - **æ¨è**ï¼š3-6å±‚ä¹‹é—´

**è®­ç»ƒå‚æ•°ï¼š**
- `--batch_size`ï¼šæ‰¹æ¬¡å¤§å°ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `2`
  - **æ¨è**ï¼š1-2ï¼ˆNASæœç´¢æ˜¾å­˜å ç”¨è¾ƒå¤§ï¼‰
- `--learning_rate`ï¼šå­¦ä¹ ç‡ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `1e-4`
  - **æ¨è**ï¼š5e-5åˆ°2e-4ä¹‹é—´

**ç³»ç»Ÿé…ç½®ï¼š**
- `--device`ï¼šè®¡ç®—è®¾å¤‡ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `auto`ï¼ˆè‡ªåŠ¨æ£€æµ‹cuda/cpuï¼‰
- `--output_dir`ï¼šæ¨¡å‹è¾“å‡ºç›®å½•ï¼ˆ**å¯é€‰å‚æ•°**ï¼‰
  - **å¯çœç•¥**ï¼šä¸æŒ‡å®šæ—¶é»˜è®¤ä½¿ç”¨ `./outputs`
  - **ä¿å­˜è·¯å¾„**ï¼š`{output_dir}/models/nas_model/checkpoints/best_model.pth`

**NASæœç´¢ç­–ç•¥è¯´æ˜ï¼š**
- **åŸºç¡€NAS**ï¼šç®€å•æœ‰æ•ˆçš„æ¶æ„æœç´¢ï¼Œé€‚åˆåˆå­¦è€…
- **DARTSæœç´¢**ï¼šå¯å¾®åˆ†æ¶æ„æœç´¢ï¼Œæœç´¢æ•ˆç‡é«˜ä½†éœ€è¦æ›´å¤šæ˜¾å­˜
- **æ¸è¿›å¼NAS**ï¼šä»ç®€å•åˆ°å¤æ‚é€æ­¥æœç´¢ï¼Œè®­ç»ƒç¨³å®šä½†è€—æ—¶è¾ƒé•¿
- **è¶…ç½‘ç»œè®­ç»ƒ**ï¼šä¸€æ¬¡è®­ç»ƒå¤šç§æ¶æ„ï¼Œæœç´¢ç©ºé—´å¤§ä½†è®¡ç®—å¤æ‚



#### ğŸ“Š è®­ç»ƒç­–ç•¥é€‰æ‹©æŒ‡å—

| æ¨¡å‹ç±»å‹ | é€‚ç”¨åœºæ™¯ | è®­ç»ƒæ—¶é—´ | å†…å­˜éœ€æ±‚ | æ€§èƒ½è¡¨ç° |
|----------|----------|----------|----------|----------|
| **åŸºç¡€æ¨¡å‹** | å¿«é€ŸéªŒè¯ã€åŸºå‡†æµ‹è¯• | çŸ­ | ä½ | è‰¯å¥½ |
| **èåˆç½‘ç»œ** | è¿½æ±‚æœ€é«˜æ€§èƒ½ | é•¿ | é«˜ | ä¼˜ç§€ |
| **çŸ¥è¯†è’¸é¦** | æ¨¡å‹å‹ç¼©ã€éƒ¨ç½²ä¼˜åŒ– | ä¸­ç­‰ | ä¸­ç­‰ | è‰¯å¥½ |
| **ç¥ç»æ¶æ„æœç´¢** | è‡ªåŠ¨åŒ–è®¾è®¡ | å¾ˆé•¿ | é«˜ | ä¼˜ç§€ |


### 3. è¯„ä¼°æ¨¡å‹

é¡¹ç›®æ”¯æŒå¯¹æ‰€æœ‰ç±»å‹æ¨¡å‹è¿›è¡Œå…¨é¢è¯„ä¼°ï¼ŒåŒ…æ‹¬åŸºç¡€æ¨¡å‹å’Œé«˜çº§æ¨¡å‹ã€‚

#### ğŸ” åŸºç¡€æ¨¡å‹è¯„ä¼°

```bash
# è¯„ä¼°åŸºç¡€æ¨¡å‹ï¼ˆé»˜è®¤ä¿å­˜ä½ç½®ï¼‰
python main.py --mode eval --model_path ./outputs/checkpoints/best_model.pth --data_dir /path/to/BraTS_data

# è¯„ä¼°ç‰¹å®šåŸºç¡€æ¨¡å‹
python main.py --mode eval --model_path ./outputs/checkpoints/best_model.pth --data_dir /path/to/BraTS_data --output_dir ./evaluation_results

# è¯„ä¼°å¹¶ä¿å­˜è¯¦ç»†æŠ¥å‘Š
python main.py --mode eval --model_path ./outputs/checkpoints/best_model.pth --data_dir /path/to/BraTS_data --save_predictions --output_dir ./evaluation_results

# è¯„ä¼°è‡ªå®šä¹‰ç›®å½•çš„åŸºç¡€æ¨¡å‹
python main.py --mode eval --model_path ./my_models/checkpoints/best_model.pth --data_dir /path/to/BraTS_data
```

#### ğŸš€ é«˜çº§æ¨¡å‹è¯„ä¼°

```bash
# è¯„ä¼°èåˆç½‘ç»œæ¨¡å‹
python main.py --mode eval --model_path ./outputs/models/fusion_model/checkpoints/best_model.pth --data_dir /path/to/BraTS_data

# è¯„ä¼°çŸ¥è¯†è’¸é¦å­¦ç”Ÿæ¨¡å‹
python main.py --mode eval --model_path ./outputs/models/distillation_student/checkpoints/best_model.pth --data_dir /path/to/BraTS_data

# è¯„ä¼°NASæœç´¢æ¨¡å‹
python main.py --mode eval --model_path ./outputs/models/nas_model/checkpoints/best_model.pth --data_dir /path/to/BraTS_data

# é«˜çº§æ¨¡å‹è¯¦ç»†è¯„ä¼°
python main.py --mode eval --model_path ./outputs/models/fusion_model/checkpoints/best_model.pth --data_dir /path/to/BraTS_data \
    --detailed_metrics --save_visualizations --output_dir ./evaluation_results

# è¯„ä¼°è‡ªå®šä¹‰ç›®å½•çš„é«˜çº§æ¨¡å‹
python main.py --mode eval --model_path ./my_advanced_models/models/fusion_model/checkpoints/best_model.pth --data_dir /path/to/BraTS_data
```



#### ğŸ“Š è¯„ä¼°å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|----------|
| `--model_path` | str | å¿…éœ€ | æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ |
| `--data_dir` | str | å¿…éœ€ | æµ‹è¯•æ•°æ®é›†è·¯å¾„ |
| `--save_predictions` | flag | False | ä¿å­˜é¢„æµ‹ç»“æœ |
| `--detailed_metrics` | flag | False | è®¡ç®—è¯¦ç»†è¯„ä¼°æŒ‡æ ‡ |
| `--save_visualizations` | flag | False | ä¿å­˜å¯è§†åŒ–ç»“æœ |

| `--batch_size` | int | 1 | è¯„ä¼°æ‰¹æ¬¡å¤§å° |

### 4. æ¨¡å‹æ¨ç†

é¡¹ç›®æä¾›å¼ºå¤§çš„æ¨ç†åŠŸèƒ½ï¼Œæ”¯æŒå•å¼ å›¾åƒã€æ‰¹é‡å¤„ç†ä»¥åŠå„ç§é«˜çº§æ¨¡å‹çš„æ¨ç†ã€‚

#### ğŸ–¼ï¸ åŸºç¡€æ¨¡å‹æ¨ç†

```bash
# å•å¼ å›¾åƒæ¨ç†ï¼ˆåŸºç¡€æ¨¡å‹ï¼‰
python main.py --mode inference --model_path ./outputs/checkpoints/best_model.pth --input /path/to/single_image.nii.gz --output /path/to/output.nii.gz

# æ‰¹é‡æ¨ç†ï¼ˆåŸºç¡€æ¨¡å‹ï¼‰
python main.py --mode inference --model_path ./outputs/checkpoints/best_model.pth --input /path/to/images_folder --output /path/to/output_folder

# æŒ‡å®šè¾“å‡ºæ ¼å¼ï¼ˆåŸºç¡€æ¨¡å‹ï¼‰
python main.py --mode inference --model_path ./outputs/checkpoints/best_model.pth --input /path/to/images \
    --output /path/to/output --save_format nifti

# è‡ªå®šä¹‰ç›®å½•åŸºç¡€æ¨¡å‹æ¨ç†
python main.py --mode inference --model_path ./my_models/checkpoints/best_model.pth --input /path/to/images --output /path/to/output
```

#### ğŸš€ é«˜çº§æ¨¡å‹æ¨ç†

```bash
# èåˆç½‘ç»œæ¨ç†
python main.py --mode inference --model_path ./outputs/models/fusion_model/checkpoints/best_model.pth --input /path/to/images \
    --output /path/to/output --model_type fusion

# çŸ¥è¯†è’¸é¦å­¦ç”Ÿæ¨¡å‹æ¨ç†
python main.py --mode inference --model_path ./outputs/models/distillation_student/checkpoints/best_model.pth --input /path/to/images \
    --output /path/to/output --model_type distillation

# NASæ¨¡å‹æ¨ç†
python main.py --mode inference --model_path ./outputs/models/nas_model/checkpoints/best_model.pth --input /path/to/images \
    --output /path/to/output --model_type nas

# è‡ªå®šä¹‰ç›®å½•é«˜çº§æ¨¡å‹æ¨ç†
python main.py --mode inference --model_path ./my_advanced_models/models/fusion_model/checkpoints/best_model.pth --input /path/to/images --output /path/to/output

# é«˜çº§æ¨ç†é…ç½®
python main.py --mode inference --model_path ./outputs/models/fusion_model/checkpoints/best_model.pth --input /path/to/images \
    --output /path/to/output --batch_size 4 --overlap 0.5 --blend_mode gaussian --tta
```



#### âš¡ é«˜æ€§èƒ½æ¨ç†

```bash
# GPUåŠ é€Ÿæ¨ç†
python main.py --mode inference --model_path ./outputs/checkpoints/best_model.pth --input /path/to/images \
    --output /path/to/output --device cuda --batch_size 8

# æ··åˆç²¾åº¦æ¨ç†
python main.py --mode inference --model_path ./outputs/checkpoints/best_model.pth --input /path/to/images \
    --output /path/to/output --amp --batch_size 16

# å¤šGPUæ¨ç†
python main.py --mode inference --model_path ./outputs/checkpoints/best_model.pth --input /path/to/images \
    --output /path/to/output --multi_gpu --batch_size 32
```

#### ğŸ“Š æ¨ç†å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|----------|
| `--model_path` | str | å¿…éœ€ | æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ |
| `--input` | str | å¿…éœ€ | è¾“å…¥å›¾åƒæˆ–æ–‡ä»¶å¤¹è·¯å¾„ |
| `--output` | str | å¿…éœ€ | è¾“å‡ºç»“æœä¿å­˜è·¯å¾„ |
| `--model_type` | str | auto | æ¨¡å‹ç±»å‹ï¼ˆbasic/fusion/distillation/nasï¼‰ |
| `--batch_size` | int | 1 | æ¨ç†æ‰¹æ¬¡å¤§å° |
| `--overlap` | float | 0.25 | æ»‘åŠ¨çª—å£é‡å ç‡ |
| `--blend_mode` | str | constant | èåˆæ¨¡å¼ï¼ˆconstant/gaussianï¼‰ |
| `--tta` | flag | False | æµ‹è¯•æ—¶å¢å¼º |

| `--voting_strategy` | str | soft | æŠ•ç¥¨ç­–ç•¥ï¼ˆsoft/hard/weightedï¼‰ |
| `--save_format` | str | nifti | è¾“å‡ºæ ¼å¼ï¼ˆnifti/png/jpgï¼‰ |
| `--device` | str | auto | è®¡ç®—è®¾å¤‡ï¼ˆcpu/cuda/autoï¼‰ |
| `--amp` | flag | False | æ··åˆç²¾åº¦æ¨ç† |
| `--multi_gpu` | flag | False | å¤šGPUæ¨ç† |

#### ğŸ¯ æ¨ç†è¾“å‡ºç»“æœ

1. **é¢„æµ‹ç»“æœæ–‡ä»¶** (`*.nii.gz`)
   - åˆ†å‰²æ©ç ï¼ŒåŒ…å«ä¸åŒçš„æ ‡ç­¾å€¼
   - æ ‡ç­¾å«ä¹‰ï¼š0=èƒŒæ™¯ï¼Œ1=åæ­»ï¼Œ2=æ°´è‚¿ï¼Œ3=å¢å¼ºè‚¿ç˜¤
   - æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ï¼ˆNIfTIã€PNGã€JPGï¼‰

2. **å¯è§†åŒ–æ–‡ä»¶** (`*_visualization.png`)
   - åŸå§‹å›¾åƒå’Œé¢„æµ‹ç»“æœçš„å åŠ æ˜¾ç¤º
   - ä¸­é—´å±‚åˆ‡ç‰‡çš„å¯è§†åŒ–
   - é«˜çº§æ¨¡å‹ç‰¹æœ‰çš„æ³¨æ„åŠ›å›¾å¯è§†åŒ–

3. **æ¨ç†æŠ¥å‘Š** (`inference_report.json`)
   - åŒ…å«æ‰€æœ‰æ–‡ä»¶çš„æ¨ç†ç»“æœç»Ÿè®¡
   - æ¨¡å‹ç±»å‹å’Œé…ç½®ä¿¡æ¯
   - æ¨ç†æ—¶é—´å’Œæ€§èƒ½æŒ‡æ ‡
   - æˆåŠŸ/å¤±è´¥çŠ¶æ€å’Œé”™è¯¯ä¿¡æ¯



#### ğŸ’» ç¼–ç¨‹æ¥å£ä½¿ç”¨

```python
from inference import InferenceEngine

# åŸºç¡€æ¨¡å‹æ¨ç†
engine = InferenceEngine(
    model_path='outputs/checkpoints/best_model.pth',
    device='cuda'
)

# é«˜çº§æ¨¡å‹æ¨ç†
advanced_engine = InferenceEngine(
    model_path='outputs/advanced/fusion_model.pth',
    model_type='fusion',
    device='cuda'
)

# é«˜çº§æ¨¡å‹æ¨ç†
advanced_engine = InferenceEngine(
    model_path='outputs/advanced/fusion_model.pth',
    voting_strategy='soft'
)

# å•æ–‡ä»¶æ¨ç†
result = engine.predict_single_case(
    image_path='data/test.nii.gz',
    output_path='results/prediction.nii.gz',
    tta=True  # æµ‹è¯•æ—¶å¢å¼º
)

# æ‰¹é‡æ¨ç†
results = engine.predict_batch(
    input_dir='data/test_cases/',
    output_dir='results/',
    batch_size=4
)
```

#### âœ¨ æ¨ç†æ¨¡å—ç‰¹ç‚¹

- **å…¨æ¨¡å‹æ”¯æŒ**: æ”¯æŒåŸºç¡€æ¨¡å‹å’Œé«˜çº§æ¨¡å‹
- **æ™ºèƒ½è¯†åˆ«**: è‡ªåŠ¨è¯†åˆ«æ¨¡å‹ç±»å‹å’Œé…ç½®
- **é«˜æ•ˆæ¨ç†**: ä¼˜åŒ–çš„æ»‘åŠ¨çª—å£å’Œæ‰¹å¤„ç†ç­–ç•¥
- **æµ‹è¯•æ—¶å¢å¼º**: æ”¯æŒTTAæå‡é¢„æµ‹ç²¾åº¦
- **å¤šGPUåŠ é€Ÿ**: æ”¯æŒå¤šGPUå¹¶è¡Œæ¨ç†
- **æ··åˆç²¾åº¦**: æ”¯æŒAMPåŠ é€Ÿæ¨ç†è¿‡ç¨‹
- **çµæ´»è¾“å‡º**: å¤šç§è¾“å‡ºæ ¼å¼å’Œå¯è§†åŒ–é€‰é¡¹
- **è¯¦ç»†æŠ¥å‘Š**: å®Œæ•´çš„æ¨ç†è¿‡ç¨‹å’Œç»“æœåˆ†æ

## æ”¯æŒçš„æ¨¡å‹

é¡¹ç›®æ”¯æŒä»¥ä¸‹7ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼š

1. **UNet** - ç»å…¸çš„Uå‹ç½‘ç»œæ¶æ„
2. **SegResNet** - åŸºäºResNetçš„åˆ†å‰²ç½‘ç»œ
3. **UNETR** - åŸºäºTransformerçš„Uå‹ç½‘ç»œ
4. **SwinUNETR** - åŸºäºSwin Transformerçš„åˆ†å‰²ç½‘ç»œ
5. **AttentionUNet** - å¸¦æ³¨æ„åŠ›æœºåˆ¶çš„Uå‹ç½‘ç»œ
6. **VNet** - 3Då·ç§¯åˆ†å‰²ç½‘ç»œ
7. **HighResNet** - é«˜åˆ†è¾¨ç‡ç½‘ç»œ

## é«˜çº§æ¨¡å‹åŠŸèƒ½

æœ¬é¡¹ç›®æ”¯æŒä¸‰ç§é«˜çº§æ¨¡å‹è®¾è®¡æ–¹æ³•ï¼Œæä¾›æ›´å¼ºå¤§çš„æ¨¡å‹æ€§èƒ½å’Œçµæ´»æ€§ï¼š

- **çŸ¥è¯†è’¸é¦ (Knowledge Distillation)**: ä½¿ç”¨å¤šä¸ªæ•™å¸ˆæ¨¡å‹è®­ç»ƒè½»é‡çº§å­¦ç”Ÿæ¨¡å‹
- **èåˆç½‘ç»œ (Fusion Networks)**: åœ¨ç‰¹å¾çº§åˆ«èåˆå¤šä¸ªä¸åŒæ¶æ„çš„æ¨¡å‹
- **ç¥ç»æ¶æ„æœç´¢ (Neural Architecture Search)**: è‡ªåŠ¨æœç´¢æœ€ä¼˜ç½‘ç»œæ¶æ„

**é»˜è®¤é…ç½®**: æ‰€æœ‰é«˜çº§æ¨¡å‹è®­ç»ƒé»˜è®¤ä½¿ç”¨å…¨éƒ¨7ä¸ªç½‘ç»œæ¶æ„ï¼ˆUNetã€SegResNetã€UNETRã€SwinUNETRã€AttentionUNetã€VNetã€HighResNetï¼‰ï¼Œä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

### çŸ¥è¯†è’¸é¦

#### åŸºæœ¬æ¦‚å¿µ

çŸ¥è¯†è’¸é¦é€šè¿‡è®©å­¦ç”Ÿæ¨¡å‹å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„"è½¯æ ‡ç­¾"æ¥æé«˜æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„è½»é‡åŒ–ã€‚

#### ä½¿ç”¨æ–¹æ³•

```bash
# åŸºæœ¬çŸ¥è¯†è’¸é¦ï¼ˆé»˜è®¤ä½¿ç”¨æ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„ä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼‰
python main.py train \
    --data_dir ./data/training_data \
    --model_category advanced \
    --model_type distillation \
    --student_model UNet \
    --distillation_temperature 4.0 \
    --distillation_alpha 0.7 \
    --epochs 100

# è‡ªå®šä¹‰æ•™å¸ˆæ¨¡å‹
python main.py train \
    --data_dir ./data/training_data \
    --model_category advanced \
    --model_type distillation \
    --teacher_models UNet SegResNet UNETR \
    --student_model UNet \
    --distillation_temperature 4.0 \
    --distillation_alpha 0.7 \
    --epochs 100
```

#### å‚æ•°è¯´æ˜

- `teacher_models`: æ•™å¸ˆæ¨¡å‹åˆ—è¡¨ï¼Œæ”¯æŒå¤šä¸ªæ¨¡å‹
- `student_model`: å­¦ç”Ÿæ¨¡å‹ï¼Œé€šå¸¸é€‰æ‹©è½»é‡çº§æ¨¡å‹
- `distillation_temperature`: è’¸é¦æ¸©åº¦ï¼Œæ§åˆ¶è½¯æ ‡ç­¾çš„å¹³æ»‘ç¨‹åº¦
- `distillation_alpha`: è½¯æ ‡ç­¾æƒé‡ï¼Œå¹³è¡¡è½¯æ ‡ç­¾å’Œç¡¬æ ‡ç­¾çš„é‡è¦æ€§

### èåˆç½‘ç»œ

#### åŸºæœ¬æ¦‚å¿µ

èåˆç½‘ç»œåœ¨ç‰¹å¾çº§åˆ«ç»“åˆå¤šä¸ªä¸åŒæ¶æ„çš„æ¨¡å‹ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å’Œè‡ªé€‚åº”èåˆæé«˜æ€§èƒ½ã€‚

#### ä½¿ç”¨æ–¹æ³•

```bash
# èåˆç½‘ç»œè®­ç»ƒï¼ˆé»˜è®¤ä½¿ç”¨æ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„ï¼‰
python main.py train \
    --data_dir ./data/training_data \
    --model_category advanced \
    --model_type fusion \
    --epochs 200

# è‡ªå®šä¹‰èåˆæ¨¡å‹
python main.py train \
    --data_dir ./data/training_data \
    --model_category advanced \
    --model_type fusion \
    --fusion_models UNet SegResNet AttentionUNet \
    --epochs 200
```

#### ç‰¹æ€§

- **è·¨æ¨¡å‹æ³¨æ„åŠ›**: ä¸åŒæ¨¡å‹ç‰¹å¾ä¹‹é—´çš„äº¤äº’
- **é€šé“æ³¨æ„åŠ›**: é‡è¦ç‰¹å¾é€šé“çš„è‡ªé€‚åº”æƒé‡
- **ç©ºé—´æ³¨æ„åŠ›**: é‡è¦ç©ºé—´ä½ç½®çš„è‡ªé€‚åº”æƒé‡
- **è‡ªé€‚åº”èåˆé—¨**: åŠ¨æ€è°ƒæ•´ä¸åŒæ¨¡å‹çš„è´¡çŒ®

### ç¥ç»æ¶æ„æœç´¢

#### åŸºæœ¬æ¦‚å¿µ

NASé€šè¿‡è‡ªåŠ¨æœç´¢æœ€ä¼˜çš„ç½‘ç»œæ¶æ„ï¼Œå‡å°‘äººå·¥è®¾è®¡çš„éœ€è¦ã€‚æœ¬å®ç°åŸºäºDARTSç®—æ³•ã€‚

#### ä½¿ç”¨æ–¹æ³•

```bash
# NASæœç´¢
python main.py train \
    --data_dir ./data/training_data \
    --model_category advanced \
    --model_type nas \
    --nas_epochs 50 \
    --batch_size 1 \
    --epochs 300
```

#### æœç´¢è¿‡ç¨‹

1. **æ¶æ„æœç´¢é˜¶æ®µ**: ä¼˜åŒ–æ¶æ„å‚æ•°
2. **æ¨¡å‹è®­ç»ƒé˜¶æ®µ**: ä½¿ç”¨æ‰¾åˆ°çš„æœ€ä¼˜æ¶æ„è®­ç»ƒæ¨¡å‹
3. **æ¸è¿›å¼æœç´¢**: é€æ­¥å¢åŠ æœç´¢å¤æ‚åº¦

### é«˜çº§æ¨¡å‹å‘½ä»¤è¡Œå‚æ•°

```bash
# æ¨¡å‹ç±»åˆ«å’Œç±»å‹
--model_category {basic,advanced}     # æ¨¡å‹ç±»åˆ«
--model_type {single,fusion,distillation,nas}  # é«˜çº§æ¨¡å‹ç±»å‹

# çŸ¥è¯†è’¸é¦å‚æ•°
--teacher_models MODEL1 MODEL2 ...    # æ•™å¸ˆæ¨¡å‹åˆ—è¡¨
--student_model MODEL                  # å­¦ç”Ÿæ¨¡å‹
--distillation_temperature FLOAT      # è’¸é¦æ¸©åº¦
--distillation_alpha FLOAT            # è½¯æ ‡ç­¾æƒé‡

# èåˆç½‘ç»œå‚æ•°
--fusion_models MODEL1 MODEL2 ...     # èåˆæ¨¡å‹åˆ—è¡¨

# NASå‚æ•°
--nas_epochs INT                       # NASæœç´¢è½®æ•°
```

### é«˜çº§æ¨¡å‹é…ç½®ç¤ºä¾‹

#### çŸ¥è¯†è’¸é¦é…ç½®

```python
distillation_config = {
    # é»˜è®¤ä½¿ç”¨æ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„ä½œä¸ºæ•™å¸ˆæ¨¡å‹
    'teacher_models': ['UNet', 'SegResNet', 'UNETR', 'SwinUNETR', 'AttentionUNet', 'VNet', 'HighResNet'],
    'student_model': 'UNet',                           # å­¦ç”Ÿæ¨¡å‹
    'distillation_temperature': 4.0,                   # è’¸é¦æ¸©åº¦
    'distillation_alpha': 0.7,                         # è½¯æ ‡ç­¾æƒé‡
    'progressive_stages': 3,                            # æ¸è¿›å¼é˜¶æ®µæ•°
    'stage_epochs': [30, 30, 40]                       # æ¯é˜¶æ®µè®­ç»ƒè½®æ•°
}
```

#### èåˆç½‘ç»œé…ç½®

```python
fusion_config = {
    # é»˜è®¤ä½¿ç”¨æ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„è¿›è¡Œèåˆ
    'fusion_models': ['UNet', 'SegResNet', 'UNETR', 'SwinUNETR', 'AttentionUNet', 'VNet', 'HighResNet'],
    'fusion_dim': 256,                                         # èåˆç‰¹å¾ç»´åº¦
    'attention_heads': 8,                                      # æ³¨æ„åŠ›å¤´æ•°
    'dropout_rate': 0.1,                                       # Dropoutç‡
    'use_cross_attention': True,                               # ä½¿ç”¨è·¨æ¨¡å‹æ³¨æ„åŠ›
    'use_channel_attention': True,                             # ä½¿ç”¨é€šé“æ³¨æ„åŠ›
    'use_spatial_attention': True                              # ä½¿ç”¨ç©ºé—´æ³¨æ„åŠ›
}
```

#### NASé…ç½®

```python
nas_config = {
    'nas_epochs': 50,                    # æ¶æ„æœç´¢è½®æ•°
    'search_space': 'darts',             # æœç´¢ç©ºé—´ç±»å‹
    'arch_lr': 3e-4,                     # æ¶æ„å­¦ä¹ ç‡
    'model_lr': 2e-4,                    # æ¨¡å‹å­¦ä¹ ç‡
    'progressive_stages': 3,             # æ¸è¿›å¼æœç´¢é˜¶æ®µ
    'operations': [                      # å€™é€‰æ“ä½œ
        'conv_3x3', 'conv_5x5', 'dilated_conv',
        'attention', 'skip_connect', 'pool'
    ]
}
```

### é«˜çº§æ¨¡å‹æ³¨æ„äº‹é¡¹

#### ç¡¬ä»¶è¦æ±‚

- **GPUå†…å­˜**: é«˜çº§æ¨¡å‹éœ€è¦æ›´å¤šGPUå†…å­˜ï¼Œå»ºè®®è‡³å°‘8GB
- **è®­ç»ƒæ—¶é—´**: æ¯”åŸºç¡€æ¨¡å‹éœ€è¦æ›´é•¿çš„è®­ç»ƒæ—¶é—´
- **CPUæ¨¡å¼**: å¯ä»¥è¿è¡Œä½†é€Ÿåº¦è¾ƒæ…¢

#### æ€§èƒ½ä¼˜åŒ–

1. **æ‰¹æ¬¡å¤§å°**: æ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼Œé«˜çº§æ¨¡å‹å»ºè®®ä½¿ç”¨è¾ƒå°æ‰¹æ¬¡
2. **æ··åˆç²¾åº¦**: å¯ç”¨AMPå¯ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
3. **æ¢¯åº¦ç´¯ç§¯**: åœ¨å°æ‰¹æ¬¡æ—¶ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

#### æœ€ä½³å®è·µ

1. **çŸ¥è¯†è’¸é¦**: 
   - é»˜è®¤ä½¿ç”¨æ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„ä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼Œè·å¾—æœ€ä½³çŸ¥è¯†è½¬ç§»æ•ˆæœ
   - å…ˆè®­ç»ƒå¥½æ•™å¸ˆæ¨¡å‹ï¼Œå†è¿›è¡Œè’¸é¦
   - å¯æ ¹æ®èµ„æºé™åˆ¶è‡ªå®šä¹‰æ•™å¸ˆæ¨¡å‹æ•°é‡

2. **èåˆç½‘ç»œ**: 
   - é»˜è®¤èåˆæ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„ï¼Œå……åˆ†åˆ©ç”¨ä¸åŒæ¨¡å‹çš„ä¼˜åŠ¿
   - é€‰æ‹©äº’è¡¥æ€§å¼ºçš„åŸºç¡€æ¨¡å‹å¯è¿›ä¸€æ­¥æå‡æ€§èƒ½
   - æ³¨æ„GPUå†…å­˜ä½¿ç”¨ï¼Œå¿…è¦æ—¶å‡å°‘èåˆæ¨¡å‹æ•°é‡

3. **NAS**: 
   - ä»å°è§„æ¨¡æœç´¢ç©ºé—´å¼€å§‹ï¼Œé€æ­¥æ‰©å¤§
   - åˆ©ç”¨æ¸è¿›å¼æœç´¢ç­–ç•¥æé«˜æ•ˆç‡

## è¯„ä¼°æŒ‡æ ‡

é¡¹ç›®å†…ç½®äº†å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡ä½“ç³»ï¼Œ**æ‰€æœ‰æ¨¡å‹åœ¨è®­ç»ƒã€è¯„ä¼°å’Œéƒ¨ç½²é˜¶æ®µéƒ½ç»Ÿä¸€ä½¿ç”¨å®Œæ•´çš„6ç§è¯„ä¼°æŒ‡æ ‡**ï¼š

### æ ¸å¿ƒåˆ†å‰²æŒ‡æ ‡
- **Diceç³»æ•°** - è¡¡é‡åˆ†å‰²é‡å åº¦ï¼ŒèŒƒå›´[0,1]ï¼Œè¶Šé«˜è¶Šå¥½
- **å¹³å‡IoU (Intersection over Union)** - äº¤å¹¶æ¯”æŒ‡æ ‡ï¼Œè¡¡é‡åˆ†å‰²å‡†ç¡®æ€§
- **å¹¿ä¹‰Diceåˆ†æ•°** - åŠ æƒDiceæŒ‡æ ‡ï¼Œå¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜

### è¾¹ç•Œå’Œå½¢çŠ¶æŒ‡æ ‡
- **Hausdorffè·ç¦»** - è¡¡é‡è¾¹ç•Œå‡†ç¡®æ€§ï¼Œè·ç¦»è¶Šå°è¶Šå¥½
- **è¡¨é¢è·ç¦»** - è¡¡é‡è¡¨é¢é‡å»ºè´¨é‡å’Œè¾¹ç•Œå¹³æ»‘åº¦

### åˆ†ç±»æ€§èƒ½æŒ‡æ ‡
- **æ··æ·†çŸ©é˜µæŒ‡æ ‡** - è¯¦ç»†çš„åˆ†ç±»æ€§èƒ½åˆ†æï¼ŒåŒ…æ‹¬ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°ç­‰

### ç»Ÿä¸€è¯„ä¼°ç­–ç•¥
- **è‡ªåŠ¨è®¡ç®—** - è®­ç»ƒè¿‡ç¨‹ä¸­å®æ—¶è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
- **å¤šç±»åˆ«æ”¯æŒ** - æ”¯æŒèƒŒæ™¯ã€åæ­»æ ¸å¿ƒã€æ°´è‚¿åŒºåŸŸã€å¢å¼ºè‚¿ç˜¤ç­‰å¤šç±»åˆ«è¯„ä¼°
- **ç»Ÿè®¡åˆ†æ** - æä¾›å‡å€¼ã€æ ‡å‡†å·®ã€æœ€å€¼ç­‰ç»Ÿè®¡ä¿¡æ¯
- **å¯è§†åŒ–å±•ç¤º** - ç”ŸæˆæŒ‡æ ‡è¶‹åŠ¿å›¾å’Œåˆ†å¸ƒå›¾

## å‘½ä»¤è¡Œå‚æ•°è¯¦è§£

### åŸºæœ¬å‚æ•°

- `--mode` - è¿è¡Œæ¨¡å¼ï¼Œå¯é€‰å€¼ï¼š`train`ï¼ˆè®­ç»ƒï¼‰ã€`eval`ï¼ˆè¯„ä¼°ï¼‰
- `--data_dir` - BraTSæ•°æ®é›†è·¯å¾„
- `--device` - è®¡ç®—è®¾å¤‡ï¼Œå¯é€‰å€¼ï¼š`auto`ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰ã€`cpu`ã€`cuda`

### è®­ç»ƒå‚æ•°

#### åŸºç¡€è®­ç»ƒå‚æ•°

- `--model_name` - å•ä¸ªæ¨¡å‹åç§°ï¼ˆUNetã€SegResNetã€UNETRç­‰ï¼‰
- `--model_names` - å¤šä¸ªæ¨¡å‹åç§°åˆ—è¡¨

- `--epochs` - è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤ï¼š50ï¼‰
- `--batch_size` - æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ï¼šè‡ªåŠ¨è°ƒæ•´ï¼‰
- `--learning_rate` - å­¦ä¹ ç‡ï¼ˆé»˜è®¤ï¼š1e-4ï¼‰
- `--output_dir` - è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼š./outputsï¼‰

#### é«˜çº§æ¨¡å‹å‚æ•°

- `--model_category` - æ¨¡å‹ç±»åˆ«ï¼Œå¯é€‰å€¼ï¼š`basic`ï¼ˆåŸºç¡€æ¨¡å‹ï¼‰ã€`advanced`ï¼ˆé«˜çº§æ¨¡å‹ï¼‰
- `--model_type` - é«˜çº§æ¨¡å‹ç±»å‹ï¼Œå¯é€‰å€¼ï¼š`single`ã€`fusion`ã€`distillation`ã€`nas`

##### çŸ¥è¯†è’¸é¦å‚æ•°

- `--teacher_models` - æ•™å¸ˆæ¨¡å‹åˆ—è¡¨ï¼ˆé»˜è®¤ï¼šæ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„ï¼‰
- `--student_model` - å­¦ç”Ÿæ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šUNetï¼‰
- `--distillation_temperature` - è’¸é¦æ¸©åº¦ï¼ˆé»˜è®¤ï¼š4.0ï¼‰
- `--distillation_alpha` - è½¯æ ‡ç­¾æƒé‡ï¼ˆé»˜è®¤ï¼š0.7ï¼‰

##### èåˆç½‘ç»œå‚æ•°

- `--fusion_models` - èåˆæ¨¡å‹åˆ—è¡¨ï¼ˆé»˜è®¤ï¼šæ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„ï¼‰

##### NASå‚æ•°

- `--nas_epochs` - NASæœç´¢è½®æ•°ï¼ˆé»˜è®¤ï¼š50ï¼‰

### è¯„ä¼°å‚æ•°

- `--model_path` - æ¨¡å‹æ–‡ä»¶è·¯å¾„
- `--output_dir` - è¯„ä¼°ç»“æœè¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼š./evaluation_resultsï¼‰

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€è®­ç»ƒ

```bash
# è®­ç»ƒå•ä¸ªUNetæ¨¡å‹
python main.py --mode train --model_name UNet --data_dir /path/to/BraTS --epochs 100

# è®­ç»ƒSegResNetæ¨¡å‹ï¼Œä½¿ç”¨GPU
python main.py --mode train --model_name SegResNet --device cuda --epochs 150 --batch_size 2

# è®­ç»ƒUNETRæ¨¡å‹ï¼Œè‡ªå®šä¹‰å­¦ä¹ ç‡
python main.py --mode train --model_name UNETR --learning_rate 5e-5 --epochs 200
```

### å¤šæ¨¡å‹è®­ç»ƒ

```bash
# é¡ºåºè®­ç»ƒå¤šä¸ªæ¨¡å‹
python main.py --mode train --model_names UNet SegResNet AttentionUNet --epochs 50

# è®­ç»ƒæ‰€æœ‰æ”¯æŒçš„æ¨¡å‹
python main.py --mode train --model_names UNet SegResNet UNETR SwinUNETR AttentionUNet VNet HighResNet --epochs 30
```



### é«˜çº§æ¨¡å‹è®­ç»ƒ

#### çŸ¥è¯†è’¸é¦è®­ç»ƒ

```bash
# åŸºæœ¬çŸ¥è¯†è’¸é¦ï¼ˆé»˜è®¤ä½¿ç”¨æ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„ä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼‰
python main.py --mode train \
    --data_dir /path/to/BraTS \
    --model_category advanced \
    --model_type distillation \
    --student_model UNet \
    --epochs 100

# è‡ªå®šä¹‰æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†è’¸é¦
python main.py --mode train \
    --data_dir /path/to/BraTS \
    --model_category advanced \
    --model_type distillation \
    --teacher_models UNet SegResNet UNETR \
    --student_model UNet \
    --distillation_temperature 4.0 \
    --distillation_alpha 0.7 \
    --epochs 100
```

#### èåˆç½‘ç»œè®­ç»ƒ

```bash
# èåˆç½‘ç»œè®­ç»ƒï¼ˆé»˜è®¤ä½¿ç”¨æ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„ï¼‰
python main.py --mode train \
    --data_dir /path/to/BraTS \
    --model_category advanced \
    --model_type fusion \
    --epochs 200

# è‡ªå®šä¹‰èåˆæ¨¡å‹
python main.py --mode train \
    --data_dir /path/to/BraTS \
    --model_category advanced \
    --model_type fusion \
    --fusion_models UNet SegResNet AttentionUNet \
    --epochs 200
```

#### ç¥ç»æ¶æ„æœç´¢è®­ç»ƒ

```bash
# NASæœç´¢è®­ç»ƒ
python main.py --mode train \
    --data_dir /path/to/BraTS \
    --model_category advanced \
    --model_type nas \
    --nas_epochs 50 \
    --batch_size 1 \
    --epochs 300

# è‡ªå®šä¹‰NASå‚æ•°
python main.py --mode train \
    --data_dir /path/to/BraTS \
    --model_category advanced \
    --model_type nas \
    --nas_epochs 100 \
    --batch_size 1 \
    --epochs 500 \
    --learning_rate 2e-4
```

### æ¨¡å‹è¯„ä¼°

```bash
# åŸºç¡€è¯„ä¼°
python main.py --mode eval --model_path ./outputs/checkpoints/best_model.pth --data_dir /path/to/BraTS

# è¯„ä¼°é«˜çº§æ¨¡å‹
python main.py --mode eval --model_path ./outputs/checkpoints/best_model.pth --data_dir /path/to/BraTS

# æŒ‡å®šè¾“å‡ºç›®å½•è¯„ä¼°
python main.py --mode eval --model_path ./outputs/checkpoints/best_model.pth --data_dir /path/to/BraTS --output_dir ./my_evaluation
```

### æ¨¡å‹æ¨ç†

```bash
# å•ä¸ªæ–‡ä»¶æ¨ç†
python main.py --mode inference \
    --model_path outputs/checkpoints/best_model.pth \
    --input data/test_case.nii.gz \
    --output results/prediction.nii.gz

# æ‰¹é‡æ¨ç†
python main.py --mode inference \
    --model_path outputs/checkpoints/best_model.pth \
    --input data/test_cases/ \
    --output results/ \
    --batch_inference

# é«˜çº§æ¨ç†é…ç½®
python main.py --mode inference \
    --model_path outputs/checkpoints/best_model.pth \
    --input data/test.nii.gz \
    --output results/pred.nii.gz \
    --device cuda \
    --roi_size 128 128 128 \
    --sw_batch_size 4 \
    --overlap 0.5

# GPUåŠ é€Ÿæ¨ç†
python main.py --mode inference \
    --device cuda \
    --sw_batch_size 8 \
    --model_path outputs/checkpoints/best_model.pth \
    --input data/test.nii.gz \
    --output results/prediction.nii.gz

# æ‰¹é‡å¤„ç†ä¼˜åŒ–ï¼ˆç¦ç”¨å¯è§†åŒ–ï¼‰
python main.py --mode inference \
    --batch_inference \
    --no_visualization \
    --model_path outputs/checkpoints/best_model.pth \
    --input data/test_cases/ \
    --output results/
```

## é¡¹ç›®ç‰¹æ€§

### ğŸ¯ ç»Ÿä¸€ç­–ç•¥æ¶æ„

- **å…¨æµç¨‹ä¸€è‡´æ€§** - è®­ç»ƒã€è¯„ä¼°ã€éƒ¨ç½²ä½¿ç”¨ç»Ÿä¸€çš„æŸå¤±å‡½æ•°å’Œè¯„ä¼°æŒ‡æ ‡
- **è‡ªé€‚åº”æŸå¤±å‡½æ•°** - æ™ºèƒ½ç»„åˆå¤šç§æŸå¤±å‡½æ•°ï¼ŒåŠ¨æ€è°ƒæ•´æƒé‡
- **å®Œæ•´è¯„ä¼°ä½“ç³»** - ç»Ÿä¸€ä½¿ç”¨6ç§è¯„ä¼°æŒ‡æ ‡ï¼Œå…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½
- **é…ç½®ç»Ÿä¸€ç®¡ç†** - æ‰€æœ‰æ¨¡å‹å®ä¾‹è‡ªåŠ¨åº”ç”¨ç»Ÿä¸€ç­–ç•¥é…ç½®

### ğŸš€ é«˜æ€§èƒ½ä¼˜åŒ–

- **è‡ªåŠ¨è®¾å¤‡æ£€æµ‹** - æ™ºèƒ½é€‰æ‹©CPUæˆ–GPU
- **å†…å­˜ä¼˜åŒ–** - æ ¹æ®è®¾å¤‡è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°å’Œç¼“å­˜ç­–ç•¥
- **å¤šè¿›ç¨‹æ•°æ®åŠ è½½** - åŠ é€Ÿæ•°æ®é¢„å¤„ç†
- **æ»‘åŠ¨çª—å£æ¨ç†** - æ”¯æŒå¤§å°ºå¯¸å›¾åƒåˆ†å‰²

### ğŸ¯ æ™ºèƒ½è®­ç»ƒ

- **è‡ªé€‚åº”å­¦ä¹ ç‡** - ä½¿ç”¨ä½™å¼¦é€€ç«è°ƒåº¦å™¨
- **åŠ¨æ€æŸå¤±è°ƒæ•´** - æ ¹æ®è®­ç»ƒè¿›åº¦è‡ªåŠ¨è°ƒæ•´æŸå¤±å‡½æ•°æƒé‡
- **æ—©åœæœºåˆ¶** - é˜²æ­¢è¿‡æ‹Ÿåˆ
- **æ¨¡å‹æ£€æŸ¥ç‚¹** - è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- **è®­ç»ƒç›‘æ§** - å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦å’Œæ‰€æœ‰è¯„ä¼°æŒ‡æ ‡

### ğŸ“Š å…¨é¢è¯„ä¼°

- **ç»Ÿä¸€è¯„ä¼°æ ‡å‡†** - æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç›¸åŒçš„6ç§è¯„ä¼°æŒ‡æ ‡
- **å¤šç»´åº¦åˆ†æ** - ä»åˆ†å‰²ç²¾åº¦ã€è¾¹ç•Œè´¨é‡ã€åˆ†ç±»æ€§èƒ½ç­‰å¤šè§’åº¦è¯„ä¼°
- **å¯è§†åŒ–ç»“æœ** - ç”Ÿæˆåˆ†å‰²ç»“æœå¯¹æ¯”å›¾å’ŒæŒ‡æ ‡è¶‹åŠ¿å›¾
- **è¯¦ç»†æŠ¥å‘Š** - è¾“å‡ºå®Œæ•´çš„è¯„ä¼°æŠ¥å‘Šå’Œç»Ÿè®¡åˆ†æ
- **æ€§èƒ½å¯¹æ¯”** - æ”¯æŒå¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ

### ğŸ”§ æ˜“ç”¨æ€§

- **ä¸€é”®è®­ç»ƒ** - ç®€å•çš„å‘½ä»¤è¡Œæ¥å£ï¼Œè‡ªåŠ¨åº”ç”¨æœ€ä½³é…ç½®
- **æ™ºèƒ½é…ç½®** - è‡ªåŠ¨åº”ç”¨ç»Ÿä¸€ç­–ç•¥ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®
- **é”™è¯¯å¤„ç†** - å‹å¥½çš„é”™è¯¯æç¤ºå’Œé…ç½®éªŒè¯
- **è¿›åº¦æ˜¾ç¤º** - æ¸…æ™°çš„è®­ç»ƒå’Œè¯„ä¼°è¿›åº¦ï¼Œå®æ—¶æŒ‡æ ‡ç›‘æ§

## è¾“å‡ºç»“æœ

### è®­ç»ƒè¾“å‡º

è®­ç»ƒå®Œæˆåï¼Œä¼šåœ¨è¾“å‡ºç›®å½•ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
outputs/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ best_model.pth              # æœ€ä½³æ¨¡å‹æƒé‡
â”‚   â””â”€â”€ latest_model.pth            # æœ€æ–°æ¨¡å‹æƒé‡
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ tensorboard/                # TensorBoardæ—¥å¿—
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ training_history.json       # è®­ç»ƒå†å²è®°å½•
â”‚   â””â”€â”€ training_curves.png         # è®­ç»ƒæ›²çº¿å›¾
â””â”€â”€ visualizations/
    â””â”€â”€ sample_predictions.png      # æ ·æœ¬é¢„æµ‹å¯è§†åŒ–
```

### è¯„ä¼°è¾“å‡º

è¯„ä¼°å®Œæˆåï¼Œä¼šç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šï¼š

```
evaluation_results/
â”œâ”€â”€ case_results.csv           # æ¯ä¸ªæ¡ˆä¾‹çš„è¯¦ç»†ç»“æœ
â”œâ”€â”€ summary_results.txt        # æ€»ä½“ç»Ÿè®¡ç»“æœ
â”œâ”€â”€ results_distribution.png   # ç»“æœåˆ†å¸ƒå›¾
â””â”€â”€ visualizations/
    â”œâ”€â”€ case_001_prediction.png
    â”œâ”€â”€ case_002_prediction.png
    â””â”€â”€ ...
```

## æ•°æ®æ ¼å¼è¦æ±‚

BraTSæ•°æ®é›†åº”æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡ï¼š

```
BraTS_data/
â”œâ”€â”€ BraTS-GLI-00000-000/
â”‚   â”œâ”€â”€ BraTS-GLI-00000-000-t1n.nii.gz    # T1 native
â”‚   â”œâ”€â”€ BraTS-GLI-00000-000-t1c.nii.gz    # T1 contrast-enhanced
â”‚   â”œâ”€â”€ BraTS-GLI-00000-000-t2w.nii.gz    # T2 weighted
â”‚   â”œâ”€â”€ BraTS-GLI-00000-000-t2f.nii.gz    # T2 FLAIR
â”‚   â””â”€â”€ BraTS-GLI-00000-000-seg.nii.gz    # åˆ†å‰²æ ‡æ³¨ï¼ˆè®­ç»ƒæ—¶éœ€è¦ï¼‰
â”œâ”€â”€ BraTS-GLI-00001-000/
â”‚   â”œâ”€â”€ BraTS-GLI-00001-000-t1n.nii.gz
â”‚   â”œâ”€â”€ BraTS-GLI-00001-000-t1c.nii.gz
â”‚   â”œâ”€â”€ BraTS-GLI-00001-000-t2w.nii.gz
â”‚   â”œâ”€â”€ BraTS-GLI-00001-000-t2f.nii.gz
â”‚   â””â”€â”€ BraTS-GLI-00001-000-seg.nii.gz
â””â”€â”€ ...
```

**æ³¨æ„**: 
- æ¯ä¸ªæ¡ˆä¾‹ç›®å½•åç§°åº”ä¸æ–‡ä»¶å‰ç¼€ä¿æŒä¸€è‡´
- æ”¯æŒçš„æ¨¡æ€ï¼št1nï¼ˆT1 nativeï¼‰ã€t1cï¼ˆT1 contrast-enhancedï¼‰ã€t2wï¼ˆT2 weightedï¼‰ã€t2fï¼ˆT2 FLAIRï¼‰
- åˆ†å‰²æ–‡ä»¶ï¼ˆseg.nii.gzï¼‰åœ¨è®­ç»ƒæ—¶å¿…éœ€ï¼Œè¯„ä¼°æ—¶å¯é€‰

## ğŸ”§ ç»Ÿä¸€ç­–ç•¥æŠ€æœ¯å®ç°

### ğŸ¯ è‡ªé€‚åº”æŸå¤±å‡½æ•°ç­–ç•¥

é¡¹ç›®å®ç°äº†æ™ºèƒ½çš„è‡ªé€‚åº”æŸå¤±å‡½æ•°ç»„åˆç­–ç•¥ï¼Œç¡®ä¿æ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨æœ€ä¼˜çš„æŸå¤±å‡½æ•°é…ç½®ï¼š

#### æŸå¤±å‡½æ•°ç»„åˆ (å®Œæ•´å®ç°)
```python
# è‡ªé€‚åº”æŸå¤±å‡½æ•°è°ƒåº¦å™¨ (AdaptiveLossScheduler)
class AdaptiveLossScheduler:
    def __init__(self, parent):
        self.losses = {
            'dice_ce': DiceCELoss(to_onehot_y=True, softmax=True, reduction="mean", include_background=True),
            'focal': FocalLoss(to_onehot_y=True, gamma=2.0, reduction="mean", include_background=True),
            'tversky': TverskyLoss(to_onehot_y=True, softmax=True, alpha=0.3, beta=0.7, reduction="mean", include_background=True),
            'generalized_dice': GeneralizedDiceLoss(to_onehot_y=True, softmax=True, reduction="mean", include_background=True),
            'dice_focal': DiceFocalLoss(to_onehot_y=True, softmax=True, gamma=2.0, reduction="mean", include_background=True)
        }
        self.current_epoch = 0
        self.total_epochs = 100
        
    def set_epoch(self, epoch, total_epochs=None):
        """æ›´æ–°å½“å‰è®­ç»ƒè¿›åº¦"""
        self.current_epoch = epoch
        if total_epochs is not None:
            self.total_epochs = total_epochs
            
    def __call__(self, pred, target):
        """æ ¹æ®è®­ç»ƒè¿›åº¦è®¡ç®—åŠ æƒæŸå¤±"""
        progress = self.current_epoch / self.total_epochs if self.total_epochs > 0 else 0
        weights = self._calculate_adaptive_weights(progress)
        
        total_loss = 0
        for name, weight in weights.items():
            if weight > 0:
                total_loss += weight * self.losses[name](pred, target)
        return total_loss
```

#### åŠ¨æ€æƒé‡è°ƒæ•´ (5é˜¶æ®µç­–ç•¥)
- **å‰20%è®­ç»ƒ** (progress < 0.2): ä¸»è¦ä½¿ç”¨DiceCEï¼Œæƒé‡ {dice_ce: 0.7, focal: 0.2, tversky: 0.1, others: 0.0}
- **20%-40%è®­ç»ƒ** (0.2 â‰¤ progress < 0.4): å¢åŠ Focalæƒé‡ï¼Œ{dice_ce: 0.5, focal: 0.3, tversky: 0.1, generalized_dice: 0.1, dice_focal: 0.0}
- **40%-60%è®­ç»ƒ** (0.4 â‰¤ progress < 0.6): å¹³è¡¡å„æŸå¤±ï¼Œ{dice_ce: 0.3, focal: 0.3, tversky: 0.2, generalized_dice: 0.1, dice_focal: 0.1}
- **60%-80%è®­ç»ƒ** (0.6 â‰¤ progress < 0.8): å¢åŠ Tverskyæƒé‡ï¼Œ{dice_ce: 0.2, focal: 0.2, tversky: 0.4, generalized_dice: 0.1, dice_focal: 0.1}
- **æœ€å20%è®­ç»ƒ** (progress â‰¥ 0.8): ç»„åˆæ‰€æœ‰æŸå¤±ï¼Œ{dice_ce: 0.2, focal: 0.2, tversky: 0.2, generalized_dice: 0.2, dice_focal: 0.2}

#### è‡ªåŠ¨æ›´æ–°æœºåˆ¶
```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­è‡ªåŠ¨è°ƒç”¨
if hasattr(self.model_creator, 'update_loss_epoch'):
    self.model_creator.update_loss_epoch(epoch, max_epochs)
elif hasattr(self.advanced_model, 'update_loss_epoch'):
    self.advanced_model.update_loss_epoch(epoch, max_epochs)
```

### ğŸ“Š å®Œæ•´è¯„ä¼°æŒ‡æ ‡ä½“ç³»

æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€ä½¿ç”¨6ç§è¯„ä¼°æŒ‡æ ‡ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œä¸€è‡´æ€§ï¼Œåœ¨è®­ç»ƒã€è¯„ä¼°ã€æ¨ç†å…¨æµç¨‹ä¸­åº”ç”¨ï¼š

#### æŒ‡æ ‡é…ç½®è¯¦æƒ…
```python
metrics = {
    # åŸºç¡€åˆ†å‰²æŒ‡æ ‡
    'dice': DiceMetric(
        include_background=False,
        reduction="mean_batch",
        get_not_nans=False
    ),
    'hausdorff': HausdorffDistanceMetric(
        include_background=False,
        distance_metric='euclidean',
        percentile=95,
        directed=False,
        reduction="mean_batch"
    ),
    # é«˜çº§å‡ ä½•æŒ‡æ ‡
    'surface_distance': SurfaceDistanceMetric(
        include_background=False,
        symmetric=True,
        reduction="mean_batch"
    ),
    'confusion_matrix': ConfusionMatrixMetric(
        include_background=False,
        metric_name="sensitivity",
        compute_sample=True,
        reduction="mean_batch"
    ),
    'mean_iou': MeanIoU(
        include_background=False,
        reduction="mean_batch"
    ),
    'generalized_dice_score': GeneralizedDiceScore(
        include_background=False,
        reduction="mean_batch"
    )
}
```

#### æŒ‡æ ‡åº”ç”¨åœºæ™¯
- **è®­ç»ƒç›‘æ§**: æ¯ä¸ªbatchè®¡ç®—DiceæŒ‡æ ‡ï¼Œå®æ—¶ç›‘æ§è®­ç»ƒæ•ˆæœ
- **æ¨¡å‹è¯„ä¼°**: å…¨é¢è®¡ç®—æ‰€æœ‰6ç§æŒ‡æ ‡ï¼Œç”Ÿæˆè¯¦ç»†è¯„ä¼°æŠ¥å‘Š
- **æ¡ˆä¾‹åˆ†æ**: é€æ¡ˆä¾‹è®¡ç®—æŒ‡æ ‡ï¼Œæ”¯æŒç»Ÿè®¡åˆ†æï¼ˆå‡å€¼ã€æ ‡å‡†å·®ã€ä¸­ä½æ•°ï¼‰
- **æ€§èƒ½å¯¹æ¯”**: å¤šæ¨¡å‹é—´çš„æ ‡å‡†åŒ–æ€§èƒ½æ¯”è¾ƒ

### ç»Ÿä¸€é…ç½®ç®¡ç†

#### å…¨å±€é…ç½®å‡½æ•°
- `get_high_performance_config()`: è¿”å›åŒ…å«ç»Ÿä¸€ç­–ç•¥çš„é…ç½®
- æ‰€æœ‰æ¨¡å‹å®ä¾‹è‡ªåŠ¨åº”ç”¨ `use_adaptive_loss=True` å’Œ `use_full_metrics=True`
- è®­ç»ƒã€è¯„ä¼°ã€éƒ¨ç½²é˜¶æ®µé…ç½®å®Œå…¨ä¸€è‡´

#### é…ç½®éªŒè¯
- è‡ªåŠ¨éªŒè¯æŸå¤±å‡½æ•°å’Œè¯„ä¼°æŒ‡æ ‡é…ç½®
- ç¡®ä¿æ‰€æœ‰æ¨¡å‹å®ä¾‹ä½¿ç”¨ç»Ÿä¸€ç­–ç•¥
- æä¾›è¯¦ç»†çš„é…ç½®æ—¥å¿—è¾“å‡º

### æŠ€æœ¯ä¼˜åŠ¿

1. **æ€§èƒ½ä¸€è‡´æ€§**: æ¶ˆé™¤è®­ç»ƒ-è¯„ä¼°-éƒ¨ç½²é˜¶æ®µçš„æ€§èƒ½å·®å¼‚
2. **æ™ºèƒ½ä¼˜åŒ–**: è‡ªé€‚åº”æŸå¤±å‡½æ•°æ ¹æ®è®­ç»ƒè¿›åº¦åŠ¨æ€ä¼˜åŒ–
3. **å…¨é¢è¯„ä¼°**: 6ç§æŒ‡æ ‡ä»å¤šä¸ªç»´åº¦å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½
4. **æ˜“äºç»´æŠ¤**: ç»Ÿä¸€é…ç½®ç®¡ç†ï¼Œå‡å°‘é…ç½®é”™è¯¯å’Œä¸ä¸€è‡´
5. **å¯æ‰©å±•æ€§**: æ–°å¢æ¨¡å‹è‡ªåŠ¨ç»§æ‰¿ç»Ÿä¸€ç­–ç•¥é…ç½®

## è¯¦ç»†æ–‡ä»¶è¯´æ˜

### main.py - ä¸»ç¨‹åºå…¥å£

è¿™æ˜¯é¡¹ç›®çš„ä¸»è¦å…¥å£æ–‡ä»¶ï¼Œè´Ÿè´£è§£æå‘½ä»¤è¡Œå‚æ•°ã€é…ç½®ç®¡ç†å’Œè°ƒç”¨ç›¸åº”çš„è®­ç»ƒæˆ–è¯„ä¼°åŠŸèƒ½ã€‚

#### ä¸»è¦å‡½æ•°è¯¦è§£ï¼š

**ç¬¬1-20è¡Œï¼šå¯¼å…¥å’Œæ–‡æ¡£è¯´æ˜**
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BraTSè„‘è‚¿ç˜¤åˆ†å‰²é¡¹ç›®ä¸»ç¨‹åº

è¿™æ˜¯ä¸€ä¸ªåŸºäºMONAIæ¡†æ¶çš„BraTSè„‘è‚¿ç˜¤åˆ†å‰²é¡¹ç›®ï¼Œæ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚
é¡¹ç›®æä¾›äº†å®Œæ•´çš„æ•°æ®å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œå¯è§†åŒ–åŠŸèƒ½ã€‚

ä½¿ç”¨ç¤ºä¾‹:
    python main.py --mode train --data_dir /path/to/dataset
    python main.py --mode eval --model_path /path/to/model.pth --data_dir /path/to/dataset
    python main.py --mode train --model_name UNet --epochs 100 --batch_size 4
    python main.py --mode train --model_name UNet --epochs 200

ä½œè€…: ä¸ªäººä½¿ç”¨ç‰ˆæœ¬
ç‰ˆæœ¬: 3.1.0
"""
```

**ç¬¬21-35è¡Œï¼šæ¨¡å—å¯¼å…¥**
```python
import os
import sys
import argparse
import torch
from pathlib import Path
from typing import Dict, Any, List

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from train import ModelTrainer
from evaluate import BraTSEvaluator
from model import get_all_supported_models
from utils import format_time
```
- å¯¼å…¥æ ‡å‡†åº“å’Œç¬¬ä¸‰æ–¹åº“
- å¯¼å…¥é¡¹ç›®è‡ªå®šä¹‰æ¨¡å—ï¼šè®­ç»ƒå™¨ã€è¯„ä¼°å™¨ã€æ¨¡å‹å·¥å…·å’Œå®ç”¨å‡½æ•°

**ç¬¬36-85è¡Œï¼šget_high_performance_configå‡½æ•°**
```python
def get_high_performance_config(device_type: str = "auto") -> Dict[str, Any]:
    """
    è·å–é«˜æ€§èƒ½é…ç½®
    
    Args:
        device_type: è®¾å¤‡ç±»å‹ ('cpu', 'cuda', 'auto')
        
    Returns:
        é…ç½®å­—å…¸
    """
```
- æ ¹æ®è®¾å¤‡ç±»å‹ï¼ˆCPU/GPUï¼‰è¿”å›ä¼˜åŒ–çš„é…ç½®å‚æ•°
- CPUé…ç½®ï¼šè¾ƒå°çš„æ‰¹æ¬¡å¤§å°(1)ã€ç¼“å­˜ç‡(0.1)ã€å·¥ä½œè¿›ç¨‹æ•°(2)
- GPUé…ç½®ï¼šè¾ƒå¤§çš„æ‰¹æ¬¡å¤§å°(4)ã€ç¼“å­˜ç‡(0.5)ã€å·¥ä½œè¿›ç¨‹æ•°(4)
- åŒ…å«æ•°æ®ã€æ¨¡å‹ã€è®­ç»ƒç­‰å„æ–¹é¢çš„é…ç½®å‚æ•°

**ç¬¬86-108è¡Œï¼šmerge_args_with_configå‡½æ•°**
```python
def merge_args_with_config(args: argparse.Namespace, config: Dict[str, Any]) -> Dict[str, Any]:
    """
    åˆå¹¶å‘½ä»¤è¡Œå‚æ•°å’Œé…ç½®å­—å…¸
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        config: åŸºç¡€é…ç½®å­—å…¸
        
    Returns:
        åˆå¹¶åçš„é…ç½®å­—å…¸
    """
```
- å°†å‘½ä»¤è¡Œå‚æ•°è¦†ç›–åˆ°åŸºç¡€é…ç½®ä¸­
- å¤„ç†ç‰¹æ®Šå‚æ•°å¦‚æ¨¡å‹åˆ—è¡¨ç­‰
- ç¡®ä¿å‚æ•°çš„æ­£ç¡®æ€§å’Œä¸€è‡´æ€§

**ç¬¬109-200è¡Œï¼šrun_simplified_trainingå‡½æ•°**
```python
def run_simplified_training(config: Dict[str, Any]) -> None:
    """
    è¿è¡Œç®€åŒ–çš„è®­ç»ƒæµç¨‹ï¼Œæ”¯æŒå¤šæ¨¡å‹è®­ç»ƒ
    
    Args:
        config: è®­ç»ƒé…ç½®å­—å…¸
    """
```
- æ”¯æŒå•æ¨¡å‹å’Œé«˜çº§æ¨¡å‹è®­ç»ƒ
- å¤„ç†å¤šæ¨¡å‹é¡ºåºè®­ç»ƒ
- é«˜çº§æ¨¡å‹çš„åˆ›å»ºå’Œè®­ç»ƒ
- è¾“å‡ºè®­ç»ƒç»“æœå’Œæ¨¡å‹ä¿¡æ¯

**ç¬¬201-250è¡Œï¼šauto_adjust_parameterså‡½æ•°**
```python
def auto_adjust_parameters(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ ¹æ®è®¾å¤‡å’Œå†…å­˜è‡ªåŠ¨è°ƒèŠ‚å‚æ•°
    
    Args:
        config: åŸå§‹é…ç½®
        
    Returns:
        è°ƒèŠ‚åçš„é…ç½®
    """
```
- æ ¹æ®GPUå†…å­˜è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°
- æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´å·¥ä½œè¿›ç¨‹æ•°
- ä¼˜åŒ–ç¼“å­˜ç‡å’Œå…¶ä»–æ€§èƒ½å‚æ•°

**ç¬¬251-350è¡Œï¼šrun_evaluationå‡½æ•°**
```python
def run_evaluation(config: Dict[str, Any]) -> None:
    """
    è¿è¡Œæ¨¡å‹è¯„ä¼°
    
    Args:
        config: è¯„ä¼°é…ç½®å­—å…¸
    """
```
- åˆ›å»ºè¯„ä¼°å™¨å®ä¾‹
- æ‰§è¡Œæ¨¡å‹è¯„ä¼°
- ç”Ÿæˆè¯„ä¼°æŠ¥å‘Šå’Œå¯è§†åŒ–ç»“æœ
- è¾“å‡ºè¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡

**ç¬¬351-550è¡Œï¼šmainå‡½æ•°**
```python
def main():
    """
    ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶æ‰§è¡Œç›¸åº”æ“ä½œ
    """
    parser = argparse.ArgumentParser(
        description="BraTSè„‘è‚¿ç˜¤åˆ†å‰²é¡¹ç›®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  è®­ç»ƒæ¨¡å‹:
    python main.py --mode train --data_dir /path/to/dataset
    python main.py --mode train --model_name UNet --epochs 100
    
  è¯„ä¼°æ¨¡å‹:
    python main.py --mode eval --model_path /path/to/model.pth --data_dir /path/to/dataset
        """
    )
```
- å®šä¹‰æ‰€æœ‰å‘½ä»¤è¡Œå‚æ•°
- åŒ…æ‹¬æ¨¡å¼é€‰æ‹©ã€æ•°æ®è·¯å¾„ã€æ¨¡å‹é…ç½®ã€è®­ç»ƒå‚æ•°ç­‰
- å‚æ•°éªŒè¯å’Œè®¾å¤‡é…ç½®
- æ ¹æ®æ¨¡å¼è°ƒç”¨ç›¸åº”çš„è®­ç»ƒæˆ–è¯„ä¼°å‡½æ•°

**ç¬¬551-589è¡Œï¼šç¨‹åºå…¥å£å’Œè®¾å¤‡é…ç½®**
```python
    # è®¾å¤‡é…ç½®
    if args.device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        device = args.device
    
    config['device'] = device
    
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print("=" * 60)
    print("ğŸ§  BraTSè„‘è‚¿ç˜¤åˆ†å‰²é¡¹ç›® v3.1.0")
    print("=" * 60)
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    print(f"è®¾å¤‡: {device}")
    print(f"æ•°æ®ç›®å½•: {args.data_dir}")
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not os.path.exists(args.data_dir):
        print(f"âš ï¸  è­¦å‘Š: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {args.data_dir}")
        print("è¯·ç¡®ä¿æ•°æ®è·¯å¾„æ­£ç¡®")
    
    # æ ¹æ®æ¨¡å¼æ‰§è¡Œç›¸åº”æ“ä½œ
    if args.mode == 'train':
        run_simplified_training(config)
    elif args.mode == 'eval':
        run_evaluation(config)
    else:
        print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å¼: {args.mode}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```
- è‡ªåŠ¨æ£€æµ‹å’Œé…ç½®è®¡ç®—è®¾å¤‡
- æ‰“å°é¡¹ç›®ä¿¡æ¯å’Œè¿è¡Œå‚æ•°
- éªŒè¯æ•°æ®ç›®å½•å­˜åœ¨æ€§
- æ ¹æ®æ¨¡å¼è°ƒç”¨è®­ç»ƒæˆ–è¯„ä¼°åŠŸèƒ½

### model.py - æ¨¡å‹å®šä¹‰å’Œåˆ›å»º

è¿™ä¸ªæ–‡ä»¶å®šä¹‰äº†æ‰€æœ‰æ”¯æŒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹å’Œç›¸å…³çš„åˆ›å»ºå‡½æ•°ã€‚

#### ä¸»è¦ç±»å’Œå‡½æ•°è¯¦è§£ï¼š

**ç¬¬1-15è¡Œï¼šå¯¼å…¥å£°æ˜**
```python
import torch
import torch.nn as nn
import torch.optim as optim
from typing import Dict, List, Tuple, Any, Optional
from monai.networks.nets import UNet, SegResNet, UNETR, SwinUNETR, AttentionUnet, VNet, HighResNet
from monai.networks.layers import Norm
from monai.losses import DiceCELoss, FocalLoss, TverskyLoss, GeneralizedDiceLoss, DiceFocalLoss
from monai.metrics import DiceMetric, HausdorffDistanceMetric, SurfaceDistanceMetric, ConfusionMatrixMetric, MeanIoU, GeneralizedDiceScore
from monai.transforms import Compose, Activations, AsDiscrete
from monai.inferers import sliding_window_inference

import torch.nn.functional as F
```
- å¯¼å…¥PyTorchæ ¸å¿ƒæ¨¡å—
- å¯¼å…¥MONAIçš„ç½‘ç»œæ¶æ„ã€æŸå¤±å‡½æ•°ã€è¯„ä¼°æŒ‡æ ‡
- å¯¼å…¥æ¨ç†å’Œå˜æ¢å·¥å…·

**ç¬¬18-40è¡Œï¼šBasicModelBankç±»åˆå§‹åŒ–**
```python
class BasicModelBank:
    """
    ç®€åŒ–çš„BraTSåˆ†å‰²æ¨¡å‹ï¼Œæ”¯æŒåŸºç¡€æ¨¡å‹æ¶æ„
    """
    def __init__(self, model_name: str = 'UNet', device: str = 'auto'):
        self.model_name = model_name
        self.device = self._setup_device(device)
        self.model = self._create_model()
        self.loss_function = self._create_loss()
        self.metrics = self._create_metrics()
```
- åˆå§‹åŒ–æ¨¡å‹åç§°å’Œè®¾å¤‡
- åˆ›å»ºæ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œè¯„ä¼°æŒ‡æ ‡
- æ”¯æŒè‡ªåŠ¨è®¾å¤‡æ£€æµ‹

**ç¬¬41-55è¡Œï¼šè®¾å¤‡è®¾ç½®æ–¹æ³•**
```python
def _setup_device(self, device: str) -> torch.device:
    """è®¾ç½®è®¾å¤‡"""
    if device == 'auto':
        return torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    elif device.lower() == 'cpu':
        return torch.device('cpu')
    elif device.lower() == 'cuda':
        if torch.cuda.is_available():
            return torch.device('cuda')
        else:
            print("è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPU")
            return torch.device('cpu')
    else:
        return torch.device(device)
```
- æ™ºèƒ½è®¾å¤‡é€‰æ‹©é€»è¾‘
- è‡ªåŠ¨æ£€æµ‹CUDAå¯ç”¨æ€§
- æä¾›è®¾å¤‡åˆ‡æ¢çš„å®‰å…¨æœºåˆ¶

**ç¬¬56-150è¡Œï¼šæ¨¡å‹åˆ›å»ºæ–¹æ³•**
```python
def _create_model(self):
    """åˆ›å»ºæ¨¡å‹"""
    if self.model_name == 'UNet':
        model = UNet(
            spatial_dims=3,
            in_channels=4,
            out_channels=4,
            channels=(32, 64, 128, 256, 512),
            strides=(2, 2, 2, 2),
            num_res_units=2,
            norm="instance",
            dropout=0.1
        )
```
- æ”¯æŒ7ç§ä¸åŒçš„ç½‘ç»œæ¶æ„ï¼šUNetã€SegResNetã€UNETRã€SwinUNETRã€AttentionUNetã€VNetã€HighResNet
- æ¯ä¸ªæ¨¡å‹éƒ½é’ˆå¯¹BraTSæ•°æ®é›†è¿›è¡Œäº†ä¼˜åŒ–é…ç½®
- ç»Ÿä¸€çš„è¾“å…¥è¾“å‡ºæ¥å£ï¼š4ä¸ªè¾“å…¥é€šé“ï¼ˆT1ã€T1ceã€T2ã€FLAIRï¼‰ï¼Œ4ä¸ªè¾“å‡ºç±»åˆ«

**ç¬¬151-170è¡Œï¼šæŸå¤±å‡½æ•°åˆ›å»º**
```python
def _create_loss(self):
    """åˆ›å»ºæŸå¤±å‡½æ•°"""
    return DiceCELoss(
        to_onehot_y=True,
        softmax=True,
        squared_pred=True,
        jaccard=False,
        reduction="mean"
    )
```
- ä½¿ç”¨Diceå’Œäº¤å‰ç†µçš„ç»„åˆæŸå¤±
- é€‚åˆåŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡
- è‡ªåŠ¨å¤„ç†one-hotç¼–ç å’Œsoftmaxæ¿€æ´»

**ç¬¬171-190è¡Œï¼šè¯„ä¼°æŒ‡æ ‡åˆ›å»º**
```python
def _create_metrics(self):
    """åˆ›å»ºè¯„ä¼°æŒ‡æ ‡"""
    return {
        'dice': DiceMetric(
            include_background=False,
            reduction="mean_batch",
            get_not_nans=False
        ),
        'hausdorff': HausdorffDistanceMetric(
            include_background=False,
            distance_metric='euclidean',
            percentile=95,
            directed=False,
            reduction="mean_batch"
        )
    }
```
- åˆ›å»ºDiceç³»æ•°å’ŒHausdorffè·ç¦»æŒ‡æ ‡
- æ’é™¤èƒŒæ™¯ç±»åˆ«çš„è®¡ç®—
- ä½¿ç”¨æ‰¹æ¬¡å¹³å‡çš„çº¦ç®€æ–¹å¼

**ç¬¬191-220è¡Œï¼šæ»‘åŠ¨çª—å£æ¨ç†**
```python
def sliding_window_inference(self, inputs: torch.Tensor, 
                            roi_size: Tuple = (128, 128, 128),
                            sw_batch_size: int = 4,
                            overlap: float = 0.6) -> torch.Tensor:
    """æ»‘åŠ¨çª—å£æ¨ç†"""
    return sliding_window_inference(
        inputs=inputs,
        roi_size=roi_size,
        sw_batch_size=sw_batch_size,
        predictor=self.model,
        overlap=overlap,
        mode="gaussian",
        sw_device=self.device,
        device=self.device
    )
```
- å®ç°æ»‘åŠ¨çª—å£æ¨ç†ç­–ç•¥
- æ”¯æŒå¤§å°ºå¯¸å›¾åƒçš„åˆ†å—å¤„ç†
- ä½¿ç”¨é«˜æ–¯æƒé‡èåˆé‡å åŒºåŸŸ



**ç¬¬281-320è¡Œï¼šä¼˜åŒ–å™¨åˆ›å»ºå‡½æ•°**
```python
def create_optimizer(model: nn.Module, 
                    optimizer_name: str = "AdamW",
                    learning_rate: float = 1e-4,
                    weight_decay: float = 1e-5) -> optim.Optimizer:
    """åˆ›å»ºä¼˜åŒ–å™¨"""
    if optimizer_name.lower() == "adam":
        return optim.Adam(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay
        )
```
- æ”¯æŒAdamã€AdamWã€SGDä¸‰ç§ä¼˜åŒ–å™¨
- æä¾›ç»Ÿä¸€çš„å‚æ•°æ¥å£
- é»˜è®¤ä½¿ç”¨AdamWä¼˜åŒ–å™¨

**ç¬¬321-360è¡Œï¼šå­¦ä¹ ç‡è°ƒåº¦å™¨åˆ›å»ºå‡½æ•°**
```python
def create_scheduler(optimizer: optim.Optimizer,
                    scheduler_name: str = "CosineAnnealingLR",
                    **kwargs):
    """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
    if scheduler_name.lower() == "steplr":
        return optim.lr_scheduler.StepLR(
            optimizer,
            step_size=kwargs.get('step_size', 30),
            gamma=kwargs.get('gamma', 0.1)
        )
```
- æ”¯æŒStepLRã€CosineAnnealingLRã€ReduceLROnPlateauè°ƒåº¦å™¨
- çµæ´»çš„å‚æ•°é…ç½®
- é»˜è®¤ä½¿ç”¨ä½™å¼¦é€€ç«è°ƒåº¦

### DatasetLoader_transforms.py - æ•°æ®åŠ è½½å’Œé¢„å¤„ç†

è¿™ä¸ªæ–‡ä»¶è´Ÿè´£BraTSæ•°æ®é›†çš„åŠ è½½ã€é¢„å¤„ç†å’Œæ•°æ®å¢å¼ºã€‚

#### ä¸»è¦ç±»å’Œå‡½æ•°è¯¦è§£ï¼š

**ç¬¬1-30è¡Œï¼šå¯¼å…¥å£°æ˜**
```python
import os
import glob
import numpy as np
import nibabel as nib
from typing import Dict, List, Tuple, Optional

import torch
from torch.utils.data import DataLoader

from monai.data import Dataset, CacheDataset, DataLoader as MonaiDataLoader
from monai.transforms import (
    Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd,
    ScaleIntensityRanged, CropForegroundd, RandCropByPosNegLabeld,
    RandFlipd, RandRotate90d, RandShiftIntensityd, RandAffined,
    ToTensord, EnsureTyped, Resized, NormalizeIntensityd,
    RandGaussianNoised, RandGaussianSmoothd, RandAdjustContrastd,
    RandZoomd, Rand3DElasticd, RandBiasFieldd
)
from monai.utils import set_determinism
```
- å¯¼å…¥æ•°æ®å¤„ç†ç›¸å…³çš„åº“
- å¯¼å…¥MONAIçš„æ•°æ®åŠ è½½å’Œå˜æ¢å·¥å…·
- å¯¼å…¥å„ç§æ•°æ®å¢å¼ºå˜æ¢

**ç¬¬31-55è¡Œï¼šDatasetLoaderç±»åˆå§‹åŒ–**
```python
class DatasetLoader:
    """
    BraTS2024-BraTS-GLIæ•°æ®é›†åŠ è½½å™¨
    æ”¯æŒå¤šæ¨¡æ€MRIå›¾åƒï¼ˆT1, T1ce, T2, FLAIRï¼‰å’Œåˆ†å‰²æ ‡ç­¾
    """
    
    def __init__(self, 
                 data_dir: str,
                 cache_rate: float = 1.0,
                 num_workers: int = 4,
                 seed: int = 42):
        self.data_dir = data_dir
        self.cache_rate = cache_rate
        self.num_workers = num_workers
        
        # è®¾ç½®éšæœºç§å­
        set_determinism(seed=seed)
        
        # å®šä¹‰å›¾åƒæ¨¡æ€
        self.modalities = ['t1n', 't1c', 't2f', 't2w']
```
- åˆå§‹åŒ–æ•°æ®ç›®å½•å’ŒåŠ è½½å‚æ•°
- è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
- å®šä¹‰BraTSæ•°æ®é›†çš„å››ç§MRIæ¨¡æ€

**ç¬¬56-120è¡Œï¼šæ•°æ®å­—å…¸è·å–æ–¹æ³•**
```python
def get_data_dicts(self) -> Tuple[List[Dict], List[Dict]]:
    """è·å–è®­ç»ƒå’ŒéªŒè¯æ•°æ®å­—å…¸"""
    data_files = []
    
    # æ‰«ææ•°æ®ç›®å½•
    if os.path.exists(self.data_dir):
        for case_dir in sorted(os.listdir(self.data_dir)):
            case_path = os.path.join(self.data_dir, case_dir)
            
            # è·³è¿‡éç›®å½•æ–‡ä»¶
            if not os.path.isdir(case_path):
                continue
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            t1n_path = os.path.join(case_path, f"{case_dir}-t1n.nii.gz")
            t1c_path = os.path.join(case_path, f"{case_dir}-t1c.nii.gz")
            t2w_path = os.path.join(case_path, f"{case_dir}-t2w.nii.gz")
            t2f_path = os.path.join(case_path, f"{case_dir}-t2f.nii.gz")
            seg_path = os.path.join(case_path, f"{case_dir}-seg.nii.gz")
```
- è‡ªåŠ¨æ‰«ææ•°æ®ç›®å½•
- æ„å»ºæ ‡å‡†çš„BraTSæ–‡ä»¶è·¯å¾„
- æ£€æŸ¥æ‰€æœ‰å¿…éœ€æ–‡ä»¶çš„å­˜åœ¨æ€§
- æŒ‰8:2æ¯”ä¾‹åˆ’åˆ†è®­ç»ƒå’ŒéªŒè¯é›†

**ç¬¬121-200è¡Œï¼šæ•°æ®å˜æ¢è·å–æ–¹æ³•**
```python
def get_transforms(self, mode: str = "train") -> Compose:
    """è·å–æ•°æ®å˜æ¢æµç¨‹"""
    # åŸºç¡€å˜æ¢ï¼ˆè®­ç»ƒå’ŒéªŒè¯éƒ½ä½¿ç”¨ï¼‰
    base_transforms = [
        LoadImaged(keys=["image", "label"]),
        EnsureChannelFirstd(keys=["image", "label"]),
        Orientationd(keys=["image", "label"], axcodes="RAS"),
        Spacingd(
            keys=["image", "label"],
            pixdim=(1.0, 1.0, 1.0),
            mode=("bilinear", "nearest")
        ),
        ScaleIntensityRanged(
            keys=["image"],
            a_min=-175,
            a_max=250,
            b_min=0.0,
            b_max=1.0,
            clip=True
        ),
        CropForegroundd(keys=["image", "label"], source_key="image"),
        Resized(
            keys=["image", "label"],
            spatial_size=(128, 128, 128),
            mode=("trilinear", "nearest")
        ),
        NormalizeIntensityd(keys=["image"], nonzero=True, channel_wise=True)
    ]
```
- å®šä¹‰åŸºç¡€çš„æ•°æ®é¢„å¤„ç†æµç¨‹
- åŒ…æ‹¬åŠ è½½ã€æ–¹å‘ç»Ÿä¸€ã€é‡é‡‡æ ·ã€å¼ºåº¦å½’ä¸€åŒ–ç­‰
- è£å‰ªå‰æ™¯åŒºåŸŸå¹¶è°ƒæ•´åˆ°ç»Ÿä¸€å°ºå¯¸

**ç¬¬201-280è¡Œï¼šè®­ç»ƒæ—¶æ•°æ®å¢å¼º**
```python
if mode == "train":
    # è®­ç»ƒæ—¶æ·»åŠ æ•°æ®å¢å¼º
    train_transforms = base_transforms + [
        RandCropByPosNegLabeld(
            keys=["image", "label"],
            label_key="label",
            spatial_size=(96, 96, 96),
            pos=1,
            neg=1,
            num_samples=2,
            image_key="image",
            image_threshold=0
        ),
        RandFlipd(
            keys=["image", "label"],
            spatial_axis=[0],
            prob=0.10
        ),
        # ... æ›´å¤šæ•°æ®å¢å¼ºå˜æ¢
        Rand3DElasticd(
            keys=["image", "label"],
            prob=0.1,
            sigma_range=(5, 8),
            magnitude_range=(100, 200),
            mode=("bilinear", "nearest")
        ),
        RandBiasFieldd(
            keys=["image"],
            prob=0.1,
            coeff_range=(0.0, 0.1),
            degree=3
        )
    ]
```
- ä¸°å¯Œçš„æ•°æ®å¢å¼ºç­–ç•¥
- åŒ…æ‹¬å‡ ä½•å˜æ¢ã€å¼ºåº¦å˜æ¢ã€å™ªå£°æ·»åŠ ç­‰
- ä¸“é—¨é’ˆå¯¹åŒ»å­¦å›¾åƒçš„å¢å¼ºæ–¹æ³•

**ç¬¬281-350è¡Œï¼šæ•°æ®åŠ è½½å™¨åˆ›å»º**
```python
def get_dataloaders(self, batch_size: int = 2) -> Tuple[DataLoader, DataLoader]:
    """è·å–è®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨"""
    # è·å–æ•°æ®æ–‡ä»¶åˆ—è¡¨
    train_files, val_files = self.get_data_dicts()
    
    return self.create_dataloaders_from_dicts(train_files, val_files, batch_size)

def create_dataloaders_from_dicts(self, train_files: List[Dict], val_files: List[Dict], 
                                 batch_size: int = 2) -> Tuple[DataLoader, DataLoader]:
    """ä»ç»™å®šçš„æ•°æ®å­—å…¸åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    # è·å–å˜æ¢
    train_transforms = self.get_transforms("train")
    val_transforms = self.get_transforms("val")
    
    # åˆ›å»ºæ•°æ®é›†
    if self.cache_rate > 0:
        # ç¼“å­˜æ•°æ®é›†
        train_ds = CacheDataset(
            data=train_files,
            transform=train_transforms,
            cache_rate=self.cache_rate,
            num_workers=self.num_workers
        )
```
- æ”¯æŒç¼“å­˜æ•°æ®é›†å’Œæ™®é€šæ•°æ®é›†
- çµæ´»çš„æ‰¹æ¬¡å¤§å°é…ç½®
- å¤šè¿›ç¨‹æ•°æ®åŠ è½½

### train.py - è®­ç»ƒæ¨¡å—

è¿™ä¸ªæ–‡ä»¶å®ç°äº†å®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹ï¼Œæ”¯æŒå•æ¨¡å‹å’Œé«˜çº§æ¨¡å‹è®­ç»ƒã€‚

#### ä¸»è¦ç±»å’Œå‡½æ•°è¯¦è§£ï¼š

**ç¬¬1-25è¡Œï¼šå¯¼å…¥å£°æ˜**
```python
import os
import time
import torch
import numpy as np
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from typing import Dict, Any
import matplotlib.pyplot as plt
from pathlib import Path

from DatasetLoader_transforms import DatasetLoader
from model import BasicModelBank, create_optimizer, create_scheduler
from utils import EarlyStopping, ModelCheckpoint, MetricsTracker
from monai.utils import set_determinism
from monai.data import decollate_batch
from monai.transforms import AsDiscrete, Compose
```
- å¯¼å…¥è®­ç»ƒæ‰€éœ€çš„æ‰€æœ‰æ¨¡å—
- åŒ…æ‹¬æ•°æ®åŠ è½½ã€æ¨¡å‹ã€å·¥å…·å‡½æ•°ç­‰

**ç¬¬26-65è¡Œï¼šModelTrainerç±»åˆå§‹åŒ–**
```python
class ModelTrainer:
    """BraTSè„‘è‚¿ç˜¤åˆ†å‰²è®­ç»ƒå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–è®­ç»ƒå™¨"""
        self.config = config
        self.device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))
        
        # è®¾ç½®éšæœºç§å­
        set_determinism(seed=config.get('seed', 42))
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(config.get('output_dir', './outputs'))
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._setup_data()
        self._setup_model()
        self._setup_training()
        self._setup_logging()
```
- åˆå§‹åŒ–è®­ç»ƒå™¨é…ç½®
- è®¾ç½®è®¾å¤‡å’Œéšæœºç§å­
- åˆ›å»ºè¾“å‡ºç›®å½•
- åˆå§‹åŒ–å„ä¸ªç»„ä»¶

**ç¬¬66-85è¡Œï¼šæ•°æ®è®¾ç½®æ–¹æ³•**
```python
def _setup_data(self):
    """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
    print("è®¾ç½®æ•°æ®åŠ è½½å™¨...")
    
    data_loader = DatasetLoader(
        data_dir=self.config['data_dir'],
        cache_rate=self.config.get('cache_rate', 0.1),
        num_workers=self.config.get('num_workers', 4),
        seed=self.config.get('seed', 42)
    )
    
    self.train_loader, self.val_loader = data_loader.get_dataloaders(
        batch_size=self.config.get('batch_size', 2)
    )
```
- åˆ›å»ºæ•°æ®åŠ è½½å™¨å®ä¾‹
- é…ç½®ç¼“å­˜ç‡ã€å·¥ä½œè¿›ç¨‹æ•°ç­‰å‚æ•°
- è·å–è®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨

**ç¬¬86-150è¡Œï¼šæ¨¡å‹è®¾ç½®æ–¹æ³•**
```python
def _setup_model(self):
    """è®¾ç½®æ¨¡å‹ã€æŸå¤±å‡½æ•°å’ŒæŒ‡æ ‡"""
    print("è®¾ç½®æ¨¡å‹...")
    
    # æ£€æŸ¥æ¨¡å‹ç±»å‹
    model_category = self.config.get('model_category', 'basic')
    
    if model_category == 'advanced':
        print("ä½¿ç”¨é«˜çº§æ¨¡å‹")
        self._setup_advanced_model()
        
        # ä¸ºé«˜çº§æ¨¡å‹åˆ›å»ºæŸå¤±å‡½æ•°å’ŒæŒ‡æ ‡
        from monai.losses import DiceCELoss
        from monai.metrics import DiceMetric, HausdorffDistanceMetric
        
        self.loss_function = DiceCELoss(
            to_onehot_y=True,
            softmax=True,
            squared_pred=True,
            jaccard=False,
            reduction="mean"
        )
```
- æ”¯æŒå•æ¨¡å‹å’Œé«˜çº§æ¨¡å‹ä¸¤ç§æ¨¡å¼
- ä¸ºé«˜çº§æ¨¡å‹åˆ›å»ºä¸“é—¨çš„æŸå¤±å‡½æ•°å’ŒæŒ‡æ ‡
- è®¡ç®—å’Œæ˜¾ç¤ºæ¨¡å‹å‚æ•°ä¿¡æ¯

**ç¬¬151-220è¡Œï¼šè®­ç»ƒç»„ä»¶è®¾ç½®**
```python
def _setup_training(self):
    """è®¾ç½®è®­ç»ƒç»„ä»¶"""
    print("è®¾ç½®è®­ç»ƒç»„ä»¶...")
    
    if self.model_category == 'advanced':
        # ä¸ºé«˜çº§æ¨¡å‹åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        self.optimizer = create_optimizer(
            self.model,
            optimizer_name=self.config.get('optimizer', 'adamw'),
            learning_rate=self.config.get('learning_rate', 1e-4),
            weight_decay=self.config.get('weight_decay', 1e-5)
        )
        
        self.scheduler = create_scheduler(
            self.optimizer,
            scheduler_name=self.config.get('scheduler', 'cosineannealinglr'),
            T_max=self.config.get('max_epochs', 500)
        )
```
- ä¸ºæ¯ä¸ªå­æ¨¡å‹åˆ›å»ºç‹¬ç«‹çš„ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
- é…ç½®æ—©åœå’Œæ¨¡å‹æ£€æŸ¥ç‚¹
- åˆå§‹åŒ–æŒ‡æ ‡è·Ÿè¸ªå™¨

**ç¬¬221-320è¡Œï¼šè®­ç»ƒepochæ–¹æ³•**
```python
def train_epoch(self, epoch: int) -> Dict[str, float]:
    """è®­ç»ƒä¸€ä¸ªepoch"""
    if self.model_category == 'advanced':
        # é«˜çº§æ¨¡å‹è®­ç»ƒ
        self.model.train()
    else:
        self.model.train()
    
    epoch_loss = 0
    num_batches = len(self.train_loader)
    
    # é‡ç½®æŒ‡æ ‡
    for metric in self.metrics.values():
        metric.reset()
    
    progress_bar = tqdm(self.train_loader, desc=f"è®­ç»ƒ Epoch {epoch+1}")
    
    for batch_idx, batch_data in enumerate(progress_bar):
        inputs = batch_data['image'].to(self.device)
        labels = batch_data['label'].to(self.device)
        
        # æ ‡å‡†è®­ç»ƒæµç¨‹
        self.optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        outputs = self.model(inputs)
        
        # è®¡ç®—æŸå¤±
        loss = self.loss_function(outputs, labels)
        
        # åå‘ä¼ æ’­
        loss.backward()
        self.optimizer.step()
```
- æ”¯æŒå•æ¨¡å‹å’Œé«˜çº§æ¨¡å‹çš„è®­ç»ƒ
- å®ç°å®Œæ•´çš„å‰å‘ä¼ æ’­ã€æŸå¤±è®¡ç®—ã€åå‘ä¼ æ’­æµç¨‹
- å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦å’ŒæŒ‡æ ‡

**ç¬¬321-400è¡Œï¼šéªŒè¯epochæ–¹æ³•**
```python
def validate_epoch(self, epoch: int) -> Dict[str, float]:
    """éªŒè¯ä¸€ä¸ªepoch"""
    self.model.eval()
    
    epoch_loss = 0
    num_batches = len(self.val_loader)
    
    # é‡ç½®æŒ‡æ ‡
    for metric in self.metrics.values():
        metric.reset()
    
    progress_bar = tqdm(self.val_loader, desc=f"éªŒè¯ Epoch {epoch+1}")
    
    with torch.no_grad():
        for batch_idx, batch_data in enumerate(progress_bar):
            inputs = batch_data['image'].to(self.device)
            labels = batch_data['label'].to(self.device)
            
            # ä½¿ç”¨æ»‘åŠ¨çª—å£æ¨ç†
            outputs = self.model_creator.sliding_window_inference(inputs)
```
- éªŒè¯æ¨¡å¼ä¸‹ç¦ç”¨æ¢¯åº¦è®¡ç®—
- ä½¿ç”¨æ»‘åŠ¨çª—å£æ¨ç†æé«˜å‡†ç¡®æ€§
- è®¡ç®—éªŒè¯æŸå¤±å’ŒæŒ‡æ ‡

**ç¬¬401-530è¡Œï¼šå®Œæ•´è®­ç»ƒæµç¨‹**
```python
def train(self):
    """æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹"""
    print("å¼€å§‹è®­ç»ƒ...")
    print(f"æœ€å¤§è®­ç»ƒè½®æ•°: {self.config.get('max_epochs', 500)}")
    print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
    print("-" * 50)
    
    max_epochs = self.config.get('max_epochs', 500)
    best_metric = -1
    
    for epoch in range(max_epochs):
        start_time = time.time()
        
        # è®­ç»ƒ
        train_metrics = self.train_epoch(epoch)
        
        # éªŒè¯
        val_metrics = self.validate_epoch(epoch)
        
        # æ›´æ–°å­¦ä¹ ç‡
        if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
            self.scheduler.step(val_metrics['val_loss'])
        else:
            self.scheduler.step()
        
        # è®°å½•æŒ‡æ ‡
        all_metrics = {**train_metrics, **val_metrics}
        self.metrics_tracker.update(all_metrics)
        
        # è®°å½•åˆ°TensorBoard
        for key, value in all_metrics.items():
            self.writer.add_scalar(f'Metrics/{key}', value, epoch)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        current_metric = val_metrics['val_dice']
        if current_metric > best_metric:
            best_metric = current_metric
            
            # ä¿å­˜æ¨¡å‹
            model_state = {
                'epoch': epoch,
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'scheduler_state_dict': self.scheduler.state_dict(),
                'best_metric': best_metric,
                'config': self.config
            }
            self.checkpoint.save(model_state)
```
- å®Œæ•´çš„è®­ç»ƒå¾ªç¯å®ç°
- è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- æ—©åœæœºåˆ¶é˜²æ­¢è¿‡æ‹Ÿåˆ
- TensorBoardæ—¥å¿—è®°å½•
- è®­ç»ƒå†å²ä¿å­˜å’Œå¯è§†åŒ–

### evaluate.py - è¯„ä¼°æ¨¡å—

è¿™ä¸ªæ–‡ä»¶å®ç°äº†è®­ç»ƒå¥½çš„æ¨¡å‹çš„æ€§èƒ½è¯„ä¼°åŠŸèƒ½ã€‚

#### ä¸»è¦ç±»å’Œå‡½æ•°è¯¦è§£ï¼š

**ç¬¬1-30è¡Œï¼šæ–‡æ¡£å’Œå¯¼å…¥**
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BraTSè„‘è‚¿ç˜¤åˆ†å‰²æ¨¡å‹è¯„ä¼°è„šæœ¬

è¿™ä¸ªè„šæœ¬ç”¨äºè¯„ä¼°è®­ç»ƒå¥½çš„BraTSè„‘è‚¿ç˜¤åˆ†å‰²æ¨¡å‹çš„æ€§èƒ½ã€‚
æ”¯æŒCPUå’ŒGPU(CUDA)è®¾å¤‡ï¼Œå¯é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šæ¨¡å‹è·¯å¾„å’Œæ•°æ®é›†è·¯å¾„ã€‚

ä½¿ç”¨ç¤ºä¾‹:
    python evaluate.py --model_path ./outputs/checkpoints/best_model.pth --data_dir /path/to/dataset
    python evaluate.py --model_path ./outputs/checkpoints/best_model.pth --data_dir /path/to/dataset --device cpu
    python evaluate.py --model_path ./outputs/checkpoints/best_model.pth --data_dir /path/to/dataset --device cuda --output_dir ./my_results

ä½œè€…: ä¸ªäººä½¿ç”¨ç‰ˆæœ¬
ç‰ˆæœ¬: 3.1.0
"""

import os
import torch
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional
import matplotlib.pyplot as plt
from tqdm import tqdm
import pandas as pd
```
- è¯¦ç»†çš„è„šæœ¬è¯´æ˜å’Œä½¿ç”¨ç¤ºä¾‹
- å¯¼å…¥è¯„ä¼°æ‰€éœ€çš„æ‰€æœ‰æ¨¡å—

**ç¬¬31-65è¡Œï¼šBraTSEvaluatorç±»åˆå§‹åŒ–**
```python
class BraTSEvaluator:
    """BraTSè„‘è‚¿ç˜¤åˆ†å‰²æ¨¡å‹è¯„ä¼°å™¨"""
    
    def __init__(self, 
                 model_path: str,
                 data_dir: str,
                 device: str = "cuda",
                 output_dir: str = "./evaluation_results"):
        """åˆå§‹åŒ–è¯„ä¼°å™¨"""
        self.model_path = model_path
        self.data_dir = data_dir
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®éšæœºç§å­
        set_determinism(seed=42)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._load_model()
        self._setup_data()
        self._setup_metrics()
```
- åˆå§‹åŒ–è¯„ä¼°å™¨å‚æ•°
- è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½•
- è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§

**ç¬¬66-150è¡Œï¼šæ¨¡å‹åŠ è½½æ–¹æ³•**
```python
def _load_model(self):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"åŠ è½½æ¨¡å‹: {self.model_path}")
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint = torch.load(self.model_path, map_location=self.device)
    config = checkpoint.get('config', {})
    
    # è·å–æ¨¡å‹åç§°
    model_name = config.get('model_name', 'UNet')
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºé«˜çº§æ¨¡å‹
    use_advanced = config.get('use_advanced', False)
    
    if use_advanced:
        print("æ£€æµ‹åˆ°é«˜çº§æ¨¡å‹ï¼Œä½¿ç”¨é«˜çº§è¯„ä¼°æ¨¡å¼")
        # è·å–é«˜çº§æ¨¡å‹é…ç½®
        model_type = config.get('model_type', 'fusion')
        print(f"é«˜çº§æ¨¡å‹ç±»å‹: {model_type}")
        
        # åˆ›å»ºé«˜çº§æ¨¡å‹
        self.model_creator = self._create_advanced_model()
        self.is_advanced = True
        print(f"æˆåŠŸåˆ›å»ºé«˜çº§æ¨¡å‹")
```
- æ™ºèƒ½æ£€æµ‹å•æ¨¡å‹å’Œé«˜çº§æ¨¡å‹
- è‡ªåŠ¨åŠ è½½ç›¸åº”çš„æ¨¡å‹æƒé‡
- æ˜¾ç¤ºè¯¦ç»†çš„æ¨¡å‹ä¿¡æ¯

**ç¬¬151-200è¡Œï¼šæ•°æ®å’ŒæŒ‡æ ‡è®¾ç½®**
```python
def _setup_data(self):
    """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
    print("è®¾ç½®æ•°æ®åŠ è½½å™¨...")
    
    data_loader = DatasetLoader(
        data_dir=self.data_dir,
        cache_rate=0.0,  # è¯„ä¼°æ—¶ä¸ä½¿ç”¨ç¼“å­˜
        num_workers=2,
        seed=42
    )
    
    # è·å–éªŒè¯æ•°æ®
    _, self.val_loader = data_loader.get_dataloaders(batch_size=1)  # è¯„ä¼°æ—¶ä½¿ç”¨batch_size=1
    
    print(f"éªŒè¯æ ·æœ¬æ•°: {len(self.val_loader)}")

def _setup_metrics(self):
    """è®¾ç½®è¯„ä¼°æŒ‡æ ‡"""
    # åˆ†å‰²æŒ‡æ ‡
    self.dice_metric = DiceMetric(
        include_background=False, 
        reduction="mean_batch",
        get_not_nans=False
    )
    
    self.hd_metric = HausdorffDistanceMetric(
        include_background=False,
        reduction="mean_batch",
        get_not_nans=False
    )
    
    self.surface_metric = SurfaceDistanceMetric(
        include_background=False,
        reduction="mean_batch",
        get_not_nans=False
    )
```
- è¯„ä¼°æ—¶ä¸ä½¿ç”¨æ•°æ®ç¼“å­˜
- ä½¿ç”¨batch_size=1ç¡®ä¿å‡†ç¡®æ€§
- è®¾ç½®å¤šç§è¯„ä¼°æŒ‡æ ‡

**ç¬¬201-320è¡Œï¼šæ¨¡å‹è¯„ä¼°æ–¹æ³•**
```python
def evaluate_model(self) -> Dict[str, float]:
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    print("å¼€å§‹æ¨¡å‹è¯„ä¼°...")
    
    # é‡ç½®æŒ‡æ ‡
    self.dice_metric.reset()
    self.hd_metric.reset()
    self.surface_metric.reset()
    
    all_dice_scores = []
    all_hd_scores = []
    all_surface_scores = []
    
    case_results = []
    
    with torch.no_grad():
        for batch_idx, batch_data in enumerate(tqdm(self.val_loader, desc="è¯„ä¼°è¿›åº¦")):
            inputs = batch_data['image'].to(self.device)
            labels = batch_data['label'].to(self.device)
            subject_id = batch_data.get('subject_id', [f'case_{batch_idx}'])[0]
            
            # ä½¿ç”¨æ»‘åŠ¨çª—å£æ¨ç†
            if self.is_advanced:
                # é«˜çº§æ¨¡å‹æ¨ç†
                outputs = self.model_creator.predict(inputs)
            else:
                # å•ä¸ªæ¨¡å‹æ¨ç†
                outputs = self.model_creator.sliding_window_inference(inputs)
            
            # åå¤„ç†
            outputs_list = decollate_batch(outputs)
            labels_list = decollate_batch(labels)
            
            outputs_convert = [self.post_pred(pred) for pred in outputs_list]
            labels_convert = [self.post_label(label) for label in labels_list]
            
            # è®¡ç®—æŒ‡æ ‡
            dice_scores = self.dice_metric(y_pred=outputs_convert, y=labels_convert)
            hd_scores = self.hd_metric(y_pred=outputs_convert, y=labels_convert)
            surface_scores = self.surface_metric(y_pred=outputs_convert, y=labels_convert)
```
- é€ä¸ªæ¡ˆä¾‹è¿›è¡Œè¯„ä¼°
- ä½¿ç”¨æ»‘åŠ¨çª—å£æ¨ç†æé«˜å‡†ç¡®æ€§
- è®¡ç®—å¤šç§è¯„ä¼°æŒ‡æ ‡
- ä¿å­˜æ¯ä¸ªæ¡ˆä¾‹çš„è¯¦ç»†ç»“æœ

**ç¬¬321-400è¡Œï¼šå¯è§†åŒ–ä¿å­˜æ–¹æ³•**
```python
def _save_visualization(self, 
                      images: np.ndarray,
                      labels: np.ndarray, 
                      predictions: np.ndarray,
                      subject_id: str,
                      dice_score: float):
    """ä¿å­˜å¯è§†åŒ–ç»“æœ"""
    # é€‰æ‹©ä¸­é—´åˆ‡ç‰‡
    slice_idx = images.shape[-1] // 2
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    fig.suptitle(f'{subject_id} - Dice: {dice_score:.4f}', fontsize=16)
    
    # æ˜¾ç¤ºä¸åŒæ¨¡æ€çš„å›¾åƒ
    modalities = ['T1n', 'T1c', 'T2w', 'T2f']
    for i in range(min(4, images.shape[0])):
        row = i // 2
        col = i % 2
        if row < 2 and col < 2:
            axes[row, col].imshow(images[i, :, :, slice_idx], cmap='gray')
            axes[row, col].set_title(f'{modalities[i]}')
            axes[row, col].axis('off')
    
    # æ˜¾ç¤ºçœŸå®æ ‡ç­¾
    axes[0, 2].imshow(images[0, :, :, slice_idx], cmap='gray')
    axes[0, 2].imshow(labels[:, :, slice_idx], cmap='jet', alpha=0.5)
    axes[0, 2].set_title('çœŸå®æ ‡ç­¾')
    axes[0, 2].axis('off')
    
    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
    axes[1, 2].imshow(images[0, :, :, slice_idx], cmap='gray')
    axes[1, 2].imshow(predictions[:, :, slice_idx], cmap='jet', alpha=0.5)
    axes[1, 2].set_title('é¢„æµ‹ç»“æœ')
    axes[1, 2].axis('off')
```
- ç”Ÿæˆç›´è§‚çš„åˆ†å‰²ç»“æœå¯è§†åŒ–
- æ˜¾ç¤ºå¤šæ¨¡æ€å›¾åƒå’Œåˆ†å‰²å¯¹æ¯”
- è‡ªåŠ¨ä¿å­˜é«˜è´¨é‡å›¾åƒ

**ç¬¬401-498è¡Œï¼šç»“æœä¿å­˜å’Œåˆ†æ**
```python
def _save_detailed_results(self, case_results: List[Dict], summary_results: Dict[str, float]):
    """ä¿å­˜è¯¦ç»†è¯„ä¼°ç»“æœ"""
    # ä¿å­˜æ¡ˆä¾‹çº§åˆ«ç»“æœ
    df_cases = pd.DataFrame(case_results)
    df_cases.to_csv(self.output_dir / 'case_results.csv', index=False)
    
    # ä¿å­˜æ€»ä½“ç»Ÿè®¡
    with open(self.output_dir / 'summary_results.txt', 'w', encoding='utf-8') as f:
        f.write("BraTSè„‘è‚¿ç˜¤åˆ†å‰²æ¨¡å‹è¯„ä¼°ç»“æœ\n")
        f.write("=" * 50 + "\n\n")
        
        f.write("Diceç³»æ•°ç»Ÿè®¡:\n")
        f.write(f"  å¹³å‡å€¼: {summary_results['mean_dice']:.4f} Â± {summary_results['std_dice']:.4f}\n")
        f.write(f"  ä¸­ä½æ•°: {summary_results['median_dice']:.4f}\n")
        f.write(f"  æœ€å°å€¼: {summary_results['min_dice']:.4f}\n")
        f.write(f"  æœ€å¤§å€¼: {summary_results['max_dice']:.4f}\n\n")
        
        f.write("Hausdorffè·ç¦»ç»Ÿè®¡:\n")
        f.write(f"  å¹³å‡å€¼: {summary_results['mean_hd']:.4f} Â± {summary_results['std_hd']:.4f}\n")
        f.write(f"  ä¸­ä½æ•°: {summary_results['median_hd']:.4f}\n\n")
```
- ä¿å­˜è¯¦ç»†çš„æ¡ˆä¾‹çº§åˆ«ç»“æœ
- ç”Ÿæˆç»Ÿè®¡æ‘˜è¦æŠ¥å‘Š
- åˆ›å»ºç»“æœåˆ†å¸ƒå›¾å’Œç®±çº¿å›¾

### utils.py - å·¥å…·å‡½æ•°

è¿™ä¸ªæ–‡ä»¶æä¾›äº†è®­ç»ƒå’Œè¯„ä¼°è¿‡ç¨‹ä¸­éœ€è¦çš„å„ç§å·¥å…·ç±»å’Œå‡½æ•°ã€‚

#### ä¸»è¦ç±»å’Œå‡½æ•°è¯¦è§£ï¼š

**ç¬¬1-15è¡Œï¼šå¯¼å…¥å£°æ˜**
```python
import os
import json
import torch
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Any, Optional
import time
from pathlib import Path
```
- å¯¼å…¥å·¥å…·å‡½æ•°æ‰€éœ€çš„åŸºç¡€æ¨¡å—

**ç¬¬16-50è¡Œï¼šEarlyStoppingç±»**
```python
class EarlyStopping:
    """æ—©åœæœºåˆ¶ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ"""
    
    def __init__(self, patience: int = 20, min_delta: float = 0.001, mode: str = 'min'):
        """
        åˆå§‹åŒ–æ—©åœæœºåˆ¶
        
        Args:
            patience: å®¹å¿è½®æ•°
            min_delta: æœ€å°æ”¹å–„å¹…åº¦
            mode: ç›‘æ§æ¨¡å¼ ('min' æˆ– 'max')
        """
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.best_score = None
        self.counter = 0
        self.early_stop = False
        
    def __call__(self, score: float) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ"""
        if self.best_score is None:
            self.best_score = score
        elif self._is_improvement(score):
            self.best_score = score
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        
        return self.early_stop
```
- å®ç°æ—©åœæœºåˆ¶é˜²æ­¢è¿‡æ‹Ÿåˆ
- æ”¯æŒæœ€å°åŒ–å’Œæœ€å¤§åŒ–ä¸¤ç§ç›‘æ§æ¨¡å¼
- å¯é…ç½®å®¹å¿è½®æ•°å’Œæœ€å°æ”¹å–„å¹…åº¦

**ç¬¬51-100è¡Œï¼šModelCheckpointç±»**
```python
class ModelCheckpoint:
    """æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜å™¨"""
    
    def __init__(self, save_dir: str, filename: str = 'best_model.pth'):
        """
        åˆå§‹åŒ–æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜å™¨
        
        Args:
            save_dir: ä¿å­˜ç›®å½•
            filename: æ–‡ä»¶å
        """
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        self.filename = filename
        self.filepath = self.save_dir / filename
        
    def save(self, state_dict: Dict[str, Any]):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
        torch.save(state_dict, self.filepath)
        
    def load(self) -> Dict[str, Any]:
        """åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹"""
        if self.filepath.exists():
            return torch.load(self.filepath)
        else:
            raise FileNotFoundError(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {self.filepath}")
```
- è‡ªåŠ¨åˆ›å»ºä¿å­˜ç›®å½•
- æä¾›ä¿å­˜å’ŒåŠ è½½æ£€æŸ¥ç‚¹çš„æ–¹æ³•
- æ”¯æŒçµæ´»çš„æ–‡ä»¶å‘½å

**ç¬¬101-180è¡Œï¼šMetricsTrackerç±»**
```python
class MetricsTracker:
    """æŒ‡æ ‡è·Ÿè¸ªå™¨ï¼Œç”¨äºè®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡"""
    
    def __init__(self):
        """åˆå§‹åŒ–æŒ‡æ ‡è·Ÿè¸ªå™¨"""
        self.history = {}
        
    def update(self, metrics: Dict[str, float]):
        """æ›´æ–°æŒ‡æ ‡"""
        for key, value in metrics.items():
            if key not in self.history:
                self.history[key] = []
            self.history[key].append(value)
            
    def get_history(self) -> Dict[str, List[float]]:
        """è·å–å†å²è®°å½•"""
        return self.history
        
    def get_latest(self) -> Dict[str, float]:
        """è·å–æœ€æ–°æŒ‡æ ‡"""
        latest = {}
        for key, values in self.history.items():
            if values:
                latest[key] = values[-1]
        return latest
        
    def get_best(self, metric_name: str, mode: str = 'max') -> float:
        """è·å–æœ€ä½³æŒ‡æ ‡å€¼"""
        if metric_name not in self.history:
            return None
            
        values = self.history[metric_name]
        if not values:
            return None
            
        if mode == 'max':
            return max(values)
        else:
            return min(values)
```
- è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ‰€æœ‰æŒ‡æ ‡
- æ”¯æŒè·å–å†å²è®°å½•ã€æœ€æ–°å€¼ã€æœ€ä½³å€¼
- æä¾›ä¿å­˜å’ŒåŠ è½½å†å²è®°å½•çš„åŠŸèƒ½

**ç¬¬181-250è¡Œï¼šVisualizationUtilsç±»**
```python
class VisualizationUtils:
    """å¯è§†åŒ–å·¥å…·ç±»"""
    
    @staticmethod
    def plot_training_metrics(history: Dict[str, List[float]], 
                            save_path: Optional[str] = None):
        """ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡æ›²çº¿"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('è®­ç»ƒè¿‡ç¨‹ç›‘æ§', fontsize=16)
        
        # æŸå¤±æ›²çº¿
        if 'loss' in history and 'val_loss' in history:
            axes[0, 0].plot(history['loss'], label='è®­ç»ƒæŸå¤±')
            axes[0, 0].plot(history['val_loss'], label='éªŒè¯æŸå¤±')
            axes[0, 0].set_title('æŸå¤±æ›²çº¿')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].legend()
            axes[0, 0].grid(True)
        
        # DiceæŒ‡æ ‡æ›²çº¿
        if 'dice' in history and 'val_dice' in history:
            axes[0, 1].plot(history['dice'], label='è®­ç»ƒDice')
            axes[0, 1].plot(history['val_dice'], label='éªŒè¯Dice')
            axes[0, 1].set_title('Diceç³»æ•°æ›²çº¿')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Dice Score')
            axes[0, 1].legend()
            axes[0, 1].grid(True)
        
        # å­¦ä¹ ç‡æ›²çº¿
        if 'learning_rate' in history:
            axes[1, 0].plot(history['learning_rate'], label='å­¦ä¹ ç‡')
            axes[1, 0].set_title('å­¦ä¹ ç‡å˜åŒ–')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Learning Rate')
            axes[1, 0].legend()
            axes[1, 0].grid(True)
        
        # Hausdorffè·ç¦»æ›²çº¿
        if 'hausdorff' in history and 'val_hausdorff' in history:
            axes[1, 1].plot(history['hausdorff'], label='è®­ç»ƒHD')
            axes[1, 1].plot(history['val_hausdorff'], label='éªŒè¯HD')
            axes[1, 1].set_title('Hausdorffè·ç¦»æ›²çº¿')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Hausdorff Distance')
            axes[1, 1].legend()
            axes[1, 1].grid(True)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()

**ç¬¬251-280è¡Œï¼šæ—¶é—´æ ¼å¼åŒ–å‡½æ•°**
```python
def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        minutes = seconds / 60
        return f"{minutes:.1f}åˆ†é’Ÿ"
    else:
        hours = seconds / 3600
        return f"{hours:.1f}å°æ—¶"
```
- å°†ç§’æ•°è½¬æ¢ä¸ºæ˜“è¯»çš„æ—¶é—´æ ¼å¼
- è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ—¶é—´å•ä½
- ç”¨äºæ˜¾ç¤ºè®­ç»ƒå’Œè¯„ä¼°è€—æ—¶

**ç¬¬281-320è¡Œï¼šæµ‹è¯•ä»£ç **
```python
if __name__ == "__main__":
    print("=" * 50)
    print("ğŸ”§ å·¥å…·ç±»æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•æ—©åœæœºåˆ¶
    print("\n1. æµ‹è¯•æ—©åœæœºåˆ¶:")
    early_stopping = EarlyStopping(patience=3, min_delta=0.01, mode='min')
    test_losses = [1.0, 0.8, 0.7, 0.71, 0.72, 0.73]  # æ¨¡æ‹ŸæŸå¤±å€¼
    
    for epoch, loss in enumerate(test_losses):
        should_stop = early_stopping(loss)
        print(f"  Epoch {epoch}: Loss={loss:.2f}, æ—©åœ={should_stop}")
        if should_stop:
            break
    
    # æµ‹è¯•æŒ‡æ ‡è·Ÿè¸ªå™¨
    print("\n2. æµ‹è¯•æŒ‡æ ‡è·Ÿè¸ªå™¨:")
    tracker = MetricsTracker()
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    for epoch in range(5):
        metrics = {
            'loss': 1.0 - epoch * 0.1,
            'dice': 0.5 + epoch * 0.1,
            'val_loss': 1.1 - epoch * 0.08,
            'val_dice': 0.45 + epoch * 0.08
        }
        tracker.update(metrics)
    
    print(f"  æœ€æ–°æŒ‡æ ‡: {tracker.get_latest()}")
    print(f"  æœ€ä½³Dice: {tracker.get_best('dice', 'max'):.3f}")
    
    # æµ‹è¯•æ—¶é—´æ ¼å¼åŒ–
    print("\n3. æµ‹è¯•æ—¶é—´æ ¼å¼åŒ–:")
    test_times = [30, 150, 3720, 7380]
    for t in test_times:
        print(f"  {t}ç§’ = {format_time(t)}")
    
    print("\nâœ… æ‰€æœ‰å·¥å…·ç±»å·²å‡†å¤‡å°±ç»ª!")
    print("\nğŸ“ æ³¨æ„: é…ç½®ç®¡ç†åŠŸèƒ½å·²æ•´åˆåˆ°main.pyä¸­çš„get_high_performance_configå‡½æ•°")
```
- å®Œæ•´çš„å·¥å…·ç±»åŠŸèƒ½æµ‹è¯•
- éªŒè¯æ—©åœæœºåˆ¶ã€æŒ‡æ ‡è·Ÿè¸ªå™¨å’Œæ—¶é—´æ ¼å¼åŒ–åŠŸèƒ½
- æä¾›ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•ç»“æœ

## ä½¿ç”¨æ–¹æ³•

### 1. æ•°æ®å‡†å¤‡

ç¡®ä¿ä½ çš„BraTSæ•°æ®é›†æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç»„ç»‡ï¼š

```
BraTS_data/
â”œâ”€â”€ BraTS-GLI-00000-000/
â”‚   â”œâ”€â”€ BraTS-GLI-00000-000-t1n.nii.gz    # T1 native
â”‚   â”œâ”€â”€ BraTS-GLI-00000-000-t1c.nii.gz    # T1 contrast-enhanced  
â”‚   â”œâ”€â”€ BraTS-GLI-00000-000-t2w.nii.gz    # T2 weighted
â”‚   â”œâ”€â”€ BraTS-GLI-00000-000-t2f.nii.gz    # T2 FLAIR
â”‚   â””â”€â”€ BraTS-GLI-00000-000-seg.nii.gz    # åˆ†å‰²æ ‡æ³¨ï¼ˆè®­ç»ƒæ—¶å¿…éœ€ï¼‰
â”œâ”€â”€ BraTS-GLI-00001-000/
â”‚   â”œâ”€â”€ BraTS-GLI-00001-000-t1n.nii.gz
â”‚   â”œâ”€â”€ BraTS-GLI-00001-000-t1c.nii.gz
â”‚   â”œâ”€â”€ BraTS-GLI-00001-000-t2w.nii.gz
â”‚   â”œâ”€â”€ BraTS-GLI-00001-000-t2f.nii.gz
â”‚   â””â”€â”€ BraTS-GLI-00001-000-seg.nii.gz
â””â”€â”€ ...
```

**é‡è¦æç¤º**ï¼š
- æ•°æ®é›†ä¼šè‡ªåŠ¨æŒ‰8:2æ¯”ä¾‹åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
- æ–‡ä»¶å‘½åå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼
- åˆ†å‰²æ–‡ä»¶åœ¨è®­ç»ƒæ—¶å¿…éœ€ï¼Œè¯„ä¼°æ—¶å¯é€‰

### 2. è®­ç»ƒæ¨¡å‹

#### åŸºç¡€è®­ç»ƒ
```bash
# ä½¿ç”¨é»˜è®¤UNetæ¨¡å‹è®­ç»ƒ
python main.py --mode train --data_dir /path/to/BraTS_data

# æŒ‡å®šç‰¹å®šæ¨¡å‹
python main.py --mode train --model_name SegResNet --data_dir /path/to/BraTS_data

# è‡ªå®šä¹‰è®­ç»ƒå‚æ•°
python main.py --mode train \
    --model_name UNet \
    --epochs 200 \
    --batch_size 4 \
    --learning_rate 1e-4 \
    --data_dir /path/to/BraTS_data \
    --output_dir ./my_outputs
```

#### å¤šæ¨¡å‹è®­ç»ƒ

é¡¹ç›®æ”¯æŒä¸¤ç§å¤šæ¨¡å‹è®­ç»ƒæ¨¡å¼ï¼š

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

ä»¥ä¸‹æ˜¯6ç§ä¸»è¦çš„è®­ç»ƒæ¨¡å¼ï¼Œå±•ç¤ºäº†ä¸åŒå‚æ•°ç»„åˆçš„ä½¿ç”¨æ–¹æ³•ï¼š

**1. å¤šæ¨¡å‹å¹¶è¡Œè®­ç»ƒ**ï¼š
```bash
# æŒ‡å®š3ä¸ªæ¨¡å‹ï¼Œé»˜è®¤parallel=trueï¼Œå¹¶è¡Œè®­ç»ƒ
python main.py --mode train --data_dir /path/to/BraTS_data --model_names UNet SegResNet UNETR
```

**2. å¤šæ¨¡å‹å¹¶è¡Œè®­ç»ƒï¼ˆæ˜¾å¼æŒ‡å®šï¼‰**ï¼š
```bash
# æŒ‡å®š3ä¸ªæ¨¡å‹ï¼Œæ˜¾å¼è®¾ç½®parallel=trueï¼Œå¹¶è¡Œè®­ç»ƒ
python main.py --mode train --data_dir /path/to/BraTS_data --model_names UNet SegResNet UNETR --parallel true
```

**3. å¤šæ¨¡å‹é€ä¸ªè®­ç»ƒ**ï¼š
```bash
# æŒ‡å®š3ä¸ªæ¨¡å‹ï¼Œè®¾ç½®parallel=falseï¼Œé€ä¸ªè®­ç»ƒ
python main.py --mode train --data_dir /path/to/BraTS_data --model_names UNet SegResNet UNETR --parallel false
```



**å‚æ•°è¯´æ˜**ï¼š
- `--model_names`: æŒ‡å®šè¦è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨
- `--parallel`: æ§åˆ¶è®­ç»ƒæ–¹å¼ï¼Œtrueï¼ˆé»˜è®¤ï¼‰ä¸ºå¹¶è¡Œè®­ç»ƒï¼Œfalseä¸ºé€ä¸ªè®­ç»ƒ



### 3. æ¨¡å‹è¯„ä¼°

```bash
# è¯„ä¼°å•ä¸ªæ¨¡å‹
python main.py --mode eval \
    --model_path ./outputs/checkpoints/best_model.pth \
    --data_dir /path/to/BraTS_data

# è¯„ä¼°é«˜çº§æ¨¡å‹
python main.py --mode eval \
    --model_path ./outputs/checkpoints/best_model.pth \
    --data_dir /path/to/BraTS_data

# è‡ªå®šä¹‰è¾“å‡ºç›®å½•
python main.py --mode eval \
    --model_path ./outputs/checkpoints/best_model.pth \
    --data_dir /path/to/BraTS_data \
    --output_dir ./my_evaluation_results

# æŒ‡å®šè®¾å¤‡è¯„ä¼°
python main.py --mode eval \
    --model_path ./outputs/checkpoints/best_model.pth \
    --data_dir /path/to/BraTS_data \
    --device cpu

# ä½¿ç”¨è‡ªåŠ¨è®¾å¤‡æ£€æµ‹
python main.py --mode eval \
    --model_path ./outputs/checkpoints/best_model.pth \
    --data_dir /path/to/BraTS_data \
    --device auto
```

### 4. æ”¯æŒçš„æ¨¡å‹æ¶æ„

é¡¹ç›®æ”¯æŒä»¥ä¸‹æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼š

- **UNet**: ç»å…¸çš„Uå‹ç½‘ç»œï¼Œé€‚åˆåŒ»å­¦å›¾åƒåˆ†å‰²
- **SegResNet**: åŸºäºResNetçš„åˆ†å‰²ç½‘ç»œ
- **UNETR**: åŸºäºTransformerçš„Uå‹ç½‘ç»œ
- **SwinUNETR**: åŸºäºSwin Transformerçš„åˆ†å‰²ç½‘ç»œ
- **AttentionUNet**: å¸¦æ³¨æ„åŠ›æœºåˆ¶çš„Uå‹ç½‘ç»œ
- **VNet**: ä¸“ä¸º3DåŒ»å­¦å›¾åƒè®¾è®¡çš„ç½‘ç»œ
- **HighResNet**: é«˜åˆ†è¾¨ç‡ç½‘ç»œ

### 5. è¾“å‡ºæ–‡ä»¶è¯´æ˜

è®­ç»ƒå®Œæˆåï¼Œä¼šåœ¨`./outputs`ç›®å½•ä¸‹ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
outputs/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ best_model.pth          # æœ€ä½³æ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ model_20240101_120000.pth # å¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶

â”œâ”€â”€ logs/
â”‚   â””â”€â”€ tensorboard_logs/       # TensorBoardæ—¥å¿—
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ training_history.json   # è®­ç»ƒå†å²è®°å½•
â”‚   â””â”€â”€ training_curves.png     # è®­ç»ƒæ›²çº¿å›¾
â””â”€â”€ visualizations/
    â””â”€â”€ sample_predictions.png  # æ ·æœ¬é¢„æµ‹å¯è§†åŒ–
```

#### é«˜çº§æ¨¡å‹ä¿å­˜è¯¦æƒ…

**æœ€ä½³æ¨¡å‹ä¿å­˜ä½ç½®**ï¼š`./outputs/checkpoints/best_model.pth`

æ¨¡å‹æ–‡ä»¶åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
- `model_state_dict`ï¼šæ¨¡å‹çŠ¶æ€å­—å…¸
- `optimizer_state_dict`ï¼šä¼˜åŒ–å™¨çŠ¶æ€
- `scheduler_state_dict`ï¼šè°ƒåº¦å™¨çŠ¶æ€  
- `best_metric`ï¼šæœ€ä½³éªŒè¯æŒ‡æ ‡ï¼ˆDiceåˆ†æ•°ï¼‰
- `config`ï¼šå®Œæ•´çš„è®­ç»ƒé…ç½®ä¿¡æ¯
- `is_advanced`ï¼šæ ‡è¯†ä¸ºé«˜çº§æ¨¡å‹ï¼ˆTrueï¼‰
- `model_name`ï¼šæ¨¡å‹åç§°
- `save_time`ï¼šä¿å­˜æ—¶é—´æˆ³
- `epoch`ï¼šä¿å­˜æ—¶çš„è®­ç»ƒè½®æ•°

**å¤‡ä»½æœºåˆ¶**ï¼š
- ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶
- æ ¼å¼ï¼š`model_YYYYMMDD_HHMMSS.pth`
- ä½ç½®ï¼šåŒæ ·åœ¨`./outputs/checkpoints/`ç›®å½•ä¸‹

**è‡ªå®šä¹‰ä¿å­˜è·¯å¾„**ï¼š
```bash
# è‡ªå®šä¹‰è¾“å‡ºç›®å½•
python main.py --mode train --output_dir ./my_custom_output
# æ¨¡å‹å°†ä¿å­˜åœ¨ï¼š./my_custom_output/checkpoints/best_model.pth
```

**è¯„ä¼°é«˜çº§æ¨¡å‹**ï¼š
```bash
python main.py --mode eval --model_path ./outputs/checkpoints/best_model.pth --data_dir /path/to/data
```

è¯„ä¼°å®Œæˆåï¼Œä¼šåœ¨æŒ‡å®šçš„è¾“å‡ºç›®å½•ä¸‹ç”Ÿæˆï¼š

```
evaluation_results/
â”œâ”€â”€ case_results.csv           # æ¯ä¸ªæ¡ˆä¾‹çš„è¯¦ç»†ç»“æœ
â”œâ”€â”€ summary_results.txt        # æ€»ä½“ç»Ÿè®¡ç»“æœ
â”œâ”€â”€ results_distribution.png   # ç»“æœåˆ†å¸ƒå›¾
â””â”€â”€ visualizations/
    â”œâ”€â”€ case_001_prediction.png
    â”œâ”€â”€ case_002_prediction.png
    â””â”€â”€ ...
```

### 6. æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### GPUå†…å­˜ä¼˜åŒ–
- å¦‚æœé‡åˆ°GPUå†…å­˜ä¸è¶³ï¼Œå¯ä»¥å‡å°`batch_size`
- ä½¿ç”¨`--auto_adjust`å‚æ•°è‡ªåŠ¨è°ƒæ•´å‚æ•°
- é™ä½`cache_rate`å‡å°‘å†…å­˜å ç”¨

#### è®­ç»ƒé€Ÿåº¦ä¼˜åŒ–
- ä½¿ç”¨æ›´å¤šçš„`num_workers`åŠ é€Ÿæ•°æ®åŠ è½½
- å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰
- ä½¿ç”¨SSDå­˜å‚¨æ•°æ®é›†

#### æ¨¡å‹æ€§èƒ½ä¼˜åŒ–
- ä½¿ç”¨é«˜çº§æ¨¡å‹æ¶æ„æé«˜å‡†ç¡®æ€§
- è°ƒæ•´å­¦ä¹ ç‡å’Œä¼˜åŒ–å™¨å‚æ•°
- ä½¿ç”¨æ•°æ®å¢å¼ºæé«˜æ³›åŒ–èƒ½åŠ›

### 7. å¸¸è§é—®é¢˜è§£å†³

#### æ•°æ®åŠ è½½é—®é¢˜
```bash
# æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„
python -c "from DatasetLoader_transforms import DatasetLoader; loader = DatasetLoader('/path/to/data'); print('æ•°æ®æ£€æŸ¥å®Œæˆ')"
```

#### æ¨¡å‹åŠ è½½é—®é¢˜
```bash
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
python -c "import torch; checkpoint = torch.load('model.pth', map_location='cpu'); print('æ¨¡å‹æ–‡ä»¶æ­£å¸¸')"
```

#### è®¾å¤‡é…ç½®é—®é¢˜
```bash
# æ£€æŸ¥CUDAå¯ç”¨æ€§
python -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPUæ•°é‡: {torch.cuda.device_count()}')"
```

## é¡¹ç›®ç‰¹ç‚¹

1. **æ¨¡å—åŒ–è®¾è®¡**: æ¸…æ™°çš„ä»£ç ç»“æ„ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
2. **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒ7ç§ä¸åŒçš„æ·±åº¦å­¦ä¹ æ¶æ„
3. **é«˜çº§æ¶æ„**: æ”¯æŒå¤šç§é«˜çº§æ¨¡å‹æ¶æ„æé«˜æ€§èƒ½
4. **è‡ªåŠ¨ä¼˜åŒ–**: æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨è°ƒæ•´å‚æ•°
5. **å®Œæ•´è¯„ä¼°**: å¤šç§è¯„ä¼°æŒ‡æ ‡å’Œå¯è§†åŒ–
6. **æ˜“äºä½¿ç”¨**: ç®€å•çš„å‘½ä»¤è¡Œæ¥å£
7. **é«˜æ€§èƒ½**: ä¼˜åŒ–çš„æ•°æ®åŠ è½½å’Œè®­ç»ƒæµç¨‹

## æŠ€æœ¯æ ˆ

- **æ·±åº¦å­¦ä¹ æ¡†æ¶**: PyTorch + MONAI
- **æ•°æ®å¤„ç†**: NumPy + NiBabel
- **å¯è§†åŒ–**: Matplotlib + TensorBoard
- **æ•°æ®åˆ†æ**: Pandas
- **è¿›åº¦æ˜¾ç¤º**: tqdm

## æ¨¡å‹éƒ¨ç½²

è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥å°†é«˜çº§æ¨¡å‹éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒä¸­è¿›è¡Œå®é™…åº”ç”¨ã€‚é¡¹ç›®æä¾›äº†å®Œæ•´çš„éƒ¨ç½²è§£å†³æ–¹æ¡ˆã€‚

### å¿«é€Ÿéƒ¨ç½²

#### å•æ–‡ä»¶æ¨ç†
```bash
# å¯¹å•ä¸ªåŒ»å­¦å›¾åƒè¿›è¡Œåˆ†å‰²é¢„æµ‹
python deploy.py \
    --model_path ./outputs/checkpoints/best_model.pth \
    --input_file /path/to/input.nii.gz \
    --output_file /path/to/output.nii.gz
```

#### æ‰¹é‡æ¨ç†
```bash
# æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶
python deploy.py \
    --model_path ./outputs/checkpoints/best_model.pth \
    --input_dir /path/to/input_directory \
    --output_dir /path/to/output_directory
```

#### APIæœåŠ¡éƒ¨ç½²
```bash
# å¯åŠ¨REST APIæœåŠ¡
python deploy.py \
    --model_path ./outputs/checkpoints/best_model.pth \
    --api_mode \
    --port 8080

# ä½¿ç”¨APIè¿›è¡Œé¢„æµ‹
curl -X POST \
  -F "file=@input_image.nii.gz" \
  http://localhost:8080/predict \
  -o prediction_result.nii.gz
```

### Dockerå®¹å™¨åŒ–éƒ¨ç½²

```bash
# æ„å»ºDockeré•œåƒ
docker build -t brats-model:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
    --name brats-api \
    --gpus all \
    -p 8080:8080 \
    -v $(pwd)/outputs/checkpoints:/app/models:ro \
    brats-model:latest

# æˆ–ä½¿ç”¨Docker Compose
docker-compose up -d
```

### éƒ¨ç½²ç‰¹æ€§

- **å¤šç§éƒ¨ç½²æ–¹å¼**: æœ¬åœ°éƒ¨ç½²ã€Dockerå®¹å™¨åŒ–ã€Kubernetesé›†ç¾¤
- **REST APIæ¥å£**: æ ‡å‡†HTTPæ¥å£ï¼Œæ˜“äºé›†æˆ
- **è‡ªåŠ¨è®¾å¤‡æ£€æµ‹**: è‡ªåŠ¨é€‰æ‹©CPU/GPUè¿›è¡Œæ¨ç†
- **æ‰¹é‡å¤„ç†**: æ”¯æŒå¤§è§„æ¨¡æ•°æ®å¤„ç†
- **å¥åº·æ£€æŸ¥**: å†…ç½®æœåŠ¡ç›‘æ§å’Œå¥åº·æ£€æŸ¥
- **æ—¥å¿—è®°å½•**: å®Œæ•´çš„æ¨ç†æ—¥å¿—å’Œé”™è¯¯è¿½è¸ª
- **æ€§èƒ½ä¼˜åŒ–**: æ»‘åŠ¨çª—å£æ¨ç†å’Œå†…å­˜ä¼˜åŒ–

### APIæ¥å£

| æ¥å£ | æ–¹æ³• | æè¿° |
|------|------|------|
| `/health` | GET | å¥åº·æ£€æŸ¥ |
| `/info` | GET | æ¨¡å‹ä¿¡æ¯ |
| `/predict` | POST | å›¾åƒåˆ†å‰²é¢„æµ‹ |

### è¯¦ç»†éƒ¨ç½²æŒ‡å—

å®Œæ•´çš„éƒ¨ç½²æ–‡æ¡£è¯·å‚è€ƒ [DEPLOYMENT.md](DEPLOYMENT.md)ï¼ŒåŒ…å«ï¼š

- ç¯å¢ƒè¦æ±‚å’Œé…ç½®
- å¤šç§éƒ¨ç½²æ–¹å¼è¯¦è§£
- æ€§èƒ½ä¼˜åŒ–å»ºè®®
- ç›‘æ§å’Œç»´æŠ¤æŒ‡å—
- æ•…éšœæ’é™¤æ–¹æ¡ˆ
- å®‰å…¨é…ç½®å»ºè®®

