import os
import torch
import torch.nn as nn
import torch.optim as optim
from typing import Dict, List, Tuple, Any, Optional
from monai.networks.nets import UNet, SegResNet, UNETR, SwinUNETR, AttentionUnet, VNet, HighResNet
from monai.losses import DiceCELoss, FocalLoss, TverskyLoss, GeneralizedDiceLoss, DiceFocalLoss
from monai.metrics import DiceMetric, HausdorffDistanceMetric, SurfaceDistanceMetric, ConfusionMatrixMetric, MeanIoU, GeneralizedDiceScore
from monai.inferers import sliding_window_inference

from knowledge_distillation import (
    KnowledgeDistillationLoss, 
    MultiTeacherDistillation, 
    ProgressiveKnowledgeDistillation
)
from fusion_architectures import FusionNetworkArchitecture
from nas_search import (
    SuperNet,
    DARTSSearcher,
    ProgressiveNAS
)


class BasicModelBank:
    """
    ç®€åŒ–çš„åˆ†å‰²æ¨¡å‹ï¼Œæ”¯æŒåŸºç¡€æ¨¡å‹æ¶æ„å’Œå¤šç§æŸå¤±å‡½æ•°ç­–ç•¥
    æ”¯æŒå¤šæ•°æ®é›†åŠ¨æ€é€šé“é…ç½®
    """
    def __init__(self, model_name: str = 'UNet', device: str = 'auto', dataset_type: str = 'BraTS'):
        self.model_name = model_name
        self.device = self._setup_device(device)
        self.dataset_type = dataset_type
        self.in_channels, self.out_channels = self._get_dataset_channels(dataset_type)
        self.model = self._create_model()
        self.loss_function = self._create_adaptive_loss()
        self.metrics = self._create_metrics()
        
    def _get_dataset_channels(self, dataset_type: str) -> Tuple[int, int]:
        """æ ¹æ®æ•°æ®é›†ç±»å‹è·å–è¾“å…¥è¾“å‡ºé€šé“æ•°"""
        dataset_configs = {
            'BraTS': {'in_channels': 4, 'out_channels': 4},  # T1, T1ce, T2, FLAIR -> ET, TC, WT, Background
            'MS_MultiSpine': {'in_channels': 2, 'out_channels': 6}  # T2, STIR/PSIR/MP2RAGE -> 6 lesion classes
        }
        
        if dataset_type not in dataset_configs:
            print(f"è­¦å‘Š: æœªçŸ¥æ•°æ®é›†ç±»å‹ '{dataset_type}'ï¼Œä½¿ç”¨BraTSé»˜è®¤é…ç½®")
            dataset_type = 'BraTS'
            
        config = dataset_configs[dataset_type]
        print(f"æ•°æ®é›†é…ç½® - {dataset_type}: è¾“å…¥é€šé“={config['in_channels']}, è¾“å‡ºé€šé“={config['out_channels']}")
        return config['in_channels'], config['out_channels']
        
    def _setup_device(self, device) -> torch.device:
        """è®¾ç½®è®¾å¤‡"""
        # å¦‚æœå·²ç»æ˜¯torch.deviceå¯¹è±¡ï¼Œç›´æ¥è¿”å›
        if isinstance(device, torch.device):
            return device
        
        # å¤„ç†å­—ç¬¦ä¸²ç±»å‹çš„è®¾å¤‡å‚æ•°
        if device == 'auto':
            return torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        elif str(device).lower() == 'cpu':
            return torch.device('cpu')
        elif str(device).lower() == 'cuda':
            if torch.cuda.is_available():
                return torch.device('cuda')
            else:
                print("è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPU")
                return torch.device('cpu')
        else:
            return torch.device(device)
        
    def _create_model(self):
        """åˆ›å»ºæ¨¡å‹"""
        if self.model_name == 'UNet':
            model = UNet(
                spatial_dims=3,
                in_channels=self.in_channels,
                out_channels=self.out_channels,
                channels=(32, 64, 128, 256, 512),
                strides=(2, 2, 2, 2),
                num_res_units=2,
                norm="instance",
                dropout=0.1
            )
        elif self.model_name == 'SegResNet':
            model = SegResNet(
                spatial_dims=3,
                init_filters=32,
                in_channels=self.in_channels,
                out_channels=self.out_channels,
                dropout_prob=0.1,
                act=("RELU", {"inplace": True}),
                norm=("GROUP", {"num_groups": 8}),
                blocks_down=(1, 2, 2, 4),
                blocks_up=(1, 1, 1),
                upsample_mode="nontrainable"
            )
        elif self.model_name == 'UNETR':
            model = UNETR(
                in_channels=self.in_channels,
                out_channels=self.out_channels,
                img_size=(128, 128, 128),
                feature_size=16,
                hidden_size=768,
                mlp_dim=3072,
                num_heads=12,
                proj_type="conv",
                norm_name="instance",
                conv_block=True,
                res_block=True,
                dropout_rate=0.1,
                spatial_dims=3,
                qkv_bias=False,
                save_attn=False
            )
        elif self.model_name == 'SwinUNETR':
            model = SwinUNETR(
                in_channels=self.in_channels,
                out_channels=self.out_channels,
                feature_size=48,
                depths=(2, 2, 2, 2),
                num_heads=(3, 6, 12, 24),
                norm_name="instance",
                drop_rate=0.0,
                attn_drop_rate=0.0,
                dropout_path_rate=0.0,
                normalize=True,
                use_checkpoint=False,
                spatial_dims=3,
                downsample="merging",
                use_v2=False
            )
        elif self.model_name == 'AttentionUNet':
            model = AttentionUnet(
                spatial_dims=3,
                in_channels=self.in_channels,
                out_channels=self.out_channels,
                channels=(32, 64, 128, 256),
                strides=(2, 2, 2),
                dropout=0.1
            )
        elif self.model_name == 'VNet':
            model = VNet(
                spatial_dims=3,
                in_channels=self.in_channels,
                out_channels=self.out_channels,
                act=("elu", {"inplace": True}),
                dropout_prob_down=0.5,
                dropout_prob_up=(0.5, 0.5),
                dropout_dim=3,
                bias=False
            )
        elif self.model_name == 'HighResNet':
            model = HighResNet(
                spatial_dims=3,
                in_channels=self.in_channels,
                out_channels=self.out_channels,
                norm_type=("batch", {"affine": True}),
                acti_type=("relu", {"inplace": True}),
                dropout_prob=0.1,
                bias=False,
                layer_params=(
                    {"name": "conv_0", "n_features": 16, "kernel_size": 3},
                    {"name": "res_1", "n_features": 16, "kernels": (3, 3), "repeat": 3},
                    {"name": "res_2", "n_features": 32, "kernels": (3, 3), "repeat": 3},
                    {"name": "res_3", "n_features": 64, "kernels": (3, 3), "repeat": 3},
                    {"name": "conv_1", "n_features": 80, "kernel_size": 1},
                    {"name": "conv_2", "kernel_size": 1},
                ),
                channel_matching="pad"
            )
        elif self.model_name == 'VNet3D':
            model = self._create_vnet3d()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_name}")
            
        return model.to(self.device)
    
    def _create_vnet3d(self):
        """
        åˆ›å»ºè‡ªå®šä¹‰VNet3Dç½‘ç»œæ¶æ„
        åŸºäºV-Netè®¾è®¡ï¼Œé’ˆå¯¹3DåŒ»å­¦å›¾åƒåˆ†å‰²ä¼˜åŒ–
        """
        class VNet3DBlock(nn.Module):
            def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
                super().__init__()
                self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)
                self.bn1 = nn.BatchNorm3d(out_channels)
                self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size, 1, padding)
                self.bn2 = nn.BatchNorm3d(out_channels)
                self.relu = nn.ReLU(inplace=True)
                
                # æ®‹å·®è¿æ¥
                if in_channels != out_channels or stride != 1:
                    self.shortcut = nn.Sequential(
                        nn.Conv3d(in_channels, out_channels, 1, stride),
                        nn.BatchNorm3d(out_channels)
                    )
                else:
                    self.shortcut = nn.Identity()
                    
            def forward(self, x):
                residual = self.shortcut(x)
                out = self.relu(self.bn1(self.conv1(x)))
                out = self.bn2(self.conv2(out))
                out += residual
                return self.relu(out)
        
        class VNet3D(nn.Module):
            def __init__(self, in_channels, out_channels):
                super().__init__()
                
                # ç¼–ç å™¨
                self.encoder1 = VNet3DBlock(in_channels, 32)
                self.encoder2 = VNet3DBlock(32, 64, stride=2)
                self.encoder3 = VNet3DBlock(64, 128, stride=2)
                self.encoder4 = VNet3DBlock(128, 256, stride=2)
                self.encoder5 = VNet3DBlock(256, 512, stride=2)
                
                # ç“¶é¢ˆå±‚
                self.bottleneck = VNet3DBlock(512, 1024, stride=2)
                
                # è§£ç å™¨
                self.upconv5 = nn.ConvTranspose3d(1024, 512, 2, 2)
                self.decoder5 = VNet3DBlock(1024, 512)  # 512 + 512 from skip connection
                
                self.upconv4 = nn.ConvTranspose3d(512, 256, 2, 2)
                self.decoder4 = VNet3DBlock(512, 256)  # 256 + 256 from skip connection
                
                self.upconv3 = nn.ConvTranspose3d(256, 128, 2, 2)
                self.decoder3 = VNet3DBlock(256, 128)  # 128 + 128 from skip connection
                
                self.upconv2 = nn.ConvTranspose3d(128, 64, 2, 2)
                self.decoder2 = VNet3DBlock(128, 64)  # 64 + 64 from skip connection
                
                self.upconv1 = nn.ConvTranspose3d(64, 32, 2, 2)
                self.decoder1 = VNet3DBlock(64, 32)  # 32 + 32 from skip connection
                
                # è¾“å‡ºå±‚
                self.final_conv = nn.Conv3d(32, out_channels, 1)
                
                # Dropoutå±‚
                self.dropout = nn.Dropout3d(0.1)
                
            def forward(self, x):
                # ç¼–ç å™¨è·¯å¾„
                enc1 = self.encoder1(x)
                enc2 = self.encoder2(enc1)
                enc3 = self.encoder3(enc2)
                enc4 = self.encoder4(enc3)
                enc5 = self.encoder5(enc4)
                
                # ç“¶é¢ˆå±‚
                bottleneck = self.bottleneck(enc5)
                bottleneck = self.dropout(bottleneck)
                
                # è§£ç å™¨è·¯å¾„
                dec5 = self.upconv5(bottleneck)
                dec5 = torch.cat([dec5, enc5], dim=1)
                dec5 = self.decoder5(dec5)
                dec5 = self.dropout(dec5)
                
                dec4 = self.upconv4(dec5)
                dec4 = torch.cat([dec4, enc4], dim=1)
                dec4 = self.decoder4(dec4)
                
                dec3 = self.upconv3(dec4)
                dec3 = torch.cat([dec3, enc3], dim=1)
                dec3 = self.decoder3(dec3)
                
                dec2 = self.upconv2(dec3)
                dec2 = torch.cat([dec2, enc2], dim=1)
                dec2 = self.decoder2(dec2)
                
                dec1 = self.upconv1(dec2)
                dec1 = torch.cat([dec1, enc1], dim=1)
                dec1 = self.decoder1(dec1)
                
                # è¾“å‡º
                output = self.final_conv(dec1)
                
                return output
        
        return VNet3D(self.in_channels, self.out_channels)
    
    def _create_adaptive_loss(self):
        """åˆ›å»ºè‡ªé€‚åº”æŸå¤±å‡½æ•°è°ƒåº¦å™¨"""
        class AdaptiveLossScheduler:
            def __init__(self, parent):
                self.parent = parent
                self.losses = {
                    'dice_ce': DiceCELoss(to_onehot_y=True, softmax=True, reduction="mean", include_background=True),
                    'focal': FocalLoss(to_onehot_y=True, gamma=2.0, reduction="mean", include_background=True),
                    'tversky': TverskyLoss(to_onehot_y=True, softmax=True, alpha=0.3, beta=0.7, reduction="mean", include_background=True),
                    'generalized_dice': GeneralizedDiceLoss(to_onehot_y=True, softmax=True, reduction="mean", include_background=True),
                    'dice_focal': DiceFocalLoss(to_onehot_y=True, softmax=True, gamma=2.0, reduction="mean", include_background=True)
                }
                self.current_epoch = 0
                self.total_epochs = 100
                
            def set_epoch(self, epoch, total_epochs=None):
                self.current_epoch = epoch
                if total_epochs is not None:
                    self.total_epochs = total_epochs
                    
            def _calculate_adaptive_weights(self, progress):
                """æ ¹æ®è®­ç»ƒè¿›åº¦è‡ªé€‚åº”è°ƒæ•´æƒé‡"""
                if progress < 0.2:  # å‰20%: ä¸»è¦ä½¿ç”¨DiceCE
                    return {'dice_ce': 0.7, 'focal': 0.2, 'tversky': 0.1, 'generalized_dice': 0.0, 'dice_focal': 0.0}
                elif progress < 0.4:  # 20%-40%: å¢åŠ Focalæƒé‡
                    return {'dice_ce': 0.5, 'focal': 0.3, 'tversky': 0.1, 'generalized_dice': 0.1, 'dice_focal': 0.0}
                elif progress < 0.6:  # 40%-60%: å¹³è¡¡å„æŸå¤±
                    return {'dice_ce': 0.3, 'focal': 0.3, 'tversky': 0.2, 'generalized_dice': 0.1, 'dice_focal': 0.1}
                elif progress < 0.8:  # 60%-80%: å¢åŠ Tverskyæƒé‡
                    return {'dice_ce': 0.2, 'focal': 0.2, 'tversky': 0.4, 'generalized_dice': 0.1, 'dice_focal': 0.1}
                else:  # æœ€å20%: ç»„åˆæ‰€æœ‰æŸå¤±
                    return {'dice_ce': 0.2, 'focal': 0.2, 'tversky': 0.2, 'generalized_dice': 0.2, 'dice_focal': 0.2}
                    
            def __call__(self, pred, target):
                progress = self.current_epoch / self.total_epochs if self.total_epochs > 0 else 0
                weights = self._calculate_adaptive_weights(progress)
                
                total_loss = 0
                for name, weight in weights.items():
                    if weight > 0:
                        total_loss += weight * self.losses[name](pred, target)
                        
                return total_loss
                    
        return AdaptiveLossScheduler(self)
        
    def _create_metrics(self):
        """åˆ›å»ºè¯„ä¼°æŒ‡æ ‡"""
        metrics = {
            'dice': DiceMetric(
                include_background=False,
                reduction="mean_batch",
                get_not_nans=False
            ),
            'hausdorff': HausdorffDistanceMetric(
                include_background=False,
                distance_metric='euclidean',
                percentile=95,
                directed=False,
                reduction="mean_batch"
            ),
            'surface_distance': SurfaceDistanceMetric(
                include_background=False,
                symmetric=True,
                reduction="mean_batch"
            ),
            'confusion_matrix': ConfusionMatrixMetric(
                include_background=False,
                metric_name="sensitivity",
                compute_sample=True,
                reduction="mean_batch"
            ),
            'mean_iou': MeanIoU(
                include_background=False,
                reduction="mean_batch"
            ),
            'generalized_dice_score': GeneralizedDiceScore(
                include_background=False,
                reduction="mean_batch"
            ),
            'froc': self._create_froc_metric()
        }
        
        return metrics
    
    def _create_froc_metric(self):
        """åŠ¨æ€åˆ›å»ºFROCæŒ‡æ ‡ä»¥é¿å…å¾ªç¯å¯¼å…¥"""
        try:
            from evaluate import FROCMetric
            return FROCMetric(
                distance_threshold=5.0,
                include_background=False
            )
        except ImportError:
            print("è­¦å‘Š: æ— æ³•å¯¼å…¥FROCMetricï¼Œè·³è¿‡FROCæŒ‡æ ‡")
            return None
        
    def get_model(self):
        """è·å–æ¨¡å‹"""
        return self.model
        
    def get_loss_function(self):
        """è·å–æŸå¤±å‡½æ•°"""
        return self.loss_function
        
    def get_metrics(self):
        """è·å–è¯„ä¼°æŒ‡æ ‡"""
        return self.metrics
    
    def update_loss_epoch(self, epoch: int, total_epochs: int = None):
        """æ›´æ–°è‡ªé€‚åº”æŸå¤±å‡½æ•°çš„epochä¿¡æ¯"""
        if hasattr(self.loss_function, 'set_epoch'):
            self.loss_function.set_epoch(epoch, total_epochs)
    
    def get_loss_info(self) -> Dict[str, Any]:
        """è·å–æŸå¤±å‡½æ•°ä¿¡æ¯"""
        info = {
            'strategy': 'adaptive_combined',
            'type': 'adaptive_multiple',
            'description': 'Adaptive combination of all loss functions with dynamic weights'
        }
        return info
        
    def sliding_window_inference(self, inputs: torch.Tensor, 
                                roi_size: Tuple = (128, 128, 128),
                                sw_batch_size: int = 4,
                                overlap: float = 0.6) -> torch.Tensor:
        """æ»‘åŠ¨çª—å£æ¨ç†"""
        return sliding_window_inference(
            inputs=inputs,
            roi_size=roi_size,
            sw_batch_size=sw_batch_size,
            predictor=self.model,
            overlap=overlap,
            mode="gaussian",
            sw_device=self.device,
            device=self.device
        )


def create_optimizer(model: nn.Module, 
                    optimizer_name: str = "AdamW",
                    learning_rate: float = 1e-4,
                    weight_decay: float = 1e-5) -> optim.Optimizer:
    """åˆ›å»ºä¼˜åŒ–å™¨"""
    if optimizer_name.lower() == "adam":
        return optim.Adam(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay
        )
    elif optimizer_name.lower() == "adamw":
        return optim.AdamW(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay
        )
    elif optimizer_name.lower() == "sgd":
        return optim.SGD(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay,
            momentum=0.9
        )
    else:
        return optim.AdamW(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay
        )


def create_scheduler(optimizer: optim.Optimizer,
                    scheduler_name: str = "CosineAnnealingLR",
                    **kwargs):
    """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
    if scheduler_name.lower() == "steplr":
        return optim.lr_scheduler.StepLR(
            optimizer,
            step_size=kwargs.get('step_size', 30),
            gamma=kwargs.get('gamma', 0.1)
        )
    elif scheduler_name.lower() == "cosineannealinglr":
        return optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=kwargs.get('T_max', 100)
        )
    elif scheduler_name.lower() == "reducelronplateau":
        return optim.lr_scheduler.ReduceLROnPlateau(
            optimizer,
            mode='min',
            factor=kwargs.get('factor', 0.5),
            patience=kwargs.get('patience', 10)
        )
    else:
        return optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=kwargs.get('T_max', 100)
        )

def get_all_supported_models() -> List[str]:
    """
    è·å–æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    """
    return ['UNet', 'SegResNet', 'UNETR', 'SwinUNETR', 'AttentionUNet', 'VNet', 'HighResNet', 'VNet3D']


class SpecializedModelFactory:
    """
    çŸ¥è¯†è’¸é¦ã€èåˆç½‘ç»œã€ç¥ç»æ¶æ„æœç´¢å’ŒNAS-è’¸é¦é›†æˆ
    æ”¯æŒå¤šæ•°æ®é›†åŠ¨æ€é€šé“é…ç½®
    """
    
    def __init__(self, 
                 model_type: str = 'fusion',  # 'fusion', 'distillation', 'nas', 'nas_distillation'
                 device: str = 'auto',
                 dataset_type: str = 'BraTS',
                 **kwargs):
        self.model_type = model_type
        self.device = self._setup_device(device)
        self.dataset_type = dataset_type
        self.kwargs = kwargs
        # å°†æ•°æ®é›†ç±»å‹ä¼ é€’ç»™kwargsï¼Œä¾›å­æ¨¡å‹ä½¿ç”¨
        self.kwargs['dataset_type'] = dataset_type
        self.model = self._create_advanced_model()
        
    def _setup_device(self, device) -> torch.device:
        """è®¾ç½®è®¾å¤‡"""
        if isinstance(device, torch.device):
            return device
        
        if device == 'auto':
            return torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        elif str(device).lower() == 'cpu':
            return torch.device('cpu')
        elif str(device).lower() == 'cuda':
            if torch.cuda.is_available():
                return torch.device('cuda')
            else:
                print("è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPU")
                return torch.device('cpu')
        else:
            return torch.device(device)
            
    def _create_advanced_model(self):
        """åˆ›å»ºå¤åˆæ¶æ„æ¨¡å‹"""
        if self.model_type == 'fusion':
            return self._create_fusion_model()
        elif self.model_type == 'distillation':
            return self._create_distillation_model()
        elif self.model_type == 'nas':
            return self._create_nas_model()
        elif self.model_type == 'nas_distillation':
            return self._create_nas_distillation_model()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¤åˆæ¶æ„æ¨¡å‹ç±»å‹: {self.model_type}")
            
    def _create_fusion_model(self):
        """åˆ›å»ºèåˆç½‘ç»œæ¨¡å‹"""
        # è·å–åŸºç¡€æ¨¡å‹åˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨æ‰€æœ‰7ä¸ªç½‘ç»œæ¶æ„
        base_model_names = self.kwargs.get('base_models', get_all_supported_models())
        base_models = []
        
        for model_name in base_model_names:
            basic_model = BasicModelBank(model_name=model_name, device=self.device, dataset_type=self.dataset_type)
            base_models.append(basic_model.model)
            
        # æ ¹æ®æ•°æ®é›†ç±»å‹è·å–è¾“å‡ºç±»åˆ«æ•°
        dataset_configs = {
            'BraTS': 4,
            'MS_MultiSpine': 6
        }
        default_num_classes = dataset_configs.get(self.dataset_type, 4)
        
        # åˆ›å»ºèåˆç½‘ç»œ
        fusion_model = FusionNetworkArchitecture(
            base_models=base_models,
            fusion_channels=self.kwargs.get('fusion_channels', [64, 128, 256, 512]),
            num_classes=self.kwargs.get('num_classes', default_num_classes),
            fusion_type=self.kwargs.get('fusion_type', 'cross_attention')
        )
        
        return fusion_model.to(self.device)
        
    def _create_distillation_model(self):
        """åˆ›å»ºçŸ¥è¯†è’¸é¦æ¨¡å‹"""
        distillation_type = self.kwargs.get('distillation_type', 'multi_teacher')
        
        if distillation_type == 'multi_teacher':
            # è·å–å­¦ç”Ÿæ¨¡å‹åç§°
            student_name = self.kwargs.get('student_model', 'VNet3D')
            
            # åˆ›å»ºæ•™å¸ˆæ¨¡å‹ï¼Œé»˜è®¤ä½¿ç”¨æ‰€æœ‰ç½‘ç»œæ¶æ„ä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼Œä½†æ’é™¤å­¦ç”Ÿæ¨¡å‹
            all_models = get_all_supported_models()
            teacher_names = self.kwargs.get('teacher_models', all_models)
            
            # ç¡®ä¿æ•™å¸ˆæ¨¡å‹åˆ—è¡¨ä¸­ä¸åŒ…å«å­¦ç”Ÿæ¨¡å‹ï¼Œé¿å…é‡å¤è®­ç»ƒ
            if isinstance(teacher_names, list):
                teacher_names = [name for name in teacher_names if name != student_name]
            
            # å¦‚æœè¿‡æ»¤åæ•™å¸ˆæ¨¡å‹åˆ—è¡¨ä¸ºç©ºï¼Œä½¿ç”¨é™¤å­¦ç”Ÿæ¨¡å‹å¤–çš„æ‰€æœ‰æ¨¡å‹
            if not teacher_names:
                teacher_names = [name for name in all_models if name != student_name]
                print(f"âš  è­¦å‘Šï¼šæ•™å¸ˆæ¨¡å‹åˆ—è¡¨ä¸ºç©ºï¼Œè‡ªåŠ¨ä½¿ç”¨é™¤å­¦ç”Ÿæ¨¡å‹({student_name})å¤–çš„æ‰€æœ‰æ¨¡å‹ä½œä¸ºæ•™å¸ˆæ¨¡å‹")
            
            print(f"ğŸ“š çŸ¥è¯†è’¸é¦é…ç½®ï¼š")
            print(f"  å­¦ç”Ÿæ¨¡å‹: {student_name}")
            print(f"  æ•™å¸ˆæ¨¡å‹: {teacher_names}")
            print(f"  æ•™å¸ˆæ¨¡å‹æ•°é‡: {len(teacher_names)}")
            
            teacher_models = []
            
            for teacher_name in teacher_names:
                teacher = BasicModelBank(model_name=teacher_name, device=self.device, dataset_type=self.dataset_type)
                
                # å°è¯•åŠ è½½é¢„è®­ç»ƒæƒé‡
                pretrained_dir = self.kwargs.get('pretrained_dir', './pretrained_teachers')
                pretrained_path = f"{pretrained_dir}/{teacher_name}_pretrained.pth"
                
                if os.path.exists(pretrained_path):
                    try:
                        print(f"åŠ è½½æ•™å¸ˆæ¨¡å‹ {teacher_name} çš„é¢„è®­ç»ƒæƒé‡: {pretrained_path}")
                        checkpoint = torch.load(pretrained_path, map_location=self.device)
                        
                        # å°è¯•ä¸åŒçš„æƒé‡é”®å
                        if 'model_state_dict' in checkpoint:
                            teacher.model.load_state_dict(checkpoint['model_state_dict'])
                        elif 'state_dict' in checkpoint:
                            teacher.model.load_state_dict(checkpoint['state_dict'])
                        else:
                            teacher.model.load_state_dict(checkpoint)
                        
                        print(f"âœ“ æˆåŠŸåŠ è½½æ•™å¸ˆæ¨¡å‹ {teacher_name} çš„é¢„è®­ç»ƒæƒé‡")
                        
                        # è·å–é¢„è®­ç»ƒæ€§èƒ½ä¿¡æ¯
                        if 'best_metric' in checkpoint:
                            print(f"  é¢„è®­ç»ƒæœ€ä½³æŒ‡æ ‡: {checkpoint['best_metric']:.4f}")
                            
                    except Exception as e:
                        print(f"âš  æ•™å¸ˆæ¨¡å‹ {teacher_name} é¢„è®­ç»ƒæƒé‡åŠ è½½å¤±è´¥: {e}")
                        print(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
                else:
                    print(f"âš  æœªæ‰¾åˆ°æ•™å¸ˆæ¨¡å‹ {teacher_name} çš„é¢„è®­ç»ƒæƒé‡: {pretrained_path}")
                    print(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
                
                teacher_models.append(teacher.model)
                
            # åˆ›å»ºå­¦ç”Ÿæ¨¡å‹ï¼ˆä½¿ç”¨ä¹‹å‰è·å–çš„student_nameï¼‰
            student = BasicModelBank(model_name=student_name, device=self.device, dataset_type=self.dataset_type)
            
            # åˆ›å»ºå¤šæ•™å¸ˆè’¸é¦æ¨¡å‹
            distillation_model = MultiTeacherDistillation(
                teacher_models=teacher_models,
                student_model=student.model,
                device=self.device,
                temperature=self.kwargs.get('temperature', 4.0)
            )
            
        elif distillation_type == 'progressive':
            # åˆ›å»ºæ¸è¿›å¼è’¸é¦æ¨¡å‹
            teacher_name = self.kwargs.get('teacher_model', 'UNETR')
            student_name = self.kwargs.get('student_model', 'VNet3D')
            
            # ç¡®ä¿æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹ä¸ç›¸åŒ
            if teacher_name == student_name:
                # å¦‚æœç›¸åŒï¼Œè‡ªåŠ¨é€‰æ‹©ä¸åŒçš„æ•™å¸ˆæ¨¡å‹
                all_models = get_all_supported_models()
                available_teachers = [name for name in all_models if name != student_name]
                if available_teachers:
                    teacher_name = available_teachers[0]  # é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ•™å¸ˆæ¨¡å‹
                    print(f"âš  è­¦å‘Šï¼šæ•™å¸ˆæ¨¡å‹ä¸å­¦ç”Ÿæ¨¡å‹ç›¸åŒï¼Œè‡ªåŠ¨é€‰æ‹© {teacher_name} ä½œä¸ºæ•™å¸ˆæ¨¡å‹")
                else:
                    raise ValueError(f"æ— æ³•æ‰¾åˆ°ä¸å­¦ç”Ÿæ¨¡å‹ {student_name} ä¸åŒçš„æ•™å¸ˆæ¨¡å‹")
            
            print(f"ğŸ“š æ¸è¿›å¼çŸ¥è¯†è’¸é¦é…ç½®ï¼š")
            print(f"  æ•™å¸ˆæ¨¡å‹: {teacher_name}")
            print(f"  å­¦ç”Ÿæ¨¡å‹: {student_name}")
            
            teacher = BasicModelBank(model_name=teacher_name, device=self.device, dataset_type=self.dataset_type)
            student = BasicModelBank(model_name=student_name, device=self.device, dataset_type=self.dataset_type)
            
            distillation_model = ProgressiveKnowledgeDistillation(
                teacher_models=[teacher.model],  # æ¸è¿›å¼è’¸é¦ä½¿ç”¨å•ä¸ªæ•™å¸ˆæ¨¡å‹çš„åˆ—è¡¨
                student_model=student.model,
                device=self.device
            )
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è’¸é¦ç±»å‹: {distillation_type}")
            
        # å¯¹äºnn.Moduleç±»å‹çš„æ¨¡å‹ï¼Œç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        if hasattr(distillation_model, 'to'):
            return distillation_model.to(self.device)
        else:
            # å¯¹äºénn.Moduleç±»å‹ï¼ˆå¦‚ProgressiveKnowledgeDistillationï¼‰ï¼Œç›´æ¥è¿”å›
            return distillation_model
        
    def _create_nas_model(self):
        """åˆ›å»ºç¥ç»æ¶æ„æœç´¢æ¨¡å‹"""
        nas_type = self.kwargs.get('nas_type', 'supernet')
        
        if nas_type == 'supernet':
            # æ ¹æ®æ•°æ®é›†ç±»å‹è·å–é»˜è®¤é…ç½®
            dataset_configs = {
                'BraTS': {'in_channels': 4, 'num_classes': 4},
                'MS_MultiSpine': {'in_channels': 2, 'num_classes': 6}
            }
            default_config = dataset_configs.get(self.dataset_type, {'in_channels': 4, 'num_classes': 4})
            
            # åˆ›å»ºè¶…ç½‘ç»œ
            supernet = SuperNet(
                in_channels=self.kwargs.get('in_channels', default_config['in_channels']),
                num_classes=self.kwargs.get('num_classes', default_config['num_classes']),
                base_channels=self.kwargs.get('base_channels', 32),
                num_layers=self.kwargs.get('num_layers', 4)
            )
            return supernet.to(self.device)
            
        elif nas_type == 'searcher':
            # æ ¹æ®æ•°æ®é›†ç±»å‹è·å–é»˜è®¤é…ç½®
            dataset_configs = {
                'BraTS': {'in_channels': 4, 'num_classes': 4},
                'MS_MultiSpine': {'in_channels': 2, 'num_classes': 6}
            }
            default_config = dataset_configs.get(self.dataset_type, {'in_channels': 4, 'num_classes': 4})
            
            # åˆ›å»ºDARTSæœç´¢å™¨
            supernet = SuperNet(
                in_channels=self.kwargs.get('in_channels', default_config['in_channels']),
                num_classes=self.kwargs.get('num_classes', default_config['num_classes']),
                base_channels=self.kwargs.get('base_channels', 32),
                num_layers=self.kwargs.get('num_layers', 4)
            )
            
            searcher = DARTSSearcher(
                supernet=supernet,
                device=self.device,
                arch_lr=self.kwargs.get('arch_lr', 3e-4),
                model_lr=self.kwargs.get('model_lr', 1e-3)
            )
            return searcher
            
        elif nas_type == 'progressive':
            # åˆ›å»ºæ¸è¿›å¼NAS
            progressive_nas = ProgressiveNAS(
                device=self.device,
                max_layers=self.kwargs.get('max_layers', 8),
                start_layers=self.kwargs.get('start_layers', 2)
            )
            return progressive_nas
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„NASç±»å‹: {nas_type}")
            
    def _create_nas_distillation_model(self):
        """åˆ›å»ºNAS-è’¸é¦é›†æˆæ¨¡å‹"""
        from nas_distillation import NASDistillationIntegration
        
        # è·å–æ•™å¸ˆæ¨¡å‹åˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨æ‰€æœ‰åŸºç¡€æ¨¡å‹
        teacher_models = self.kwargs.get('teacher_models', get_all_supported_models())
        
        # ç¡®ä¿æ•™å¸ˆæ¨¡å‹åˆ—è¡¨ä¸ä¸ºç©º
        if not teacher_models:
            teacher_models = get_all_supported_models()
            print(f"âš  è­¦å‘Šï¼šæ•™å¸ˆæ¨¡å‹åˆ—è¡¨ä¸ºç©ºï¼Œè‡ªåŠ¨ä½¿ç”¨æ‰€æœ‰åŸºç¡€æ¨¡å‹ä½œä¸ºæ•™å¸ˆæ¨¡å‹")
            
        print(f"ğŸ”¬ NAS-è’¸é¦é›†æˆé…ç½®ï¼š")
        print(f"  æ•™å¸ˆæ¨¡å‹: {teacher_models}")
        print(f"  æ•™å¸ˆæ¨¡å‹æ•°é‡: {len(teacher_models)}")
        print(f"  æ•°æ®é›†ç±»å‹: {self.dataset_type}")
        
        # åˆ›å»ºNAS-è’¸é¦é›†æˆå™¨
        nas_distillation = NASDistillationIntegration(
            teacher_models=teacher_models,
            device=self.device,
            dataset_type=self.dataset_type,
            nas_epochs=self.kwargs.get('nas_epochs', 50),
            distillation_epochs=self.kwargs.get('distillation_epochs', 100),
            arch_lr=self.kwargs.get('arch_lr', 3e-4),
            model_lr=self.kwargs.get('model_lr', 1e-3),
            distillation_lr=self.kwargs.get('distillation_lr', 1e-4),
            temperature=self.kwargs.get('temperature', 4.0),
            alpha=self.kwargs.get('alpha', 0.7),
            save_dir=self.kwargs.get('save_dir', './checkpoints/nas_distillation')
        )
        
        return nas_distillation
            
    def get_model(self):
        """è·å–æ¨¡å‹"""
        return self.model
        
    def get_loss_function(self):
        """è·å–æŸå¤±å‡½æ•°"""
        if self.model_type == 'distillation':
            return KnowledgeDistillationLoss(
                temperature=self.kwargs.get('temperature', 4.0),
                alpha=self.kwargs.get('alpha', 0.7)
            )
        else:
            # ä½¿ç”¨æ ‡å‡†æŸå¤±å‡½æ•°
            return DiceCELoss(to_onehot_y=True, softmax=True)
            
    def train_step(self, data, labels, optimizer=None):
        """è®­ç»ƒæ­¥éª¤"""
        if self.model_type == 'nas' and hasattr(self.model, 'search_step'):
            # NASæœç´¢æ­¥éª¤
            if len(data) >= 2 and len(labels) >= 2:
                train_data, val_data = data[:len(data)//2], data[len(data)//2:]
                train_labels, val_labels = labels[:len(labels)//2], labels[len(labels)//2:]
                return self.model.search_step(train_data, train_labels, val_data, val_labels)
            else:
                raise ValueError("NASæœç´¢éœ€è¦è®­ç»ƒå’ŒéªŒè¯æ•°æ®")
        else:
            # æ ‡å‡†è®­ç»ƒæ­¥éª¤
            if optimizer is None:
                raise ValueError("æ ‡å‡†è®­ç»ƒéœ€è¦ä¼˜åŒ–å™¨")
                
            optimizer.zero_grad()
            
            if self.model_type == 'distillation':
                # çŸ¥è¯†è’¸é¦è®­ç»ƒ
                student_output, loss = self.model(data, labels)
                # æŸå¤±å·²ç»åœ¨æ¨¡å‹å†…éƒ¨è®¡ç®—å®Œæˆ
            else:
                # æ ‡å‡†è®­ç»ƒ
                output = self.model(data)
                loss_fn = self.get_loss_function()
                loss = loss_fn(output, labels)
                
            loss.backward()
            optimizer.step()
            
            return loss.item()


class ModelFactory:
    """
    æ¨¡å‹å·¥å‚ï¼šç»Ÿä¸€åˆ›å»ºå„ç§ç±»å‹çš„æ¨¡å‹
    æ”¯æŒå¤šæ•°æ®é›†åŠ¨æ€é€šé“é…ç½®
    """
    
    @staticmethod
    def create_model(model_config: Dict[str, Any]) -> Any:
        """
        æ ¹æ®é…ç½®åˆ›å»ºæ¨¡å‹
        """
        model_category = model_config.get('category', 'basic')  # 'basic', 'advanced'
        dataset_type = model_config.get('dataset_type', 'BraTS')
        
        if model_category == 'basic':
            return BasicModelBank(
                model_name=model_config.get('model_name', 'UNet'),
                device=model_config.get('device', 'auto'),
                dataset_type=dataset_type
            )
            
        elif model_category == 'advanced':
            return SpecializedModelFactory(
                model_type=model_config.get('model_type', 'fusion'),
                device=model_config.get('device', 'auto'),
                dataset_type=dataset_type,
                **model_config.get('kwargs', {})
            )
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»åˆ«: {model_category}")
            
    @staticmethod
    def get_model_info() -> Dict[str, List[str]]:
        """
        è·å–æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹ä¿¡æ¯
        """
        return {
            'basic_models': get_all_supported_models(),
            'advanced_types': ['fusion', 'distillation', 'nas'],
            'fusion_types': ['cross_attention', 'channel_attention', 'spatial_attention', 'adaptive'],
            'distillation_types': ['multi_teacher', 'progressive'],
            'nas_types': ['supernet', 'searcher', 'progressive']
        }


if __name__ == "__main__":
    # åŠŸèƒ½éªŒè¯
    print("æ¨¡å‹åº“åŠŸèƒ½éªŒè¯...")
    
    # æ˜¾ç¤ºæ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    supported_models = get_all_supported_models()
    print(f"åŸºç¡€æ¨¡å‹æ•°é‡: {len(supported_models)}")
    print(f"åŸºç¡€æ¨¡å‹åˆ—è¡¨: {supported_models}")
    
    # æ˜¾ç¤ºå¤åˆæ¶æ„æ¨¡å‹ä¿¡æ¯
    model_info = ModelFactory.get_model_info()
    print(f"\nå¤åˆæ¶æ„æ¨¡å‹ä¿¡æ¯:")
    for category, models in model_info.items():
        print(f"  {category}: {models}")
    
    # åˆ›å»ºæµ‹è¯•æ¨¡å‹éªŒè¯è®¾å¤‡é…ç½®
    test_model = BasicModelBank()
    device = test_model._setup_device('auto')
    print(f"\nè®¾å¤‡é…ç½®éªŒè¯é€šè¿‡ï¼Œè®¾å¤‡: {device}")
    
    # æµ‹è¯•æ¨¡å‹å·¥å‚
    try:
        # æµ‹è¯•åŸºç¡€æ¨¡å‹åˆ›å»ºï¼ˆBraTSæ•°æ®é›†ï¼‰
        basic_config_brats = {
            'category': 'basic',
            'model_name': 'UNet',
            'device': 'auto',
            'dataset_type': 'BraTS'
        }
        basic_model_brats = ModelFactory.create_model(basic_config_brats)
        print(f"BraTSåŸºç¡€æ¨¡å‹åˆ›å»ºæˆåŠŸ: {type(basic_model_brats).__name__}")
        
        # æµ‹è¯•åŸºç¡€æ¨¡å‹åˆ›å»ºï¼ˆMS_MultiSpineæ•°æ®é›†ï¼‰
        basic_config_ms = {
            'category': 'basic',
            'model_name': 'UNet',
            'device': 'auto',
            'dataset_type': 'MS_MultiSpine'
        }
        basic_model_ms = ModelFactory.create_model(basic_config_ms)
        print(f"MS_MultiSpineåŸºç¡€æ¨¡å‹åˆ›å»ºæˆåŠŸ: {type(basic_model_ms).__name__}")
        
        # æµ‹è¯•å¤åˆæ¶æ„æ¨¡å‹åˆ›å»ºï¼ˆèåˆç½‘ç»œï¼‰
        fusion_config = {
            'category': 'advanced',
            'model_type': 'fusion',
            'device': 'auto',
            'dataset_type': 'BraTS',
            'kwargs': {
                'base_models': ['UNet', 'SegResNet'],
                'fusion_type': 'cross_attention'
            }
        }
        fusion_model = ModelFactory.create_model(fusion_config)
        print(f"èåˆæ¨¡å‹åˆ›å»ºæˆåŠŸ: {type(fusion_model).__name__}")
        
        print("\næ‰€æœ‰åŠŸèƒ½éªŒè¯é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nåŠŸèƒ½éªŒè¯å¤±è´¥: {e}")
        print("æ³¨æ„: æŸäº›åŠŸèƒ½å¯èƒ½éœ€è¦é¢å¤–çš„ä¾èµ–æˆ–æ•°æ®")